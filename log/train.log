2019-04-26 19:20:19,133  Display original image
2019-04-26 19:20:19,154  update_title_pos
2019-04-26 19:20:19,165  findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('C:\\Users\\Yash\\.conda\\envs\\squad\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans.ttf') with score of 0.050000.
2019-04-26 19:20:19,169  Assigning font /b'F1' = 'C:\\Users\\Yash\\.conda\\envs\\squad\\lib\\site-packages\\matplotlib\\mpl-data\\fonts\\ttf\\DejaVuSans.ttf'
2019-04-26 19:20:19,756  The shape of training data: (33600, 1, 28, 28)
2019-04-26 19:20:19,758  The shape of testing  data: (8400, 1, 28, 28)
2019-04-26 19:20:19,758  The shape of training label data: (33600, 1)
2019-04-26 19:20:19,900  The shape of testing  label data: (8400, 1)
2019-04-26 19:20:19,907  The device on which the model is running is :: cpu
2019-04-26 19:20:20,081  Saver will maximize Accuracy...
2019-04-26 19:20:20,203  The loss during training is  :: 3.2349319458007812 
2019-04-26 19:20:20,381  The global step train is 1
2019-04-26 19:20:20,521  The loss during training is  :: 3.134950637817383 
2019-04-26 19:20:20,670  The global step train is 2
2019-04-26 19:20:20,788  The loss during training is  :: 2.787653923034668 
2019-04-26 19:20:20,955  The global step train is 3
2019-04-26 19:20:21,085  The loss during training is  :: 2.473076105117798 
2019-04-26 19:20:21,248  The global step train is 4
2019-04-26 19:20:21,367  The loss during training is  :: 2.3292465209960938 
2019-04-26 19:20:21,521  The global step train is 5
2019-04-26 19:20:21,639  The loss during training is  :: 2.315016031265259 
2019-04-26 19:20:21,799  The global step train is 6
2019-04-26 19:20:21,917  The loss during training is  :: 2.2446448802948 
2019-04-26 19:20:22,072  The global step train is 7
2019-04-26 19:20:22,192  The loss during training is  :: 2.20784854888916 
2019-04-26 19:20:22,337  The global step train is 8
2019-04-26 19:20:22,450  The loss during training is  :: 2.132446527481079 
2019-04-26 19:20:22,605  The global step train is 9
2019-04-26 19:20:22,735  The loss during training is  :: 2.082085132598877 
2019-04-26 19:20:22,891  The global step train is 10
2019-04-26 19:20:23,014  The loss during training is  :: 2.013667106628418 
2019-04-26 19:20:23,166  The global step train is 11
2019-04-26 19:20:23,295  The loss during training is  :: 2.043381452560425 
2019-04-26 19:20:23,445  The global step train is 12
2019-04-26 19:20:23,575  The loss during training is  :: 2.014681100845337 
2019-04-26 19:20:23,724  The global step train is 13
2019-04-26 19:20:23,878  The loss during training is  :: 1.985845685005188 
2019-04-26 19:20:24,026  The global step train is 14
2019-04-26 19:20:24,165  The loss during training is  :: 1.9170290231704712 
2019-04-26 19:20:24,317  The global step train is 15
2019-04-26 19:20:24,444  The loss during training is  :: 1.8367047309875488 
2019-04-26 19:20:24,606  The global step train is 16
2019-04-26 19:20:24,728  The loss during training is  :: 1.8819193840026855 
2019-04-26 19:20:24,883  The global step train is 17
2019-04-26 19:20:25,018  The loss during training is  :: 1.8220252990722656 
2019-04-26 19:20:25,176  The global step train is 18
2019-04-26 19:20:25,304  The loss during training is  :: 1.7608569860458374 
2019-04-26 19:20:25,465  The global step train is 19
2019-04-26 19:20:25,592  The loss during training is  :: 1.7672024965286255 
2019-04-26 19:20:25,757  The global step train is 20
2019-04-26 19:20:25,884  The loss during training is  :: 1.7156339883804321 
2019-04-26 19:20:26,044  The global step train is 21
2019-04-26 19:20:26,195  The loss during training is  :: 1.7013880014419556 
2019-04-26 19:20:26,350  The global step train is 22
2019-04-26 19:20:26,476  The loss during training is  :: 1.7162257432937622 
2019-04-26 19:20:26,625  The global step train is 23
2019-04-26 19:20:26,735  The loss during training is  :: 1.5925625562667847 
2019-04-26 19:20:26,883  The global step train is 24
2019-04-26 19:20:26,991  The loss during training is  :: 1.5177205801010132 
2019-04-26 19:20:27,141  The global step train is 25
2019-04-26 19:20:27,260  The loss during training is  :: 1.436915636062622 
2019-04-26 19:20:27,414  The global step train is 26
2019-04-26 19:20:27,526  The loss during training is  :: 1.4987279176712036 
2019-04-26 19:20:27,677  The global step train is 27
2019-04-26 19:20:27,787  The loss during training is  :: 1.518586277961731 
2019-04-26 19:20:27,941  The global step train is 28
2019-04-26 19:20:28,056  The loss during training is  :: 1.384928584098816 
2019-04-26 19:20:28,219  The global step train is 29
2019-04-26 19:20:28,335  The loss during training is  :: 1.4687436819076538 
2019-04-26 19:20:28,488  The global step train is 30
2019-04-26 19:20:28,615  The loss during training is  :: 1.4815906286239624 
2019-04-26 19:20:28,782  The global step train is 31
2019-04-26 19:20:28,896  The loss during training is  :: 1.4726674556732178 
2019-04-26 19:20:29,041  The global step train is 32
2019-04-26 19:20:29,156  The loss during training is  :: 1.3760206699371338 
2019-04-26 19:20:29,311  The global step train is 33
2019-04-26 19:20:29,428  The loss during training is  :: 1.2553499937057495 
2019-04-26 19:20:29,579  The global step train is 34
2019-04-26 19:20:29,694  The loss during training is  :: 1.3838095664978027 
2019-04-26 19:20:29,852  The global step train is 35
2019-04-26 19:20:29,967  The loss during training is  :: 1.2830572128295898 
2019-04-26 19:20:30,119  The global step train is 36
2019-04-26 19:20:30,234  The loss during training is  :: 1.2409403324127197 
2019-04-26 19:20:30,389  The global step train is 37
2019-04-26 19:20:30,504  The loss during training is  :: 1.2710740566253662 
2019-04-26 19:20:30,659  The global step train is 38
2019-04-26 19:20:30,789  The loss during training is  :: 1.2460163831710815 
2019-04-26 19:20:30,971  The global step train is 39
2019-04-26 19:20:31,117  The loss during training is  :: 1.1571807861328125 
2019-04-26 19:20:31,293  The global step train is 40
2019-04-26 19:20:31,422  The loss during training is  :: 1.1372534036636353 
2019-04-26 19:20:31,582  The global step train is 41
2019-04-26 19:20:31,723  The loss during training is  :: 1.1617515087127686 
2019-04-26 19:20:31,903  The global step train is 42
2019-04-26 19:20:32,030  The loss during training is  :: 1.0695134401321411 
2019-04-26 19:20:32,194  The global step train is 43
2019-04-26 19:20:32,324  The loss during training is  :: 1.0298941135406494 
2019-04-26 19:20:32,500  The global step train is 44
2019-04-26 19:20:32,632  The loss during training is  :: 1.003503680229187 
2019-04-26 19:20:32,811  The global step train is 45
2019-04-26 19:20:32,937  The loss during training is  :: 0.9438326954841614 
2019-04-26 19:20:33,105  The global step train is 46
2019-04-26 19:20:33,235  The loss during training is  :: 0.9349778294563293 
2019-04-26 19:20:33,403  The global step train is 47
2019-04-26 19:20:33,531  The loss during training is  :: 0.9975050687789917 
2019-04-26 19:20:33,700  The global step train is 48
2019-04-26 19:20:33,828  The loss during training is  :: 0.9374736547470093 
2019-04-26 19:20:34,012  The global step train is 49
2019-04-26 19:20:34,144  The loss during training is  :: 0.9061307907104492 
2019-04-26 19:20:34,308  The global step train is 50
2019-04-26 19:20:34,429  The loss during training is  :: 0.8668572902679443 
2019-04-26 19:20:34,594  The global step train is 51
2019-04-26 19:20:34,707  The loss during training is  :: 1.0012202262878418 
2019-04-26 19:20:34,866  The global step train is 52
2019-04-26 19:20:34,976  The loss during training is  :: 0.9948807954788208 
2019-04-26 19:20:35,123  The global step train is 53
2019-04-26 19:20:35,239  The loss during training is  :: 0.8035190105438232 
2019-04-26 19:20:35,401  The global step train is 54
2019-04-26 19:20:35,512  The loss during training is  :: 0.8271763324737549 
2019-04-26 19:20:35,660  The global step train is 55
2019-04-26 19:20:35,778  The loss during training is  :: 0.8417134284973145 
2019-04-26 19:20:35,936  The global step train is 56
2019-04-26 19:20:36,047  The loss during training is  :: 0.8425224423408508 
2019-04-26 19:20:36,200  The global step train is 57
2019-04-26 19:20:36,316  The loss during training is  :: 0.7774316072463989 
2019-04-26 19:20:36,461  The global step train is 58
2019-04-26 19:20:36,573  The loss during training is  :: 0.6935345530509949 
2019-04-26 19:20:36,724  The global step train is 59
2019-04-26 19:20:36,838  The loss during training is  :: 0.8498170971870422 
2019-04-26 19:20:36,987  The global step train is 60
2019-04-26 19:20:37,111  The loss during training is  :: 0.9189823269844055 
2019-04-26 19:20:37,268  The global step train is 61
2019-04-26 19:20:37,396  The loss during training is  :: 0.625465989112854 
2019-04-26 19:20:37,553  The global step train is 62
2019-04-26 19:20:37,683  The loss during training is  :: 0.6529869437217712 
2019-04-26 19:20:37,837  The global step train is 63
2019-04-26 19:20:37,964  The loss during training is  :: 0.8765759468078613 
2019-04-26 19:20:38,123  The global step train is 64
2019-04-26 19:20:38,247  The loss during training is  :: 0.762399435043335 
2019-04-26 19:20:38,402  The global step train is 65
2019-04-26 19:20:38,522  The loss during training is  :: 0.7376499176025391 
2019-04-26 19:20:38,679  The global step train is 66
2019-04-26 19:20:38,803  The loss during training is  :: 0.6889140009880066 
2019-04-26 19:20:38,968  The global step train is 67
2019-04-26 19:20:39,092  The loss during training is  :: 0.6680411100387573 
2019-04-26 19:20:39,256  The global step train is 68
2019-04-26 19:20:39,381  The loss during training is  :: 0.6173800230026245 
2019-04-26 19:20:39,541  The global step train is 69
2019-04-26 19:20:39,664  The loss during training is  :: 0.7313190698623657 
2019-04-26 19:20:39,824  The global step train is 70
2019-04-26 19:20:39,948  The loss during training is  :: 0.5590468049049377 
2019-04-26 19:20:40,113  The global step train is 71
2019-04-26 19:20:40,246  The loss during training is  :: 0.6630229949951172 
2019-04-26 19:20:40,411  The global step train is 72
2019-04-26 19:20:40,541  The loss during training is  :: 0.7664816975593567 
2019-04-26 19:20:40,703  The global step train is 73
2019-04-26 19:20:40,836  The loss during training is  :: 0.5453615188598633 
2019-04-26 19:20:40,998  The global step train is 74
2019-04-26 19:20:41,128  The loss during training is  :: 0.5918530225753784 
2019-04-26 19:20:41,317  The global step train is 75
2019-04-26 19:20:41,474  The loss during training is  :: 0.5964195132255554 
2019-04-26 19:20:41,660  The global step train is 76
2019-04-26 19:20:41,809  The loss during training is  :: 0.5539441704750061 
2019-04-26 19:20:42,002  The global step train is 77
2019-04-26 19:20:42,149  The loss during training is  :: 0.5776920318603516 
2019-04-26 19:20:42,327  The global step train is 78
2019-04-26 19:20:42,473  The loss during training is  :: 0.5252202153205872 
2019-04-26 19:20:42,708  The global step train is 79
2019-04-26 19:20:42,861  The loss during training is  :: 0.4717661142349243 
2019-04-26 19:20:43,057  The global step train is 80
2019-04-26 19:20:43,217  The loss during training is  :: 0.5353232026100159 
2019-04-26 19:20:43,426  The global step train is 81
2019-04-26 19:20:43,583  The loss during training is  :: 0.5011629462242126 
2019-04-26 19:20:43,794  The global step train is 82
2019-04-26 19:20:43,939  The loss during training is  :: 0.512725830078125 
2019-04-26 19:20:44,131  The global step train is 83
2019-04-26 19:20:44,280  The loss during training is  :: 0.3990797996520996 
2019-04-26 19:20:44,461  The global step train is 84
2019-04-26 19:20:44,598  The loss during training is  :: 0.4732736349105835 
2019-04-26 19:20:44,759  The global step train is 85
2019-04-26 19:20:44,892  The loss during training is  :: 0.5559669733047485 
2019-04-26 19:20:45,051  The global step train is 86
2019-04-26 19:20:45,177  The loss during training is  :: 0.44271454215049744 
2019-04-26 19:20:45,347  The global step train is 87
2019-04-26 19:20:45,473  The loss during training is  :: 0.4357193410396576 
2019-04-26 19:20:45,630  The global step train is 88
2019-04-26 19:20:45,755  The loss during training is  :: 0.49066880345344543 
2019-04-26 19:20:45,912  The global step train is 89
2019-04-26 19:20:46,036  The loss during training is  :: 0.5695011019706726 
2019-04-26 19:20:46,195  The global step train is 90
2019-04-26 19:20:46,325  The loss during training is  :: 0.5024124979972839 
2019-04-26 19:20:46,482  The global step train is 91
2019-04-26 19:20:46,603  The loss during training is  :: 0.3677104711532593 
2019-04-26 19:20:46,763  The global step train is 92
2019-04-26 19:20:46,891  The loss during training is  :: 0.4810259938240051 
2019-04-26 19:20:47,052  The global step train is 93
2019-04-26 19:20:47,179  The loss during training is  :: 0.4119660556316376 
2019-04-26 19:20:47,337  The global step train is 94
2019-04-26 19:20:47,460  The loss during training is  :: 0.4995207190513611 
2019-04-26 19:20:47,621  The global step train is 95
2019-04-26 19:20:47,748  The loss during training is  :: 0.49288132786750793 
2019-04-26 19:20:47,909  The global step train is 96
2019-04-26 19:20:48,036  The loss during training is  :: 0.3740944564342499 
2019-04-26 19:20:48,199  The global step train is 97
2019-04-26 19:20:48,328  The loss during training is  :: 0.4972819983959198 
2019-04-26 19:20:48,493  The global step train is 98
2019-04-26 19:20:48,622  The loss during training is  :: 0.41430336236953735 
2019-04-26 19:20:48,779  The global step train is 99
2019-04-26 19:20:48,906  The loss during training is  :: 0.48793476819992065 
2019-04-26 19:20:49,069  The global step train is 100
2019-04-26 19:20:49,191  The loss during training is  :: 0.3987313508987427 
2019-04-26 19:20:49,355  The global step train is 101
2019-04-26 19:20:49,481  The loss during training is  :: 0.406757652759552 
2019-04-26 19:20:49,639  The global step train is 102
2019-04-26 19:20:49,765  The loss during training is  :: 0.3440176844596863 
2019-04-26 19:20:49,924  The global step train is 103
2019-04-26 19:20:50,049  The loss during training is  :: 0.415947824716568 
2019-04-26 19:20:50,209  The global step train is 104
2019-04-26 19:20:50,355  The loss during training is  :: 0.4114849865436554 
2019-04-26 19:20:50,519  The global step train is 105
2019-04-26 19:20:50,651  The loss during training is  :: 0.38417044281959534 
2019-04-26 19:20:50,811  The global step train is 106
2019-04-26 19:20:50,940  The loss during training is  :: 0.30582961440086365 
2019-04-26 19:20:51,097  The global step train is 107
2019-04-26 19:20:51,224  The loss during training is  :: 0.3955894410610199 
2019-04-26 19:20:51,385  The global step train is 108
2019-04-26 19:20:51,511  The loss during training is  :: 0.34922531247138977 
2019-04-26 19:20:51,670  The global step train is 109
2019-04-26 19:20:51,796  The loss during training is  :: 0.348550945520401 
2019-04-26 19:20:51,958  The global step train is 110
2019-04-26 19:20:52,087  The loss during training is  :: 0.38999471068382263 
2019-04-26 19:20:52,249  The global step train is 111
2019-04-26 19:20:52,378  The loss during training is  :: 0.3490162789821625 
2019-04-26 19:20:52,539  The global step train is 112
2019-04-26 19:20:52,672  The loss during training is  :: 0.43817245960235596 
2019-04-26 19:20:52,835  The global step train is 113
2019-04-26 19:20:52,963  The loss during training is  :: 0.2965225577354431 
2019-04-26 19:20:53,133  The global step train is 114
2019-04-26 19:20:53,254  The loss during training is  :: 0.3715079724788666 
2019-04-26 19:20:53,419  The global step train is 115
2019-04-26 19:20:53,552  The loss during training is  :: 0.3344305455684662 
2019-04-26 19:20:53,713  The global step train is 116
2019-04-26 19:20:53,844  The loss during training is  :: 0.40398457646369934 
2019-04-26 19:20:54,006  The global step train is 117
2019-04-26 19:20:54,142  The loss during training is  :: 0.42803430557250977 
2019-04-26 19:20:54,316  The global step train is 118
2019-04-26 19:20:54,447  The loss during training is  :: 0.261817067861557 
2019-04-26 19:20:54,611  The global step train is 119
2019-04-26 19:20:54,743  The loss during training is  :: 0.3118423521518707 
2019-04-26 19:20:54,906  The global step train is 120
2019-04-26 19:20:55,035  The loss during training is  :: 0.4018220603466034 
2019-04-26 19:20:55,227  The global step train is 121
2019-04-26 19:20:55,355  The loss during training is  :: 0.29386836290359497 
2019-04-26 19:20:55,517  The global step train is 122
2019-04-26 19:20:55,641  The loss during training is  :: 0.32764267921447754 
2019-04-26 19:20:55,836  The global step train is 123
2019-04-26 19:20:55,964  The loss during training is  :: 0.3006027936935425 
2019-04-26 19:20:56,123  The global step train is 124
2019-04-26 19:20:56,248  The loss during training is  :: 0.43231531977653503 
2019-04-26 19:20:56,416  The global step train is 125
2019-04-26 19:20:56,554  The loss during training is  :: 0.276645690202713 
2019-04-26 19:20:56,718  The global step train is 126
2019-04-26 19:20:56,848  The loss during training is  :: 0.27663618326187134 
2019-04-26 19:20:57,015  The global step train is 127
2019-04-26 19:20:57,150  The loss during training is  :: 0.29594728350639343 
2019-04-26 19:20:57,309  The global step train is 128
2019-04-26 19:20:57,453  The loss during training is  :: 0.3638310134410858 
2019-04-26 19:20:57,629  The global step train is 129
2019-04-26 19:20:57,762  The loss during training is  :: 0.3190111219882965 
2019-04-26 19:20:57,920  The global step train is 130
2019-04-26 19:20:58,045  The loss during training is  :: 0.36779525876045227 
2019-04-26 19:20:58,206  The global step train is 131
2019-04-26 19:20:58,337  The loss during training is  :: 0.3328900635242462 
2019-04-26 19:20:58,494  The global step train is 132
2019-04-26 19:20:58,618  The loss during training is  :: 0.27022066712379456 
2019-04-26 19:20:58,778  The global step train is 133
2019-04-26 19:20:58,906  The loss during training is  :: 0.2543294131755829 
2019-04-26 19:20:59,074  The global step train is 134
2019-04-26 19:20:59,212  The loss during training is  :: 0.27954578399658203 
2019-04-26 19:20:59,387  The global step train is 135
2019-04-26 19:20:59,524  The loss during training is  :: 0.2509521543979645 
2019-04-26 19:20:59,685  The global step train is 136
2019-04-26 19:20:59,818  The loss during training is  :: 0.23040761053562164 
2019-04-26 19:20:59,979  The global step train is 137
2019-04-26 19:21:00,126  The loss during training is  :: 0.2859173119068146 
2019-04-26 19:21:00,306  The global step train is 138
2019-04-26 19:21:00,444  The loss during training is  :: 0.33149266242980957 
2019-04-26 19:21:00,615  The global step train is 139
2019-04-26 19:21:00,750  The loss during training is  :: 0.2925466299057007 
2019-04-26 19:21:00,941  The global step train is 140
2019-04-26 19:21:01,095  The loss during training is  :: 0.26060304045677185 
2019-04-26 19:21:01,317  The global step train is 141
2019-04-26 19:21:01,457  The loss during training is  :: 0.3732091784477234 
2019-04-26 19:21:01,623  The global step train is 142
2019-04-26 19:21:01,749  The loss during training is  :: 0.2945890426635742 
2019-04-26 19:21:01,907  The global step train is 143
2019-04-26 19:21:02,034  The loss during training is  :: 0.30349430441856384 
2019-04-26 19:21:02,191  The global step train is 144
2019-04-26 19:21:02,320  The loss during training is  :: 0.40646371245384216 
2019-04-26 19:21:02,477  The global step train is 145
2019-04-26 19:21:02,605  The loss during training is  :: 0.2927020788192749 
2019-04-26 19:21:02,762  The global step train is 146
2019-04-26 19:21:02,886  The loss during training is  :: 0.2741558253765106 
2019-04-26 19:21:03,046  The global step train is 147
2019-04-26 19:21:03,172  The loss during training is  :: 0.28815749287605286 
2019-04-26 19:21:03,327  The global step train is 148
2019-04-26 19:21:03,454  The loss during training is  :: 0.3055080473423004 
2019-04-26 19:21:03,608  The global step train is 149
2019-04-26 19:21:03,735  The loss during training is  :: 0.2389853149652481 
2019-04-26 19:21:03,889  The global step train is 150
2019-04-26 19:21:04,019  The loss during training is  :: 0.3422955274581909 
2019-04-26 19:21:04,174  The global step train is 151
2019-04-26 19:21:04,300  The loss during training is  :: 0.3851025104522705 
2019-04-26 19:21:04,455  The global step train is 152
2019-04-26 19:21:04,582  The loss during training is  :: 0.2620786130428314 
2019-04-26 19:21:04,736  The global step train is 153
2019-04-26 19:21:04,860  The loss during training is  :: 0.2618430554866791 
2019-04-26 19:21:05,014  The global step train is 154
2019-04-26 19:21:05,140  The loss during training is  :: 0.24714966118335724 
2019-04-26 19:21:05,302  The global step train is 155
2019-04-26 19:21:05,426  The loss during training is  :: 0.34192463755607605 
2019-04-26 19:21:05,583  The global step train is 156
2019-04-26 19:21:05,706  The loss during training is  :: 0.298607736825943 
2019-04-26 19:21:05,866  The global step train is 157
2019-04-26 19:21:05,991  The loss during training is  :: 0.28282278776168823 
2019-04-26 19:21:06,149  The global step train is 158
2019-04-26 19:21:06,281  The loss during training is  :: 0.23985229432582855 
2019-04-26 19:21:06,447  The global step train is 159
2019-04-26 19:21:06,572  The loss during training is  :: 0.2001122087240219 
2019-04-26 19:21:06,733  The global step train is 160
2019-04-26 19:21:06,859  The loss during training is  :: 0.4407593905925751 
2019-04-26 19:21:07,017  The global step train is 161
2019-04-26 19:21:07,139  The loss during training is  :: 0.29204198718070984 
2019-04-26 19:21:07,301  The global step train is 162
2019-04-26 19:21:07,437  The loss during training is  :: 0.28346729278564453 
2019-04-26 19:21:07,615  The global step train is 163
2019-04-26 19:21:07,740  The loss during training is  :: 0.32784128189086914 
2019-04-26 19:21:07,898  The global step train is 164
2019-04-26 19:21:08,023  The loss during training is  :: 0.23219990730285645 
2019-04-26 19:21:08,184  The global step train is 165
2019-04-26 19:21:08,315  The loss during training is  :: 0.23115107417106628 
2019-04-26 19:21:08,472  The global step train is 166
2019-04-26 19:21:08,598  The loss during training is  :: 0.1980494111776352 
2019-04-26 19:21:08,757  The global step train is 167
2019-04-26 19:21:08,878  The loss during training is  :: 0.19043263792991638 
2019-04-26 19:21:09,036  The global step train is 168
2019-04-26 19:21:09,166  The loss during training is  :: 0.24773557484149933 
2019-04-26 19:21:09,328  The global step train is 169
2019-04-26 19:21:09,457  The loss during training is  :: 0.22251194715499878 
2019-04-26 19:21:09,611  The global step train is 170
2019-04-26 19:21:09,735  The loss during training is  :: 0.26639705896377563 
2019-04-26 19:21:09,889  The global step train is 171
2019-04-26 19:21:10,016  The loss during training is  :: 0.23773638904094696 
2019-04-26 19:21:10,182  The global step train is 172
2019-04-26 19:21:10,311  The loss during training is  :: 0.2009742707014084 
2019-04-26 19:21:10,469  The global step train is 173
2019-04-26 19:21:10,593  The loss during training is  :: 0.19315177202224731 
2019-04-26 19:21:10,748  The global step train is 174
2019-04-26 19:21:10,882  The loss during training is  :: 0.18370427191257477 
2019-04-26 19:21:11,054  The global step train is 175
2019-04-26 19:21:11,178  The loss during training is  :: 0.22007161378860474 
2019-04-26 19:21:11,339  The global step train is 176
2019-04-26 19:21:11,467  The loss during training is  :: 0.23587438464164734 
2019-04-26 19:21:11,623  The global step train is 177
2019-04-26 19:21:11,748  The loss during training is  :: 0.30935370922088623 
2019-04-26 19:21:11,910  The global step train is 178
2019-04-26 19:21:12,038  The loss during training is  :: 0.3552117943763733 
2019-04-26 19:21:12,192  The global step train is 179
2019-04-26 19:21:12,323  The loss during training is  :: 0.12358515709638596 
2019-04-26 19:21:12,482  The global step train is 180
2019-04-26 19:21:12,608  The loss during training is  :: 0.20089922845363617 
2019-04-26 19:21:12,767  The global step train is 181
2019-04-26 19:21:12,891  The loss during training is  :: 0.209152951836586 
2019-04-26 19:21:13,048  The global step train is 182
2019-04-26 19:21:13,178  The loss during training is  :: 0.2579347789287567 
2019-04-26 19:21:13,336  The global step train is 183
2019-04-26 19:21:13,462  The loss during training is  :: 0.24672187864780426 
2019-04-26 19:21:13,630  The global step train is 184
2019-04-26 19:21:13,754  The loss during training is  :: 0.2362787127494812 
2019-04-26 19:21:13,911  The global step train is 185
2019-04-26 19:21:14,033  The loss during training is  :: 0.25173813104629517 
2019-04-26 19:21:14,195  The global step train is 186
2019-04-26 19:21:14,326  The loss during training is  :: 0.27122771739959717 
2019-04-26 19:21:14,489  The global step train is 187
2019-04-26 19:21:14,613  The loss during training is  :: 0.1417098045349121 
2019-04-26 19:21:14,770  The global step train is 188
2019-04-26 19:21:14,894  The loss during training is  :: 0.18843984603881836 
2019-04-26 19:21:15,052  The global step train is 189
2019-04-26 19:21:15,178  The loss during training is  :: 0.25194981694221497 
2019-04-26 19:21:15,344  The global step train is 190
2019-04-26 19:21:15,470  The loss during training is  :: 0.271660715341568 
2019-04-26 19:21:15,633  The global step train is 191
2019-04-26 19:21:15,755  The loss during training is  :: 0.2881922125816345 
2019-04-26 19:21:15,913  The global step train is 192
2019-04-26 19:21:16,038  The loss during training is  :: 0.21206776797771454 
2019-04-26 19:21:16,198  The global step train is 193
2019-04-26 19:21:16,325  The loss during training is  :: 0.2831055819988251 
2019-04-26 19:21:16,481  The global step train is 194
2019-04-26 19:21:16,610  The loss during training is  :: 0.20214462280273438 
2019-04-26 19:21:16,766  The global step train is 195
2019-04-26 19:21:16,891  The loss during training is  :: 0.2875221371650696 
2019-04-26 19:21:17,048  The global step train is 196
2019-04-26 19:21:17,176  The loss during training is  :: 0.18933048844337463 
2019-04-26 19:21:17,340  The global step train is 197
2019-04-26 19:21:17,466  The loss during training is  :: 0.2469000220298767 
2019-04-26 19:21:17,624  The global step train is 198
2019-04-26 19:21:17,752  The loss during training is  :: 0.18184150755405426 
2019-04-26 19:21:17,910  The global step train is 199
2019-04-26 19:21:18,035  The loss during training is  :: 0.19493669271469116 
2019-04-26 19:21:18,197  The global step train is 200
2019-04-26 19:21:18,327  The loss during training is  :: 0.1586044281721115 
2019-04-26 19:21:18,489  The global step train is 201
2019-04-26 19:21:18,612  The loss during training is  :: 0.15298855304718018 
2019-04-26 19:21:18,770  The global step train is 202
2019-04-26 19:21:18,898  The loss during training is  :: 0.27538424730300903 
2019-04-26 19:21:19,056  The global step train is 203
2019-04-26 19:21:19,188  The loss during training is  :: 0.22253328561782837 
2019-04-26 19:21:19,364  The global step train is 204
2019-04-26 19:21:19,487  The loss during training is  :: 0.31431901454925537 
2019-04-26 19:21:19,646  The global step train is 205
2019-04-26 19:21:19,777  The loss during training is  :: 0.249468132853508 
2019-04-26 19:21:19,937  The global step train is 206
2019-04-26 19:21:20,062  The loss during training is  :: 0.2334408015012741 
2019-04-26 19:21:20,220  The global step train is 207
2019-04-26 19:21:20,349  The loss during training is  :: 0.19630666077136993 
2019-04-26 19:21:20,510  The global step train is 208
2019-04-26 19:21:20,640  The loss during training is  :: 0.17137311398983002 
2019-04-26 19:21:20,802  The global step train is 209
2019-04-26 19:21:20,929  The loss during training is  :: 0.3441016972064972 
2019-04-26 19:21:21,090  The global step train is 210
2019-04-26 19:21:21,214  The loss during training is  :: 0.23295456171035767 
2019-04-26 19:21:21,377  The global step train is 211
2019-04-26 19:21:21,499  The loss during training is  :: 0.2890353500843048 
2019-04-26 19:21:21,658  The global step train is 212
2019-04-26 19:21:21,782  The loss during training is  :: 0.33383551239967346 
2019-04-26 19:21:21,942  The global step train is 213
2019-04-26 19:21:22,068  The loss during training is  :: 0.18721060454845428 
2019-04-26 19:21:22,227  The global step train is 214
2019-04-26 19:21:22,352  The loss during training is  :: 0.28084278106689453 
2019-04-26 19:21:22,509  The global step train is 215
2019-04-26 19:21:22,635  The loss during training is  :: 0.19523264467716217 
2019-04-26 19:21:22,797  The global step train is 216
2019-04-26 19:21:22,924  The loss during training is  :: 0.22086867690086365 
2019-04-26 19:21:23,088  The global step train is 217
2019-04-26 19:21:23,221  The loss during training is  :: 0.1626233607530594 
2019-04-26 19:21:23,382  The global step train is 218
2019-04-26 19:21:23,510  The loss during training is  :: 0.14947229623794556 
2019-04-26 19:21:23,674  The global step train is 219
2019-04-26 19:21:23,800  The loss during training is  :: 0.21062450110912323 
2019-04-26 19:21:23,962  The global step train is 220
2019-04-26 19:21:24,085  The loss during training is  :: 0.18911181390285492 
2019-04-26 19:21:24,244  The global step train is 221
2019-04-26 19:21:24,370  The loss during training is  :: 0.18363003432750702 
2019-04-26 19:21:24,530  The global step train is 222
2019-04-26 19:21:24,656  The loss during training is  :: 0.17813603579998016 
2019-04-26 19:21:24,817  The global step train is 223
2019-04-26 19:21:24,944  The loss during training is  :: 0.20832906663417816 
2019-04-26 19:21:25,104  The global step train is 224
2019-04-26 19:21:25,106  Starting evaluation 
2019-04-26 19:21:25,233  The loss during eval_loss is  :: 0.24473437666893005
2019-04-26 19:21:25,235  The global step eval is 1
2019-04-26 19:21:25,356  The loss during eval_loss is  :: 0.19043241441249847
2019-04-26 19:21:25,358  The global step eval is 2
2019-04-26 19:21:25,460  The loss during eval_loss is  :: 0.16810905933380127
2019-04-26 19:21:25,462  The global step eval is 3
2019-04-26 19:21:25,569  The loss during eval_loss is  :: 0.22555045783519745
2019-04-26 19:21:25,570  The global step eval is 4
2019-04-26 19:21:25,680  The loss during eval_loss is  :: 0.20605073869228363
2019-04-26 19:21:25,682  The global step eval is 5
2019-04-26 19:21:25,789  The loss during eval_loss is  :: 0.26422545313835144
2019-04-26 19:21:25,791  The global step eval is 6
2019-04-26 19:21:25,895  The loss during eval_loss is  :: 0.2210233360528946
2019-04-26 19:21:25,897  The global step eval is 7
2019-04-26 19:21:26,010  The loss during eval_loss is  :: 0.15285730361938477
2019-04-26 19:21:26,011  The global step eval is 8
2019-04-26 19:21:26,112  The loss during eval_loss is  :: 0.2800882160663605
2019-04-26 19:21:26,114  The global step eval is 9
2019-04-26 19:21:26,213  The loss during eval_loss is  :: 0.17451056838035583
2019-04-26 19:21:26,216  The global step eval is 10
2019-04-26 19:21:26,318  The loss during eval_loss is  :: 0.17108668386936188
2019-04-26 19:21:26,320  The global step eval is 11
2019-04-26 19:21:26,423  The loss during eval_loss is  :: 0.20704622566699982
2019-04-26 19:21:26,424  The global step eval is 12
2019-04-26 19:21:26,528  The loss during eval_loss is  :: 0.14975181221961975
2019-04-26 19:21:26,530  The global step eval is 13
2019-04-26 19:21:26,636  The loss during eval_loss is  :: 0.20917315781116486
2019-04-26 19:21:26,638  The global step eval is 14
2019-04-26 19:21:26,747  The loss during eval_loss is  :: 0.2664268910884857
2019-04-26 19:21:26,749  The global step eval is 15
2019-04-26 19:21:26,866  The loss during eval_loss is  :: 0.240786612033844
2019-04-26 19:21:26,868  The global step eval is 16
2019-04-26 19:21:26,977  The loss during eval_loss is  :: 0.19947928190231323
2019-04-26 19:21:26,979  The global step eval is 17
2019-04-26 19:21:27,076  The loss during eval_loss is  :: 0.300210565328598
2019-04-26 19:21:27,078  The global step eval is 18
2019-04-26 19:21:27,179  The loss during eval_loss is  :: 0.21203488111495972
2019-04-26 19:21:27,181  The global step eval is 19
2019-04-26 19:21:27,289  The loss during eval_loss is  :: 0.19664786756038666
2019-04-26 19:21:27,291  The global step eval is 20
2019-04-26 19:21:27,409  The loss during eval_loss is  :: 0.25213152170181274
2019-04-26 19:21:27,411  The global step eval is 21
2019-04-26 19:21:27,526  The loss during eval_loss is  :: 0.20444534718990326
2019-04-26 19:21:27,528  The global step eval is 22
2019-04-26 19:21:27,644  The loss during eval_loss is  :: 0.14586296677589417
2019-04-26 19:21:27,646  The global step eval is 23
2019-04-26 19:21:27,746  The loss during eval_loss is  :: 0.19854645431041718
2019-04-26 19:21:27,747  The global step eval is 24
2019-04-26 19:21:27,860  The loss during eval_loss is  :: 0.15064501762390137
2019-04-26 19:21:27,862  The global step eval is 25
2019-04-26 19:21:27,965  The loss during eval_loss is  :: 0.23128585517406464
2019-04-26 19:21:27,966  The global step eval is 26
2019-04-26 19:21:28,067  The loss during eval_loss is  :: 0.22287432849407196
2019-04-26 19:21:28,069  The global step eval is 27
2019-04-26 19:21:28,178  The loss during eval_loss is  :: 0.2067408263683319
2019-04-26 19:21:28,180  The global step eval is 28
2019-04-26 19:21:28,289  The loss during eval_loss is  :: 0.2028013914823532
2019-04-26 19:21:28,291  The global step eval is 29
2019-04-26 19:21:28,404  The loss during eval_loss is  :: 0.17975857853889465
2019-04-26 19:21:28,406  The global step eval is 30
2019-04-26 19:21:28,508  The loss during eval_loss is  :: 0.1791704297065735
2019-04-26 19:21:28,510  The global step eval is 31
2019-04-26 19:21:28,614  The loss during eval_loss is  :: 0.30227401852607727
2019-04-26 19:21:28,616  The global step eval is 32
2019-04-26 19:21:28,720  The loss during eval_loss is  :: 0.23335517942905426
2019-04-26 19:21:28,722  The global step eval is 33
2019-04-26 19:21:28,835  The loss during eval_loss is  :: 0.2610187530517578
2019-04-26 19:21:28,837  The global step eval is 34
2019-04-26 19:21:28,942  The loss during eval_loss is  :: 0.20873525738716125
2019-04-26 19:21:28,944  The global step eval is 35
2019-04-26 19:21:29,056  The loss during eval_loss is  :: 0.18251703679561615
2019-04-26 19:21:29,058  The global step eval is 36
2019-04-26 19:21:29,169  The loss during eval_loss is  :: 0.31576135754585266
2019-04-26 19:21:29,171  The global step eval is 37
2019-04-26 19:21:29,283  The loss during eval_loss is  :: 0.1706233024597168
2019-04-26 19:21:29,286  The global step eval is 38
2019-04-26 19:21:29,394  The loss during eval_loss is  :: 0.17968443036079407
2019-04-26 19:21:29,396  The global step eval is 39
2019-04-26 19:21:29,498  The loss during eval_loss is  :: 0.19684924185276031
2019-04-26 19:21:29,500  The global step eval is 40
2019-04-26 19:21:29,600  The loss during eval_loss is  :: 0.20185768604278564
2019-04-26 19:21:29,602  The global step eval is 41
2019-04-26 19:21:29,711  The loss during eval_loss is  :: 0.1492544561624527
2019-04-26 19:21:29,713  The global step eval is 42
2019-04-26 19:21:29,813  The loss during eval_loss is  :: 0.2999131679534912
2019-04-26 19:21:29,815  The global step eval is 43
2019-04-26 19:21:29,915  The loss during eval_loss is  :: 0.2110072374343872
2019-04-26 19:21:29,917  The global step eval is 44
2019-04-26 19:21:30,020  The loss during eval_loss is  :: 0.1869702786207199
2019-04-26 19:21:30,022  The global step eval is 45
2019-04-26 19:21:30,123  The loss during eval_loss is  :: 0.16961883008480072
2019-04-26 19:21:30,125  The global step eval is 46
2019-04-26 19:21:30,230  The loss during eval_loss is  :: 0.22658579051494598
2019-04-26 19:21:30,232  The global step eval is 47
2019-04-26 19:21:30,339  The loss during eval_loss is  :: 0.23913685977458954
2019-04-26 19:21:30,341  The global step eval is 48
2019-04-26 19:21:30,446  The loss during eval_loss is  :: 0.18853919208049774
2019-04-26 19:21:30,448  The global step eval is 49
2019-04-26 19:21:30,549  The loss during eval_loss is  :: 0.31746596097946167
2019-04-26 19:21:30,551  The global step eval is 50
2019-04-26 19:21:30,654  The loss during eval_loss is  :: 0.1893135905265808
2019-04-26 19:21:30,656  The global step eval is 51
2019-04-26 19:21:30,765  The loss during eval_loss is  :: 0.265482097864151
2019-04-26 19:21:30,767  The global step eval is 52
2019-04-26 19:21:30,874  The loss during eval_loss is  :: 0.20548543334007263
2019-04-26 19:21:30,876  The global step eval is 53
2019-04-26 19:21:30,981  The loss during eval_loss is  :: 0.1766148954629898
2019-04-26 19:21:30,983  The global step eval is 54
2019-04-26 19:21:31,088  The loss during eval_loss is  :: 0.2010604292154312
2019-04-26 19:21:31,090  The global step eval is 55
2019-04-26 19:21:31,199  The loss during eval_loss is  :: 0.2182675451040268
2019-04-26 19:21:31,202  The global step eval is 56
2019-04-26 19:21:31,213  Saved checkpoint: ./trained_model\step_0.pth.tar
2019-04-26 19:21:31,218  New best checkpoint at step 0...
2019-04-26 19:21:31,316  The loss during training is  :: 0.2371262162923813 
2019-04-26 19:21:31,465  The global step train is 225
2019-04-26 19:21:31,590  The loss during training is  :: 0.18197953701019287 
2019-04-26 19:21:31,751  The global step train is 226
2019-04-26 19:21:31,879  The loss during training is  :: 0.2552706003189087 
2019-04-26 19:21:32,040  The global step train is 227
2019-04-26 19:21:32,168  The loss during training is  :: 0.16474859416484833 
2019-04-26 19:21:32,330  The global step train is 228
2019-04-26 19:21:32,453  The loss during training is  :: 0.20343585312366486 
2019-04-26 19:21:32,609  The global step train is 229
2019-04-26 19:21:32,738  The loss during training is  :: 0.20198430120944977 
2019-04-26 19:21:32,898  The global step train is 230
2019-04-26 19:21:33,019  The loss during training is  :: 0.16058889031410217 
2019-04-26 19:21:33,184  The global step train is 231
2019-04-26 19:21:33,308  The loss during training is  :: 0.12698888778686523 
2019-04-26 19:21:33,468  The global step train is 232
2019-04-26 19:21:33,592  The loss during training is  :: 0.15670146048069 
2019-04-26 19:21:33,755  The global step train is 233
2019-04-26 19:21:33,879  The loss during training is  :: 0.32668399810791016 
2019-04-26 19:21:34,036  The global step train is 234
2019-04-26 19:21:34,163  The loss during training is  :: 0.13995051383972168 
2019-04-26 19:21:34,327  The global step train is 235
2019-04-26 19:21:34,454  The loss during training is  :: 0.18647107481956482 
2019-04-26 19:21:34,614  The global step train is 236
2019-04-26 19:21:34,739  The loss during training is  :: 0.27136287093162537 
2019-04-26 19:21:34,896  The global step train is 237
2019-04-26 19:21:35,019  The loss during training is  :: 0.20959721505641937 
2019-04-26 19:21:35,180  The global step train is 238
2019-04-26 19:21:35,310  The loss during training is  :: 0.15111106634140015 
2019-04-26 19:21:35,471  The global step train is 239
2019-04-26 19:21:35,600  The loss during training is  :: 0.15473204851150513 
2019-04-26 19:21:35,763  The global step train is 240
2019-04-26 19:21:35,884  The loss during training is  :: 0.19917593896389008 
2019-04-26 19:21:36,042  The global step train is 241
2019-04-26 19:21:36,205  The loss during training is  :: 0.19190378487110138 
2019-04-26 19:21:36,374  The global step train is 242
2019-04-26 19:21:36,504  The loss during training is  :: 0.1878206580877304 
2019-04-26 19:21:36,665  The global step train is 243
2019-04-26 19:21:36,796  The loss during training is  :: 0.09707491844892502 
2019-04-26 19:21:36,957  The global step train is 244
2019-04-26 19:21:37,090  The loss during training is  :: 0.15893281996250153 
2019-04-26 19:21:37,253  The global step train is 245
2019-04-26 19:21:37,384  The loss during training is  :: 0.23362436890602112 
2019-04-26 19:21:37,544  The global step train is 246
2019-04-26 19:21:37,672  The loss during training is  :: 0.10671374201774597 
2019-04-26 19:21:37,833  The global step train is 247
2019-04-26 19:21:37,959  The loss during training is  :: 0.154536172747612 
2019-04-26 19:21:38,122  The global step train is 248
2019-04-26 19:21:38,247  The loss during training is  :: 0.20411217212677002 
2019-04-26 19:21:38,407  The global step train is 249
2019-04-26 19:21:38,533  The loss during training is  :: 0.14343924820423126 
2019-04-26 19:21:38,690  The global step train is 250
2019-04-26 19:21:38,817  The loss during training is  :: 0.19767822325229645 
2019-04-26 19:21:38,977  The global step train is 251
2019-04-26 19:21:39,104  The loss during training is  :: 0.22069326043128967 
2019-04-26 19:21:39,266  The global step train is 252
2019-04-26 19:21:39,393  The loss during training is  :: 0.14882728457450867 
2019-04-26 19:21:39,553  The global step train is 253
2019-04-26 19:21:39,679  The loss during training is  :: 0.17188526690006256 
2019-04-26 19:21:39,848  The global step train is 254
2019-04-26 19:21:39,972  The loss during training is  :: 0.17886196076869965 
2019-04-26 19:21:40,130  The global step train is 255
2019-04-26 19:21:40,264  The loss during training is  :: 0.17326343059539795 
2019-04-26 19:21:40,429  The global step train is 256
2019-04-26 19:21:40,559  The loss during training is  :: 0.2511957883834839 
2019-04-26 19:21:40,716  The global step train is 257
2019-04-26 19:21:40,839  The loss during training is  :: 0.14719969034194946 
2019-04-26 19:21:41,003  The global step train is 258
2019-04-26 19:21:41,132  The loss during training is  :: 0.14131362736225128 
2019-04-26 19:21:41,295  The global step train is 259
2019-04-26 19:21:41,438  The loss during training is  :: 0.14525775611400604 
2019-04-26 19:21:41,616  The global step train is 260
2019-04-26 19:21:41,759  The loss during training is  :: 0.18439288437366486 
2019-04-26 19:21:41,928  The global step train is 261
2019-04-26 19:21:42,058  The loss during training is  :: 0.17324930429458618 
2019-04-26 19:21:42,226  The global step train is 262
2019-04-26 19:21:42,357  The loss during training is  :: 0.08706560730934143 
2019-04-26 19:21:42,517  The global step train is 263
2019-04-26 19:21:42,645  The loss during training is  :: 0.11542575806379318 
2019-04-26 19:21:42,807  The global step train is 264
2019-04-26 19:21:42,931  The loss during training is  :: 0.16764307022094727 
2019-04-26 19:21:43,096  The global step train is 265
2019-04-26 19:21:43,223  The loss during training is  :: 0.119299978017807 
2019-04-26 19:21:43,387  The global step train is 266
2019-04-26 19:21:43,510  The loss during training is  :: 0.15397198498249054 
2019-04-26 19:21:43,666  The global step train is 267
2019-04-26 19:21:43,795  The loss during training is  :: 0.11605849862098694 
2019-04-26 19:21:43,948  The global step train is 268
2019-04-26 19:21:44,072  The loss during training is  :: 0.22603924572467804 
2019-04-26 19:21:44,233  The global step train is 269
2019-04-26 19:21:44,365  The loss during training is  :: 0.13279885053634644 
2019-04-26 19:21:44,530  The global step train is 270
2019-04-26 19:21:44,657  The loss during training is  :: 0.30871060490608215 
2019-04-26 19:21:44,826  The global step train is 271
2019-04-26 19:21:44,950  The loss during training is  :: 0.14589738845825195 
2019-04-26 19:21:45,110  The global step train is 272
2019-04-26 19:21:45,250  The loss during training is  :: 0.15320584177970886 
2019-04-26 19:21:45,421  The global step train is 273
2019-04-26 19:21:45,554  The loss during training is  :: 0.25154128670692444 
2019-04-26 19:21:45,718  The global step train is 274
2019-04-26 19:21:45,844  The loss during training is  :: 0.20685771107673645 
2019-04-26 19:21:45,997  The global step train is 275
2019-04-26 19:21:46,125  The loss during training is  :: 0.18219305574893951 
2019-04-26 19:21:46,293  The global step train is 276
2019-04-26 19:21:46,425  The loss during training is  :: 0.18091267347335815 
2019-04-26 19:21:46,587  The global step train is 277
2019-04-26 19:21:46,716  The loss during training is  :: 0.1356542408466339 
2019-04-26 19:21:46,877  The global step train is 278
2019-04-26 19:21:47,003  The loss during training is  :: 0.14337457716464996 
2019-04-26 19:21:47,162  The global step train is 279
2019-04-26 19:21:47,292  The loss during training is  :: 0.15553881227970123 
2019-04-26 19:21:47,453  The global step train is 280
2019-04-26 19:21:47,580  The loss during training is  :: 0.11056961119174957 
2019-04-26 19:21:47,739  The global step train is 281
2019-04-26 19:21:47,866  The loss during training is  :: 0.12624339759349823 
2019-04-26 19:21:48,026  The global step train is 282
2019-04-26 19:21:48,155  The loss during training is  :: 0.16981489956378937 
2019-04-26 19:21:48,316  The global step train is 283
2019-04-26 19:21:48,443  The loss during training is  :: 0.29042911529541016 
2019-04-26 19:21:48,597  The global step train is 284
2019-04-26 19:21:48,719  The loss during training is  :: 0.15815089643001556 
2019-04-26 19:21:48,881  The global step train is 285
2019-04-26 19:21:49,010  The loss during training is  :: 0.2828728258609772 
2019-04-26 19:21:49,169  The global step train is 286
2019-04-26 19:21:49,298  The loss during training is  :: 0.19438008964061737 
2019-04-26 19:21:49,455  The global step train is 287
2019-04-26 19:21:49,584  The loss during training is  :: 0.20862892270088196 
2019-04-26 19:21:49,741  The global step train is 288
2019-04-26 19:21:49,871  The loss during training is  :: 0.10527888685464859 
2019-04-26 19:21:50,028  The global step train is 289
2019-04-26 19:21:50,157  The loss during training is  :: 0.23910710215568542 
2019-04-26 19:21:50,326  The global step train is 290
2019-04-26 19:21:50,462  The loss during training is  :: 0.20350110530853271 
2019-04-26 19:21:50,620  The global step train is 291
2019-04-26 19:21:50,749  The loss during training is  :: 0.1205776110291481 
2019-04-26 19:21:50,907  The global step train is 292
2019-04-26 19:21:51,030  The loss during training is  :: 0.17279629409313202 
2019-04-26 19:21:51,194  The global step train is 293
2019-04-26 19:21:51,318  The loss during training is  :: 0.14274482429027557 
2019-04-26 19:21:51,475  The global step train is 294
2019-04-26 19:21:51,601  The loss during training is  :: 0.13444213569164276 
2019-04-26 19:21:51,761  The global step train is 295
2019-04-26 19:21:51,880  The loss during training is  :: 0.23208549618721008 
2019-04-26 19:21:52,042  The global step train is 296
2019-04-26 19:21:52,171  The loss during training is  :: 0.11701130867004395 
2019-04-26 19:21:52,333  The global step train is 297
2019-04-26 19:21:52,459  The loss during training is  :: 0.15065579116344452 
2019-04-26 19:21:52,614  The global step train is 298
2019-04-26 19:21:52,741  The loss during training is  :: 0.1825522929430008 
2019-04-26 19:21:52,902  The global step train is 299
2019-04-26 19:21:53,029  The loss during training is  :: 0.16353169083595276 
2019-04-26 19:21:53,186  The global step train is 300
2019-04-26 19:21:53,314  The loss during training is  :: 0.10841545462608337 
2019-04-26 19:21:53,473  The global step train is 301
2019-04-26 19:21:53,601  The loss during training is  :: 0.17063622176647186 
2019-04-26 19:21:53,763  The global step train is 302
2019-04-26 19:21:53,890  The loss during training is  :: 0.17715825140476227 
2019-04-26 19:21:54,049  The global step train is 303
2019-04-26 19:21:54,173  The loss during training is  :: 0.19275428354740143 
2019-04-26 19:21:54,334  The global step train is 304
2019-04-26 19:21:54,462  The loss during training is  :: 0.13973362743854523 
2019-04-26 19:21:54,621  The global step train is 305
2019-04-26 19:21:54,742  The loss during training is  :: 0.19550427794456482 
2019-04-26 19:21:54,899  The global step train is 306
2019-04-26 19:21:55,024  The loss during training is  :: 0.23795746266841888 
2019-04-26 19:21:55,181  The global step train is 307
2019-04-26 19:21:55,308  The loss during training is  :: 0.13383646309375763 
2019-04-26 19:21:55,469  The global step train is 308
2019-04-26 19:21:55,594  The loss during training is  :: 0.1641305685043335 
2019-04-26 19:21:55,755  The global step train is 309
2019-04-26 19:21:55,882  The loss during training is  :: 0.0781760886311531 
2019-04-26 19:21:56,042  The global step train is 310
2019-04-26 19:21:56,166  The loss during training is  :: 0.16617204248905182 
2019-04-26 19:21:56,329  The global step train is 311
2019-04-26 19:21:56,453  The loss during training is  :: 0.09356804192066193 
2019-04-26 19:21:56,612  The global step train is 312
2019-04-26 19:21:56,740  The loss during training is  :: 0.13697601854801178 
2019-04-26 19:21:56,903  The global step train is 313
2019-04-26 19:21:57,022  The loss during training is  :: 0.1268206536769867 
2019-04-26 19:21:57,183  The global step train is 314
2019-04-26 19:21:57,311  The loss during training is  :: 0.16005480289459229 
2019-04-26 19:21:57,469  The global step train is 315
2019-04-26 19:21:57,590  The loss during training is  :: 0.1333131343126297 
2019-04-26 19:21:57,751  The global step train is 316
2019-04-26 19:21:57,880  The loss during training is  :: 0.23104019463062286 
2019-04-26 19:21:58,043  The global step train is 317
2019-04-26 19:21:58,173  The loss during training is  :: 0.14889831840991974 
2019-04-26 19:21:58,332  The global step train is 318
2019-04-26 19:21:58,457  The loss during training is  :: 0.12709209322929382 
2019-04-26 19:21:58,626  The global step train is 319
2019-04-26 19:21:58,749  The loss during training is  :: 0.12590189278125763 
2019-04-26 19:21:58,920  The global step train is 320
2019-04-26 19:21:59,046  The loss during training is  :: 0.22094939649105072 
2019-04-26 19:21:59,202  The global step train is 321
2019-04-26 19:21:59,330  The loss during training is  :: 0.21342238783836365 
2019-04-26 19:21:59,491  The global step train is 322
2019-04-26 19:21:59,617  The loss during training is  :: 0.22625839710235596 
2019-04-26 19:21:59,780  The global step train is 323
2019-04-26 19:21:59,902  The loss during training is  :: 0.17036780714988708 
2019-04-26 19:22:00,060  The global step train is 324
2019-04-26 19:22:00,182  The loss during training is  :: 0.1927713304758072 
2019-04-26 19:22:00,343  The global step train is 325
2019-04-26 19:22:00,471  The loss during training is  :: 0.22801531851291656 
2019-04-26 19:22:00,634  The global step train is 326
2019-04-26 19:22:00,761  The loss during training is  :: 0.16764648258686066 
2019-04-26 19:22:00,922  The global step train is 327
2019-04-26 19:22:01,051  The loss during training is  :: 0.15509487688541412 
2019-04-26 19:22:01,215  The global step train is 328
2019-04-26 19:22:01,345  The loss during training is  :: 0.18169675767421722 
2019-04-26 19:22:01,501  The global step train is 329
2019-04-26 19:22:01,628  The loss during training is  :: 0.15741345286369324 
2019-04-26 19:22:01,789  The global step train is 330
2019-04-26 19:22:01,987  The loss during training is  :: 0.15893307328224182 
2019-04-26 19:22:02,140  The global step train is 331
2019-04-26 19:22:02,263  The loss during training is  :: 0.10053642094135284 
2019-04-26 19:22:02,424  The global step train is 332
2019-04-26 19:22:02,549  The loss during training is  :: 0.187252476811409 
2019-04-26 19:22:02,706  The global step train is 333
2019-04-26 19:22:02,834  The loss during training is  :: 0.2064996212720871 
2019-04-26 19:22:02,991  The global step train is 334
2019-04-26 19:22:03,119  The loss during training is  :: 0.22135385870933533 
2019-04-26 19:22:03,281  The global step train is 335
2019-04-26 19:22:03,407  The loss during training is  :: 0.1320001482963562 
2019-04-26 19:22:03,565  The global step train is 336
2019-04-26 19:22:03,691  The loss during training is  :: 0.14525018632411957 
2019-04-26 19:22:03,847  The global step train is 337
2019-04-26 19:22:03,971  The loss during training is  :: 0.08536045253276825 
2019-04-26 19:22:04,132  The global step train is 338
2019-04-26 19:22:04,258  The loss during training is  :: 0.11832127720117569 
2019-04-26 19:22:04,419  The global step train is 339
2019-04-26 19:22:04,546  The loss during training is  :: 0.10777600854635239 
2019-04-26 19:22:04,710  The global step train is 340
2019-04-26 19:22:04,829  The loss during training is  :: 0.10701406747102737 
2019-04-26 19:22:04,986  The global step train is 341
2019-04-26 19:22:05,116  The loss during training is  :: 0.12327593564987183 
2019-04-26 19:22:05,277  The global step train is 342
2019-04-26 19:22:05,411  The loss during training is  :: 0.15941086411476135 
2019-04-26 19:22:05,573  The global step train is 343
2019-04-26 19:22:05,704  The loss during training is  :: 0.05757114291191101 
2019-04-26 19:22:05,869  The global step train is 344
2019-04-26 19:22:05,994  The loss during training is  :: 0.10015890747308731 
2019-04-26 19:22:06,154  The global step train is 345
2019-04-26 19:22:06,285  The loss during training is  :: 0.10270136594772339 
2019-04-26 19:22:06,449  The global step train is 346
2019-04-26 19:22:06,575  The loss during training is  :: 0.13771140575408936 
2019-04-26 19:22:06,733  The global step train is 347
2019-04-26 19:22:06,856  The loss during training is  :: 0.08876210451126099 
2019-04-26 19:22:07,018  The global step train is 348
2019-04-26 19:22:07,146  The loss during training is  :: 0.11476331204175949 
2019-04-26 19:22:07,306  The global step train is 349
2019-04-26 19:22:07,430  The loss during training is  :: 0.11140567809343338 
2019-04-26 19:22:07,589  The global step train is 350
2019-04-26 19:22:07,717  The loss during training is  :: 0.1986125111579895 
2019-04-26 19:22:07,878  The global step train is 351
2019-04-26 19:22:08,005  The loss during training is  :: 0.09952584654092789 
2019-04-26 19:22:08,159  The global step train is 352
2019-04-26 19:22:08,286  The loss during training is  :: 0.14929169416427612 
2019-04-26 19:22:08,444  The global step train is 353
2019-04-26 19:22:08,568  The loss during training is  :: 0.10510217398405075 
2019-04-26 19:22:08,730  The global step train is 354
2019-04-26 19:22:08,854  The loss during training is  :: 0.18937982618808746 
2019-04-26 19:22:09,010  The global step train is 355
2019-04-26 19:22:09,139  The loss during training is  :: 0.15863941609859467 
2019-04-26 19:22:09,299  The global step train is 356
2019-04-26 19:22:09,426  The loss during training is  :: 0.07224640995264053 
2019-04-26 19:22:09,582  The global step train is 357
2019-04-26 19:22:09,705  The loss during training is  :: 0.09576641768217087 
2019-04-26 19:22:09,864  The global step train is 358
2019-04-26 19:22:09,989  The loss during training is  :: 0.1554306000471115 
2019-04-26 19:22:10,152  The global step train is 359
2019-04-26 19:22:10,275  The loss during training is  :: 0.1462903916835785 
2019-04-26 19:22:10,435  The global step train is 360
2019-04-26 19:22:10,562  The loss during training is  :: 0.11438679695129395 
2019-04-26 19:22:10,723  The global step train is 361
2019-04-26 19:22:10,846  The loss during training is  :: 0.11111077666282654 
2019-04-26 19:22:11,009  The global step train is 362
2019-04-26 19:22:11,133  The loss during training is  :: 0.13257355988025665 
2019-04-26 19:22:11,294  The global step train is 363
2019-04-26 19:22:11,419  The loss during training is  :: 0.11288481205701828 
2019-04-26 19:22:11,582  The global step train is 364
2019-04-26 19:22:11,707  The loss during training is  :: 0.18914538621902466 
2019-04-26 19:22:11,865  The global step train is 365
2019-04-26 19:22:11,991  The loss during training is  :: 0.17075912654399872 
2019-04-26 19:22:12,155  The global step train is 366
2019-04-26 19:22:12,281  The loss during training is  :: 0.13947857916355133 
2019-04-26 19:22:12,438  The global step train is 367
2019-04-26 19:22:12,569  The loss during training is  :: 0.08675660192966461 
2019-04-26 19:22:12,738  The global step train is 368
2019-04-26 19:22:12,870  The loss during training is  :: 0.22138062119483948 
2019-04-26 19:22:13,032  The global step train is 369
2019-04-26 19:22:13,157  The loss during training is  :: 0.17725011706352234 
2019-04-26 19:22:13,322  The global step train is 370
2019-04-26 19:22:13,448  The loss during training is  :: 0.1032823771238327 
2019-04-26 19:22:13,606  The global step train is 371
2019-04-26 19:22:13,732  The loss during training is  :: 0.11875656247138977 
2019-04-26 19:22:13,891  The global step train is 372
2019-04-26 19:22:14,018  The loss during training is  :: 0.2572499215602875 
2019-04-26 19:22:14,178  The global step train is 373
2019-04-26 19:22:14,306  The loss during training is  :: 0.07678355276584625 
2019-04-26 19:22:14,462  The global step train is 374
2019-04-26 19:22:14,586  The loss during training is  :: 0.2008771300315857 
2019-04-26 19:22:14,745  The global step train is 375
2019-04-26 19:22:14,868  The loss during training is  :: 0.18607981503009796 
2019-04-26 19:22:15,027  The global step train is 376
2019-04-26 19:22:15,161  The loss during training is  :: 0.0932631716132164 
2019-04-26 19:22:15,319  The global step train is 377
2019-04-26 19:22:15,445  The loss during training is  :: 0.10739149898290634 
2019-04-26 19:22:15,597  The global step train is 378
2019-04-26 19:22:15,726  The loss during training is  :: 0.13352684676647186 
2019-04-26 19:22:15,884  The global step train is 379
2019-04-26 19:22:16,011  The loss during training is  :: 0.05738476291298866 
2019-04-26 19:22:16,174  The global step train is 380
2019-04-26 19:22:16,302  The loss during training is  :: 0.1414565145969391 
2019-04-26 19:22:16,454  The global step train is 381
2019-04-26 19:22:16,582  The loss during training is  :: 0.11958994716405869 
2019-04-26 19:22:16,739  The global step train is 382
2019-04-26 19:22:16,867  The loss during training is  :: 0.15867595374584198 
2019-04-26 19:22:17,026  The global step train is 383
2019-04-26 19:22:17,151  The loss during training is  :: 0.19814638793468475 
2019-04-26 19:22:17,327  The global step train is 384
2019-04-26 19:22:17,457  The loss during training is  :: 0.15598322451114655 
2019-04-26 19:22:17,611  The global step train is 385
2019-04-26 19:22:17,739  The loss during training is  :: 0.12126296758651733 
2019-04-26 19:22:17,900  The global step train is 386
2019-04-26 19:22:18,025  The loss during training is  :: 0.1467582881450653 
2019-04-26 19:22:18,184  The global step train is 387
2019-04-26 19:22:18,309  The loss during training is  :: 0.21617619693279266 
2019-04-26 19:22:18,471  The global step train is 388
2019-04-26 19:22:18,594  The loss during training is  :: 0.10223488509654999 
2019-04-26 19:22:18,753  The global step train is 389
2019-04-26 19:22:18,880  The loss during training is  :: 0.08911976218223572 
2019-04-26 19:22:19,040  The global step train is 390
2019-04-26 19:22:19,172  The loss during training is  :: 0.09229612350463867 
2019-04-26 19:22:19,334  The global step train is 391
2019-04-26 19:22:19,461  The loss during training is  :: 0.15017245709896088 
2019-04-26 19:22:19,616  The global step train is 392
2019-04-26 19:22:19,743  The loss during training is  :: 0.12704072892665863 
2019-04-26 19:22:19,906  The global step train is 393
2019-04-26 19:22:20,032  The loss during training is  :: 0.11825408786535263 
2019-04-26 19:22:20,190  The global step train is 394
2019-04-26 19:22:20,318  The loss during training is  :: 0.1446201503276825 
2019-04-26 19:22:20,480  The global step train is 395
2019-04-26 19:22:20,603  The loss during training is  :: 0.23476755619049072 
2019-04-26 19:22:20,765  The global step train is 396
2019-04-26 19:22:20,891  The loss during training is  :: 0.09679939597845078 
2019-04-26 19:22:21,053  The global step train is 397
2019-04-26 19:22:21,186  The loss during training is  :: 0.13414213061332703 
2019-04-26 19:22:21,349  The global step train is 398
2019-04-26 19:22:21,477  The loss during training is  :: 0.15996496379375458 
2019-04-26 19:22:21,631  The global step train is 399
2019-04-26 19:22:21,757  The loss during training is  :: 0.13658109307289124 
2019-04-26 19:22:21,919  The global step train is 400
2019-04-26 19:22:22,041  The loss during training is  :: 0.07272308319807053 
2019-04-26 19:22:22,199  The global step train is 401
2019-04-26 19:22:22,328  The loss during training is  :: 0.12581034004688263 
2019-04-26 19:22:22,484  The global step train is 402
2019-04-26 19:22:22,609  The loss during training is  :: 0.11816294491291046 
2019-04-26 19:22:22,768  The global step train is 403
2019-04-26 19:22:22,897  The loss during training is  :: 0.09261386841535568 
2019-04-26 19:22:23,060  The global step train is 404
2019-04-26 19:22:23,185  The loss during training is  :: 0.08154229074716568 
2019-04-26 19:22:23,344  The global step train is 405
2019-04-26 19:22:23,471  The loss during training is  :: 0.206647589802742 
2019-04-26 19:22:23,633  The global step train is 406
2019-04-26 19:22:23,756  The loss during training is  :: 0.13666556775569916 
2019-04-26 19:22:23,913  The global step train is 407
2019-04-26 19:22:24,040  The loss during training is  :: 0.1574791669845581 
2019-04-26 19:22:24,203  The global step train is 408
2019-04-26 19:22:24,332  The loss during training is  :: 0.13430428504943848 
2019-04-26 19:22:24,491  The global step train is 409
2019-04-26 19:22:24,614  The loss during training is  :: 0.12613029778003693 
2019-04-26 19:22:24,778  The global step train is 410
2019-04-26 19:22:24,904  The loss during training is  :: 0.08137959986925125 
2019-04-26 19:22:25,065  The global step train is 411
2019-04-26 19:22:25,192  The loss during training is  :: 0.10248292982578278 
2019-04-26 19:22:25,349  The global step train is 412
2019-04-26 19:22:25,473  The loss during training is  :: 0.09731371700763702 
2019-04-26 19:22:25,631  The global step train is 413
2019-04-26 19:22:25,758  The loss during training is  :: 0.1086302176117897 
2019-04-26 19:22:25,925  The global step train is 414
2019-04-26 19:22:26,053  The loss during training is  :: 0.14391762018203735 
2019-04-26 19:22:26,208  The global step train is 415
2019-04-26 19:22:26,337  The loss during training is  :: 0.20659710466861725 
2019-04-26 19:22:26,499  The global step train is 416
2019-04-26 19:22:26,627  The loss during training is  :: 0.13399851322174072 
2019-04-26 19:22:26,787  The global step train is 417
2019-04-26 19:22:26,912  The loss during training is  :: 0.14701509475708008 
2019-04-26 19:22:27,074  The global step train is 418
2019-04-26 19:22:27,204  The loss during training is  :: 0.10112278163433075 
2019-04-26 19:22:27,370  The global step train is 419
2019-04-26 19:22:27,494  The loss during training is  :: 0.17751513421535492 
2019-04-26 19:22:27,654  The global step train is 420
2019-04-26 19:22:27,784  The loss during training is  :: 0.12791696190834045 
2019-04-26 19:22:27,945  The global step train is 421
2019-04-26 19:22:28,072  The loss during training is  :: 0.13023340702056885 
2019-04-26 19:22:28,234  The global step train is 422
2019-04-26 19:22:28,361  The loss during training is  :: 0.1552540510892868 
2019-04-26 19:22:28,523  The global step train is 423
2019-04-26 19:22:28,647  The loss during training is  :: 0.05484338849782944 
2019-04-26 19:22:28,801  The global step train is 424
2019-04-26 19:22:28,929  The loss during training is  :: 0.09105131030082703 
2019-04-26 19:22:29,087  The global step train is 425
2019-04-26 19:22:29,218  The loss during training is  :: 0.16072283685207367 
2019-04-26 19:22:29,379  The global step train is 426
2019-04-26 19:22:29,504  The loss during training is  :: 0.11502762138843536 
2019-04-26 19:22:29,666  The global step train is 427
2019-04-26 19:22:29,792  The loss during training is  :: 0.08007101714611053 
2019-04-26 19:22:29,948  The global step train is 428
2019-04-26 19:22:30,074  The loss during training is  :: 0.15165767073631287 
2019-04-26 19:22:30,227  The global step train is 429
2019-04-26 19:22:30,349  The loss during training is  :: 0.11761195212602615 
2019-04-26 19:22:30,507  The global step train is 430
2019-04-26 19:22:30,633  The loss during training is  :: 0.12633994221687317 
2019-04-26 19:22:30,794  The global step train is 431
2019-04-26 19:22:30,917  The loss during training is  :: 0.09149032086133957 
2019-04-26 19:22:31,077  The global step train is 432
2019-04-26 19:22:31,208  The loss during training is  :: 0.15456387400627136 
2019-04-26 19:22:31,370  The global step train is 433
2019-04-26 19:22:31,498  The loss during training is  :: 0.14130577445030212 
2019-04-26 19:22:31,658  The global step train is 434
2019-04-26 19:22:31,782  The loss during training is  :: 0.09919232875108719 
2019-04-26 19:22:31,942  The global step train is 435
2019-04-26 19:22:32,071  The loss during training is  :: 0.1239098384976387 
2019-04-26 19:22:32,234  The global step train is 436
2019-04-26 19:22:32,362  The loss during training is  :: 0.11494481563568115 
2019-04-26 19:22:32,519  The global step train is 437
2019-04-26 19:22:32,649  The loss during training is  :: 0.19309069216251373 
2019-04-26 19:22:32,813  The global step train is 438
2019-04-26 19:22:32,943  The loss during training is  :: 0.1613093912601471 
2019-04-26 19:22:33,106  The global step train is 439
2019-04-26 19:22:33,234  The loss during training is  :: 0.14562870562076569 
2019-04-26 19:22:33,396  The global step train is 440
2019-04-26 19:22:33,522  The loss during training is  :: 0.13779239356517792 
2019-04-26 19:22:33,680  The global step train is 441
2019-04-26 19:22:33,809  The loss during training is  :: 0.09958700090646744 
2019-04-26 19:22:33,964  The global step train is 442
2019-04-26 19:22:34,094  The loss during training is  :: 0.07554981112480164 
2019-04-26 19:22:34,266  The global step train is 443
2019-04-26 19:22:34,396  The loss during training is  :: 0.17784136533737183 
2019-04-26 19:22:34,559  The global step train is 444
2019-04-26 19:22:34,687  The loss during training is  :: 0.11102671176195145 
2019-04-26 19:22:34,859  The global step train is 445
2019-04-26 19:22:34,982  The loss during training is  :: 0.20555268228054047 
2019-04-26 19:22:35,142  The global step train is 446
2019-04-26 19:22:35,276  The loss during training is  :: 0.19348618388175964 
2019-04-26 19:22:35,433  The global step train is 447
2019-04-26 19:22:35,559  The loss during training is  :: 0.09944982081651688 
2019-04-26 19:22:35,723  The global step train is 448
2019-04-26 19:22:35,725  Starting evaluation 
2019-04-26 19:22:35,860  The loss during eval_loss is  :: 0.18173202872276306
2019-04-26 19:22:35,863  The global step eval is 57
2019-04-26 19:22:35,987  The loss during eval_loss is  :: 0.10120082646608353
2019-04-26 19:22:35,989  The global step eval is 58
2019-04-26 19:22:36,104  The loss during eval_loss is  :: 0.10070047527551651
2019-04-26 19:22:36,106  The global step eval is 59
2019-04-26 19:22:36,217  The loss during eval_loss is  :: 0.09782364964485168
2019-04-26 19:22:36,219  The global step eval is 60
2019-04-26 19:22:36,327  The loss during eval_loss is  :: 0.10814224183559418
2019-04-26 19:22:36,329  The global step eval is 61
2019-04-26 19:22:36,437  The loss during eval_loss is  :: 0.1716727912425995
2019-04-26 19:22:36,439  The global step eval is 62
2019-04-26 19:22:36,551  The loss during eval_loss is  :: 0.1930479109287262
2019-04-26 19:22:36,552  The global step eval is 63
2019-04-26 19:22:36,657  The loss during eval_loss is  :: 0.07259340584278107
2019-04-26 19:22:36,659  The global step eval is 64
2019-04-26 19:22:36,767  The loss during eval_loss is  :: 0.15866388380527496
2019-04-26 19:22:36,769  The global step eval is 65
2019-04-26 19:22:36,881  The loss during eval_loss is  :: 0.09189555794000626
2019-04-26 19:22:36,883  The global step eval is 66
2019-04-26 19:22:36,993  The loss during eval_loss is  :: 0.12569905817508698
2019-04-26 19:22:36,995  The global step eval is 67
2019-04-26 19:22:37,108  The loss during eval_loss is  :: 0.0777537077665329
2019-04-26 19:22:37,109  The global step eval is 68
2019-04-26 19:22:37,214  The loss during eval_loss is  :: 0.08301673084497452
2019-04-26 19:22:37,216  The global step eval is 69
2019-04-26 19:22:37,322  The loss during eval_loss is  :: 0.08280503004789352
2019-04-26 19:22:37,324  The global step eval is 70
2019-04-26 19:22:37,433  The loss during eval_loss is  :: 0.15059536695480347
2019-04-26 19:22:37,435  The global step eval is 71
2019-04-26 19:22:37,552  The loss during eval_loss is  :: 0.14990222454071045
2019-04-26 19:22:37,553  The global step eval is 72
2019-04-26 19:22:37,663  The loss during eval_loss is  :: 0.1479490101337433
2019-04-26 19:22:37,665  The global step eval is 73
2019-04-26 19:22:37,767  The loss during eval_loss is  :: 0.1777358502149582
2019-04-26 19:22:37,769  The global step eval is 74
2019-04-26 19:22:37,877  The loss during eval_loss is  :: 0.11144629120826721
2019-04-26 19:22:37,879  The global step eval is 75
2019-04-26 19:22:37,996  The loss during eval_loss is  :: 0.12857818603515625
2019-04-26 19:22:37,998  The global step eval is 76
2019-04-26 19:22:38,113  The loss during eval_loss is  :: 0.14477688074111938
2019-04-26 19:22:38,114  The global step eval is 77
2019-04-26 19:22:38,221  The loss during eval_loss is  :: 0.11312596499919891
2019-04-26 19:22:38,223  The global step eval is 78
2019-04-26 19:22:38,335  The loss during eval_loss is  :: 0.07240656763315201
2019-04-26 19:22:38,337  The global step eval is 79
2019-04-26 19:22:38,439  The loss during eval_loss is  :: 0.09249243140220642
2019-04-26 19:22:38,441  The global step eval is 80
2019-04-26 19:22:38,544  The loss during eval_loss is  :: 0.06769624352455139
2019-04-26 19:22:38,545  The global step eval is 81
2019-04-26 19:22:38,647  The loss during eval_loss is  :: 0.14252673089504242
2019-04-26 19:22:38,649  The global step eval is 82
2019-04-26 19:22:38,756  The loss during eval_loss is  :: 0.1207410916686058
2019-04-26 19:22:38,758  The global step eval is 83
2019-04-26 19:22:38,873  The loss during eval_loss is  :: 0.1490427851676941
2019-04-26 19:22:38,875  The global step eval is 84
2019-04-26 19:22:38,986  The loss during eval_loss is  :: 0.11614339053630829
2019-04-26 19:22:38,989  The global step eval is 85
2019-04-26 19:22:39,098  The loss during eval_loss is  :: 0.0926070287823677
2019-04-26 19:22:39,100  The global step eval is 86
2019-04-26 19:22:39,209  The loss during eval_loss is  :: 0.09773421287536621
2019-04-26 19:22:39,211  The global step eval is 87
2019-04-26 19:22:39,327  The loss during eval_loss is  :: 0.18317434191703796
2019-04-26 19:22:39,329  The global step eval is 88
2019-04-26 19:22:39,434  The loss during eval_loss is  :: 0.147653728723526
2019-04-26 19:22:39,436  The global step eval is 89
2019-04-26 19:22:39,556  The loss during eval_loss is  :: 0.1741706132888794
2019-04-26 19:22:39,557  The global step eval is 90
2019-04-26 19:22:39,663  The loss during eval_loss is  :: 0.09295851737260818
2019-04-26 19:22:39,665  The global step eval is 91
2019-04-26 19:22:39,775  The loss during eval_loss is  :: 0.12170372158288956
2019-04-26 19:22:39,776  The global step eval is 92
2019-04-26 19:22:39,887  The loss during eval_loss is  :: 0.1604028344154358
2019-04-26 19:22:39,889  The global step eval is 93
2019-04-26 19:22:39,995  The loss during eval_loss is  :: 0.08707340061664581
2019-04-26 19:22:39,997  The global step eval is 94
2019-04-26 19:22:40,099  The loss during eval_loss is  :: 0.07522113621234894
2019-04-26 19:22:40,101  The global step eval is 95
2019-04-26 19:22:40,216  The loss during eval_loss is  :: 0.08263928443193436
2019-04-26 19:22:40,217  The global step eval is 96
2019-04-26 19:22:40,337  The loss during eval_loss is  :: 0.08591315150260925
2019-04-26 19:22:40,339  The global step eval is 97
2019-04-26 19:22:40,439  The loss during eval_loss is  :: 0.06457681953907013
2019-04-26 19:22:40,441  The global step eval is 98
2019-04-26 19:22:40,550  The loss during eval_loss is  :: 0.15359926223754883
2019-04-26 19:22:40,552  The global step eval is 99
2019-04-26 19:22:40,659  The loss during eval_loss is  :: 0.09296627342700958
2019-04-26 19:22:40,661  The global step eval is 100
2019-04-26 19:22:40,765  The loss during eval_loss is  :: 0.14817097783088684
2019-04-26 19:22:40,767  The global step eval is 101
2019-04-26 19:22:40,875  The loss during eval_loss is  :: 0.10225321352481842
2019-04-26 19:22:40,877  The global step eval is 102
2019-04-26 19:22:40,978  The loss during eval_loss is  :: 0.16419504582881927
2019-04-26 19:22:40,979  The global step eval is 103
2019-04-26 19:22:41,083  The loss during eval_loss is  :: 0.1912183314561844
2019-04-26 19:22:41,085  The global step eval is 104
2019-04-26 19:22:41,196  The loss during eval_loss is  :: 0.07442113012075424
2019-04-26 19:22:41,198  The global step eval is 105
2019-04-26 19:22:41,318  The loss during eval_loss is  :: 0.2244432121515274
2019-04-26 19:22:41,320  The global step eval is 106
2019-04-26 19:22:41,430  The loss during eval_loss is  :: 0.11414850503206253
2019-04-26 19:22:41,431  The global step eval is 107
2019-04-26 19:22:41,546  The loss during eval_loss is  :: 0.14209093153476715
2019-04-26 19:22:41,548  The global step eval is 108
2019-04-26 19:22:41,655  The loss during eval_loss is  :: 0.11584510654211044
2019-04-26 19:22:41,657  The global step eval is 109
2019-04-26 19:22:41,767  The loss during eval_loss is  :: 0.07238951325416565
2019-04-26 19:22:41,769  The global step eval is 110
2019-04-26 19:22:41,872  The loss during eval_loss is  :: 0.12263406068086624
2019-04-26 19:22:41,874  The global step eval is 111
2019-04-26 19:22:41,982  The loss during eval_loss is  :: 0.11797042936086655
2019-04-26 19:22:41,984  The global step eval is 112
2019-04-26 19:22:41,996  Saved checkpoint: ./trained_model\step_1.pth.tar
2019-04-26 19:22:42,103  The loss during training is  :: 0.14485414326190948 
2019-04-26 19:22:42,259  The global step train is 449
2019-04-26 19:22:42,381  The loss during training is  :: 0.07917667925357819 
2019-04-26 19:22:42,542  The global step train is 450
2019-04-26 19:22:42,673  The loss during training is  :: 0.1564093977212906 
2019-04-26 19:22:42,834  The global step train is 451
2019-04-26 19:22:42,964  The loss during training is  :: 0.1329595297574997 
2019-04-26 19:22:43,123  The global step train is 452
2019-04-26 19:22:43,254  The loss during training is  :: 0.09602910280227661 
2019-04-26 19:22:43,416  The global step train is 453
2019-04-26 19:22:43,542  The loss during training is  :: 0.08554178476333618 
2019-04-26 19:22:43,697  The global step train is 454
2019-04-26 19:22:43,824  The loss during training is  :: 0.11036092042922974 
2019-04-26 19:22:43,979  The global step train is 455
2019-04-26 19:22:44,104  The loss during training is  :: 0.12838399410247803 
2019-04-26 19:22:44,265  The global step train is 456
2019-04-26 19:22:44,393  The loss during training is  :: 0.12721140682697296 
2019-04-26 19:22:44,556  The global step train is 457
2019-04-26 19:22:44,688  The loss during training is  :: 0.07567436248064041 
2019-04-26 19:22:44,841  The global step train is 458
2019-04-26 19:22:44,968  The loss during training is  :: 0.10925445705652237 
2019-04-26 19:22:45,130  The global step train is 459
2019-04-26 19:22:45,258  The loss during training is  :: 0.1859084516763687 
2019-04-26 19:22:45,417  The global step train is 460
2019-04-26 19:22:45,541  The loss during training is  :: 0.08826940506696701 
2019-04-26 19:22:45,702  The global step train is 461
2019-04-26 19:22:45,827  The loss during training is  :: 0.1141081228852272 
2019-04-26 19:22:45,984  The global step train is 462
2019-04-26 19:22:46,117  The loss during training is  :: 0.20710371434688568 
2019-04-26 19:22:46,280  The global step train is 463
2019-04-26 19:22:46,407  The loss during training is  :: 0.11500738561153412 
2019-04-26 19:22:46,567  The global step train is 464
2019-04-26 19:22:46,688  The loss during training is  :: 0.1078190878033638 
2019-04-26 19:22:46,849  The global step train is 465
2019-04-26 19:22:46,977  The loss during training is  :: 0.14825056493282318 
2019-04-26 19:22:47,134  The global step train is 466
2019-04-26 19:22:47,257  The loss during training is  :: 0.08906003832817078 
2019-04-26 19:22:47,417  The global step train is 467
2019-04-26 19:22:47,547  The loss during training is  :: 0.1261628121137619 
2019-04-26 19:22:47,705  The global step train is 468
2019-04-26 19:22:47,829  The loss during training is  :: 0.08157370239496231 
2019-04-26 19:22:47,992  The global step train is 469
2019-04-26 19:22:48,119  The loss during training is  :: 0.1100463718175888 
2019-04-26 19:22:48,278  The global step train is 470
2019-04-26 19:22:48,403  The loss during training is  :: 0.15737338364124298 
2019-04-26 19:22:48,565  The global step train is 471
2019-04-26 19:22:48,692  The loss during training is  :: 0.043336499482393265 
2019-04-26 19:22:48,854  The global step train is 472
2019-04-26 19:22:48,983  The loss during training is  :: 0.17628726363182068 
2019-04-26 19:22:49,146  The global step train is 473
2019-04-26 19:22:49,273  The loss during training is  :: 0.07649888843297958 
2019-04-26 19:22:49,431  The global step train is 474
2019-04-26 19:22:49,555  The loss during training is  :: 0.09233777970075607 
2019-04-26 19:22:49,715  The global step train is 475
2019-04-26 19:22:49,844  The loss during training is  :: 0.08236486464738846 
2019-04-26 19:22:50,003  The global step train is 476
2019-04-26 19:22:50,126  The loss during training is  :: 0.055933550000190735 
2019-04-26 19:22:50,308  The global step train is 477
2019-04-26 19:22:50,434  The loss during training is  :: 0.09940565377473831 
2019-04-26 19:22:50,596  The global step train is 478
2019-04-26 19:22:50,726  The loss during training is  :: 0.0963917151093483 
2019-04-26 19:22:50,887  The global step train is 479
2019-04-26 19:22:51,017  The loss during training is  :: 0.07862447202205658 
2019-04-26 19:22:51,175  The global step train is 480
2019-04-26 19:22:51,304  The loss during training is  :: 0.056079789996147156 
2019-04-26 19:22:51,465  The global step train is 481
2019-04-26 19:22:51,589  The loss during training is  :: 0.11091712862253189 
2019-04-26 19:22:51,748  The global step train is 482
2019-04-26 19:22:51,880  The loss during training is  :: 0.18074864149093628 
2019-04-26 19:22:52,042  The global step train is 483
2019-04-26 19:22:52,170  The loss during training is  :: 0.13220755755901337 
2019-04-26 19:22:52,330  The global step train is 484
2019-04-26 19:22:52,458  The loss during training is  :: 0.0980808287858963 
2019-04-26 19:22:52,618  The global step train is 485
2019-04-26 19:22:52,743  The loss during training is  :: 0.1388513594865799 
2019-04-26 19:22:52,902  The global step train is 486
2019-04-26 19:22:53,029  The loss during training is  :: 0.13816124200820923 
2019-04-26 19:22:53,190  The global step train is 487
2019-04-26 19:22:53,317  The loss during training is  :: 0.06958293169736862 
2019-04-26 19:22:53,477  The global step train is 488
2019-04-26 19:22:53,598  The loss during training is  :: 0.12956511974334717 
2019-04-26 19:22:53,755  The global step train is 489
2019-04-26 19:22:53,876  The loss during training is  :: 0.14099843800067902 
2019-04-26 19:22:54,036  The global step train is 490
2019-04-26 19:22:54,159  The loss during training is  :: 0.13644187152385712 
2019-04-26 19:22:54,321  The global step train is 491
2019-04-26 19:22:54,441  The loss during training is  :: 0.11212023347616196 
2019-04-26 19:22:54,599  The global step train is 492
2019-04-26 19:22:54,723  The loss during training is  :: 0.10579559206962585 
2019-04-26 19:22:54,880  The global step train is 493
2019-04-26 19:22:55,006  The loss during training is  :: 0.07529447227716446 
2019-04-26 19:22:55,165  The global step train is 494
2019-04-26 19:22:55,290  The loss during training is  :: 0.08827318251132965 
2019-04-26 19:22:55,452  The global step train is 495
2019-04-26 19:22:55,576  The loss during training is  :: 0.12409982085227966 
2019-04-26 19:22:55,738  The global step train is 496
2019-04-26 19:22:55,863  The loss during training is  :: 0.1745997965335846 
2019-04-26 19:22:56,024  The global step train is 497
2019-04-26 19:22:56,151  The loss during training is  :: 0.06798892468214035 
2019-04-26 19:22:56,313  The global step train is 498
2019-04-26 19:22:56,434  The loss during training is  :: 0.13957825303077698 
2019-04-26 19:22:56,594  The global step train is 499
2019-04-26 19:22:56,720  The loss during training is  :: 0.10747596621513367 
2019-04-26 19:22:56,884  The global step train is 500
2019-04-26 19:22:57,008  The loss during training is  :: 0.07182729244232178 
2019-04-26 19:22:57,166  The global step train is 501
2019-04-26 19:22:57,299  The loss during training is  :: 0.1013951301574707 
2019-04-26 19:22:57,463  The global step train is 502
2019-04-26 19:22:57,583  The loss during training is  :: 0.06898204982280731 
2019-04-26 19:22:57,739  The global step train is 503
2019-04-26 19:22:57,863  The loss during training is  :: 0.06504711508750916 
2019-04-26 19:22:58,021  The global step train is 504
2019-04-26 19:22:58,146  The loss during training is  :: 0.09989369660615921 
2019-04-26 19:22:58,309  The global step train is 505
2019-04-26 19:22:58,435  The loss during training is  :: 0.09379055351018906 
2019-04-26 19:22:58,592  The global step train is 506
2019-04-26 19:22:58,717  The loss during training is  :: 0.10370251536369324 
2019-04-26 19:22:58,877  The global step train is 507
2019-04-26 19:22:59,002  The loss during training is  :: 0.0765814259648323 
2019-04-26 19:22:59,160  The global step train is 508
2019-04-26 19:22:59,284  The loss during training is  :: 0.08670509606599808 
2019-04-26 19:22:59,440  The global step train is 509
2019-04-26 19:22:59,562  The loss during training is  :: 0.0980394184589386 
2019-04-26 19:22:59,723  The global step train is 510
2019-04-26 19:22:59,851  The loss during training is  :: 0.05508490279316902 
2019-04-26 19:23:00,014  The global step train is 511
2019-04-26 19:23:00,140  The loss during training is  :: 0.08287930488586426 
2019-04-26 19:23:00,301  The global step train is 512
2019-04-26 19:23:00,424  The loss during training is  :: 0.10158631205558777 
2019-04-26 19:23:00,601  The global step train is 513
2019-04-26 19:23:00,724  The loss during training is  :: 0.14000119268894196 
2019-04-26 19:23:00,884  The global step train is 514
2019-04-26 19:23:01,007  The loss during training is  :: 0.06673051416873932 
2019-04-26 19:23:01,167  The global step train is 515
2019-04-26 19:23:01,290  The loss during training is  :: 0.07678816467523575 
2019-04-26 19:23:01,453  The global step train is 516
2019-04-26 19:23:01,574  The loss during training is  :: 0.10147280991077423 
2019-04-26 19:23:01,735  The global step train is 517
2019-04-26 19:23:01,863  The loss during training is  :: 0.1519756019115448 
2019-04-26 19:23:02,023  The global step train is 518
2019-04-26 19:23:02,150  The loss during training is  :: 0.052312418818473816 
2019-04-26 19:23:02,312  The global step train is 519
2019-04-26 19:23:02,436  The loss during training is  :: 0.05743907764554024 
2019-04-26 19:23:02,597  The global step train is 520
2019-04-26 19:23:02,720  The loss during training is  :: 0.0933951884508133 
2019-04-26 19:23:02,879  The global step train is 521
2019-04-26 19:23:03,005  The loss during training is  :: 0.04919656738638878 
2019-04-26 19:23:03,169  The global step train is 522
2019-04-26 19:23:03,297  The loss during training is  :: 0.0693180039525032 
2019-04-26 19:23:03,460  The global step train is 523
2019-04-26 19:23:03,584  The loss during training is  :: 0.11305341124534607 
2019-04-26 19:23:03,741  The global step train is 524
2019-04-26 19:23:03,867  The loss during training is  :: 0.08970468491315842 
2019-04-26 19:23:04,027  The global step train is 525
2019-04-26 19:23:04,152  The loss during training is  :: 0.09566764533519745 
2019-04-26 19:23:04,314  The global step train is 526
2019-04-26 19:23:04,438  The loss during training is  :: 0.1794525533914566 
2019-04-26 19:23:04,597  The global step train is 527
2019-04-26 19:23:04,721  The loss during training is  :: 0.08895095437765121 
2019-04-26 19:23:04,879  The global step train is 528
2019-04-26 19:23:04,998  The loss during training is  :: 0.12221397459506989 
2019-04-26 19:23:05,151  The global step train is 529
2019-04-26 19:23:05,276  The loss during training is  :: 0.048266518861055374 
2019-04-26 19:23:05,434  The global step train is 530
2019-04-26 19:23:05,560  The loss during training is  :: 0.0911191925406456 
2019-04-26 19:23:05,718  The global step train is 531
2019-04-26 19:23:05,841  The loss during training is  :: 0.053966350853443146 
2019-04-26 19:23:06,003  The global step train is 532
2019-04-26 19:23:06,127  The loss during training is  :: 0.06660249084234238 
2019-04-26 19:23:06,291  The global step train is 533
2019-04-26 19:23:06,418  The loss during training is  :: 0.23805668950080872 
2019-04-26 19:23:06,578  The global step train is 534
2019-04-26 19:23:06,699  The loss during training is  :: 0.07841765135526657 
2019-04-26 19:23:06,857  The global step train is 535
2019-04-26 19:23:06,981  The loss during training is  :: 0.10339611768722534 
2019-04-26 19:23:07,134  The global step train is 536
2019-04-26 19:23:07,260  The loss during training is  :: 0.06769020855426788 
2019-04-26 19:23:07,419  The global step train is 537
2019-04-26 19:23:07,544  The loss during training is  :: 0.0665944442152977 
2019-04-26 19:23:07,703  The global step train is 538
2019-04-26 19:23:07,829  The loss during training is  :: 0.16919384896755219 
2019-04-26 19:23:07,988  The global step train is 539
2019-04-26 19:23:08,111  The loss during training is  :: 0.09584283083677292 
2019-04-26 19:23:08,275  The global step train is 540
2019-04-26 19:23:08,396  The loss during training is  :: 0.052977900952100754 
2019-04-26 19:23:08,563  The global step train is 541
2019-04-26 19:23:08,685  The loss during training is  :: 0.07552971690893173 
2019-04-26 19:23:08,836  The global step train is 542
2019-04-26 19:23:08,960  The loss during training is  :: 0.11016733944416046 
2019-04-26 19:23:09,120  The global step train is 543
2019-04-26 19:23:09,241  The loss during training is  :: 0.10358782112598419 
2019-04-26 19:23:09,399  The global step train is 544
2019-04-26 19:23:09,521  The loss during training is  :: 0.04538503661751747 
2019-04-26 19:23:09,683  The global step train is 545
2019-04-26 19:23:09,810  The loss during training is  :: 0.1108386218547821 
2019-04-26 19:23:09,971  The global step train is 546
2019-04-26 19:23:10,100  The loss during training is  :: 0.07663790881633759 
2019-04-26 19:23:10,261  The global step train is 547
2019-04-26 19:23:10,384  The loss during training is  :: 0.06101466342806816 
2019-04-26 19:23:10,546  The global step train is 548
2019-04-26 19:23:10,671  The loss during training is  :: 0.11492640525102615 
2019-04-26 19:23:10,827  The global step train is 549
2019-04-26 19:23:10,952  The loss during training is  :: 0.0642571672797203 
2019-04-26 19:23:11,113  The global step train is 550
2019-04-26 19:23:11,246  The loss during training is  :: 0.10091302543878555 
2019-04-26 19:23:11,404  The global step train is 551
2019-04-26 19:23:11,527  The loss during training is  :: 0.08311260491609573 
2019-04-26 19:23:11,690  The global step train is 552
2019-04-26 19:23:11,818  The loss during training is  :: 0.07713642716407776 
2019-04-26 19:23:11,980  The global step train is 553
2019-04-26 19:23:12,106  The loss during training is  :: 0.10536150634288788 
2019-04-26 19:23:12,263  The global step train is 554
2019-04-26 19:23:12,395  The loss during training is  :: 0.13989494740962982 
2019-04-26 19:23:12,558  The global step train is 555
2019-04-26 19:23:12,682  The loss during training is  :: 0.06867536902427673 
2019-04-26 19:23:12,840  The global step train is 556
2019-04-26 19:23:12,971  The loss during training is  :: 0.07619353383779526 
2019-04-26 19:23:13,132  The global step train is 557
2019-04-26 19:23:13,258  The loss during training is  :: 0.0547434501349926 
2019-04-26 19:23:13,423  The global step train is 558
2019-04-26 19:23:13,549  The loss during training is  :: 0.07884827256202698 
2019-04-26 19:23:13,709  The global step train is 559
2019-04-26 19:23:13,840  The loss during training is  :: 0.06656420230865479 
2019-04-26 19:23:13,998  The global step train is 560
2019-04-26 19:23:14,124  The loss during training is  :: 0.12092599272727966 
2019-04-26 19:23:14,286  The global step train is 561
2019-04-26 19:23:14,411  The loss during training is  :: 0.18628068268299103 
2019-04-26 19:23:14,571  The global step train is 562
2019-04-26 19:23:14,695  The loss during training is  :: 0.09100396186113358 
2019-04-26 19:23:14,861  The global step train is 563
2019-04-26 19:23:14,987  The loss during training is  :: 0.06928667426109314 
2019-04-26 19:23:15,143  The global step train is 564
2019-04-26 19:23:15,269  The loss during training is  :: 0.13066454231739044 
2019-04-26 19:23:15,430  The global step train is 565
2019-04-26 19:23:15,558  The loss during training is  :: 0.06005581468343735 
2019-04-26 19:23:15,721  The global step train is 566
2019-04-26 19:23:15,851  The loss during training is  :: 0.08462175726890564 
2019-04-26 19:23:16,021  The global step train is 567
2019-04-26 19:23:16,150  The loss during training is  :: 0.0873849093914032 
2019-04-26 19:23:16,310  The global step train is 568
2019-04-26 19:23:16,435  The loss during training is  :: 0.21404337882995605 
2019-04-26 19:23:16,594  The global step train is 569
2019-04-26 19:23:16,721  The loss during training is  :: 0.11923501640558243 
2019-04-26 19:23:16,882  The global step train is 570
2019-04-26 19:23:17,007  The loss during training is  :: 0.12089645117521286 
2019-04-26 19:23:17,183  The global step train is 571
2019-04-26 19:23:17,319  The loss during training is  :: 0.10566888749599457 
2019-04-26 19:23:17,482  The global step train is 572
2019-04-26 19:23:17,606  The loss during training is  :: 0.1441144347190857 
2019-04-26 19:23:17,766  The global step train is 573
2019-04-26 19:23:17,888  The loss during training is  :: 0.10109197348356247 
2019-04-26 19:23:18,053  The global step train is 574
2019-04-26 19:23:18,186  The loss during training is  :: 0.07228582352399826 
2019-04-26 19:23:18,348  The global step train is 575
2019-04-26 19:23:18,477  The loss during training is  :: 0.11267460882663727 
2019-04-26 19:23:18,642  The global step train is 576
2019-04-26 19:23:18,771  The loss during training is  :: 0.10613179206848145 
2019-04-26 19:23:18,943  The global step train is 577
2019-04-26 19:23:19,070  The loss during training is  :: 0.06544390320777893 
2019-04-26 19:23:19,233  The global step train is 578
2019-04-26 19:23:19,361  The loss during training is  :: 0.08179879933595657 
2019-04-26 19:23:19,517  The global step train is 579
2019-04-26 19:23:19,643  The loss during training is  :: 0.2575887143611908 
2019-04-26 19:23:19,809  The global step train is 580
2019-04-26 19:23:19,939  The loss during training is  :: 0.14092402160167694 
2019-04-26 19:23:20,110  The global step train is 581
2019-04-26 19:23:20,237  The loss during training is  :: 0.08010968565940857 
2019-04-26 19:23:20,395  The global step train is 582
2019-04-26 19:23:20,528  The loss during training is  :: 0.07919151335954666 
2019-04-26 19:23:20,688  The global step train is 583
2019-04-26 19:23:20,817  The loss during training is  :: 0.14756609499454498 
2019-04-26 19:23:20,979  The global step train is 584
2019-04-26 19:23:21,104  The loss during training is  :: 0.18762624263763428 
2019-04-26 19:23:21,263  The global step train is 585
2019-04-26 19:23:21,388  The loss during training is  :: 0.10488815605640411 
2019-04-26 19:23:21,545  The global step train is 586
2019-04-26 19:23:21,670  The loss during training is  :: 0.09743072837591171 
2019-04-26 19:23:21,831  The global step train is 587
2019-04-26 19:23:21,961  The loss during training is  :: 0.14870253205299377 
2019-04-26 19:23:22,119  The global step train is 588
2019-04-26 19:23:22,249  The loss during training is  :: 0.09835869818925858 
2019-04-26 19:23:22,407  The global step train is 589
2019-04-26 19:23:22,533  The loss during training is  :: 0.1598447859287262 
2019-04-26 19:23:22,695  The global step train is 590
2019-04-26 19:23:22,820  The loss during training is  :: 0.09911993145942688 
2019-04-26 19:23:22,979  The global step train is 591
2019-04-26 19:23:23,110  The loss during training is  :: 0.08968358486890793 
2019-04-26 19:23:23,274  The global step train is 592
2019-04-26 19:23:23,397  The loss during training is  :: 0.08386897295713425 
2019-04-26 19:23:23,568  The global step train is 593
2019-04-26 19:23:23,690  The loss during training is  :: 0.07838714867830276 
2019-04-26 19:23:23,853  The global step train is 594
2019-04-26 19:23:23,970  The loss during training is  :: 0.10705172270536423 
2019-04-26 19:23:24,130  The global step train is 595
2019-04-26 19:23:24,261  The loss during training is  :: 0.13518747687339783 
2019-04-26 19:23:24,435  The global step train is 596
2019-04-26 19:23:24,566  The loss during training is  :: 0.1626901477575302 
2019-04-26 19:23:24,728  The global step train is 597
2019-04-26 19:23:24,851  The loss during training is  :: 0.07372850179672241 
2019-04-26 19:23:25,009  The global step train is 598
2019-04-26 19:23:25,136  The loss during training is  :: 0.08003111183643341 
2019-04-26 19:23:25,295  The global step train is 599
2019-04-26 19:23:25,425  The loss during training is  :: 0.05640696734189987 
2019-04-26 19:23:25,587  The global step train is 600
2019-04-26 19:23:25,714  The loss during training is  :: 0.1413693130016327 
2019-04-26 19:23:25,884  The global step train is 601
2019-04-26 19:23:26,010  The loss during training is  :: 0.13230690360069275 
2019-04-26 19:23:26,171  The global step train is 602
2019-04-26 19:23:26,300  The loss during training is  :: 0.03897078335285187 
2019-04-26 19:23:26,460  The global step train is 603
2019-04-26 19:23:26,589  The loss during training is  :: 0.1544984132051468 
2019-04-26 19:23:26,751  The global step train is 604
2019-04-26 19:23:26,877  The loss during training is  :: 0.14008493721485138 
2019-04-26 19:23:27,035  The global step train is 605
2019-04-26 19:23:27,164  The loss during training is  :: 0.14322425425052643 
2019-04-26 19:23:27,325  The global step train is 606
2019-04-26 19:23:27,450  The loss during training is  :: 0.08690705895423889 
2019-04-26 19:23:27,610  The global step train is 607
2019-04-26 19:23:27,740  The loss during training is  :: 0.05516768619418144 
2019-04-26 19:23:27,904  The global step train is 608
2019-04-26 19:23:28,035  The loss during training is  :: 0.07710620760917664 
2019-04-26 19:23:28,195  The global step train is 609
2019-04-26 19:23:28,321  The loss during training is  :: 0.08779802173376083 
2019-04-26 19:23:28,483  The global step train is 610
2019-04-26 19:23:28,610  The loss during training is  :: 0.08583643287420273 
2019-04-26 19:23:28,766  The global step train is 611
2019-04-26 19:23:28,897  The loss during training is  :: 0.24900224804878235 
2019-04-26 19:23:29,065  The global step train is 612
2019-04-26 19:23:29,194  The loss during training is  :: 0.10830751061439514 
2019-04-26 19:23:29,354  The global step train is 613
2019-04-26 19:23:29,479  The loss during training is  :: 0.07647928595542908 
2019-04-26 19:23:29,640  The global step train is 614
2019-04-26 19:23:29,779  The loss during training is  :: 0.13666729629039764 
2019-04-26 19:23:29,941  The global step train is 615
2019-04-26 19:23:30,066  The loss during training is  :: 0.03903612866997719 
2019-04-26 19:23:30,227  The global step train is 616
2019-04-26 19:23:30,357  The loss during training is  :: 0.0958527997136116 
2019-04-26 19:23:30,526  The global step train is 617
2019-04-26 19:23:30,664  The loss during training is  :: 0.11782912909984589 
2019-04-26 19:23:30,822  The global step train is 618
2019-04-26 19:23:30,953  The loss during training is  :: 0.07761288434267044 
2019-04-26 19:23:31,115  The global step train is 619
2019-04-26 19:23:31,246  The loss during training is  :: 0.12910248339176178 
2019-04-26 19:23:31,406  The global step train is 620
2019-04-26 19:23:31,530  The loss during training is  :: 0.04122411832213402 
2019-04-26 19:23:31,694  The global step train is 621
2019-04-26 19:23:31,820  The loss during training is  :: 0.07792801409959793 
2019-04-26 19:23:31,974  The global step train is 622
2019-04-26 19:23:32,103  The loss during training is  :: 0.05284754931926727 
2019-04-26 19:23:32,262  The global step train is 623
2019-04-26 19:23:32,385  The loss during training is  :: 0.09840089082717896 
2019-04-26 19:23:32,549  The global step train is 624
2019-04-26 19:23:32,675  The loss during training is  :: 0.05339469388127327 
2019-04-26 19:23:32,833  The global step train is 625
2019-04-26 19:23:32,959  The loss during training is  :: 0.06578516960144043 
2019-04-26 19:23:33,114  The global step train is 626
2019-04-26 19:23:33,241  The loss during training is  :: 0.09542879462242126 
2019-04-26 19:23:33,401  The global step train is 627
2019-04-26 19:23:33,533  The loss during training is  :: 0.0900997519493103 
2019-04-26 19:23:33,693  The global step train is 628
2019-04-26 19:23:33,816  The loss during training is  :: 0.10525712370872498 
2019-04-26 19:23:33,980  The global step train is 629
2019-04-26 19:23:34,110  The loss during training is  :: 0.05642181262373924 
2019-04-26 19:23:34,270  The global step train is 630
2019-04-26 19:23:34,399  The loss during training is  :: 0.15065239369869232 
2019-04-26 19:23:34,559  The global step train is 631
2019-04-26 19:23:34,687  The loss during training is  :: 0.09276523441076279 
2019-04-26 19:23:34,849  The global step train is 632
2019-04-26 19:23:34,979  The loss during training is  :: 0.1070050448179245 
2019-04-26 19:23:35,144  The global step train is 633
2019-04-26 19:23:35,274  The loss during training is  :: 0.07535585761070251 
2019-04-26 19:23:35,432  The global step train is 634
2019-04-26 19:23:35,561  The loss during training is  :: 0.08213889598846436 
2019-04-26 19:23:35,723  The global step train is 635
2019-04-26 19:23:35,851  The loss during training is  :: 0.11463660001754761 
2019-04-26 19:23:36,013  The global step train is 636
2019-04-26 19:23:36,142  The loss during training is  :: 0.07281442731618881 
2019-04-26 19:23:36,299  The global step train is 637
2019-04-26 19:23:36,433  The loss during training is  :: 0.12967027723789215 
2019-04-26 19:23:36,594  The global step train is 638
2019-04-26 19:23:36,720  The loss during training is  :: 0.10843757539987564 
2019-04-26 19:23:36,883  The global step train is 639
2019-04-26 19:23:37,010  The loss during training is  :: 0.06697449833154678 
2019-04-26 19:23:37,172  The global step train is 640
2019-04-26 19:23:37,300  The loss during training is  :: 0.08762474358081818 
2019-04-26 19:23:37,457  The global step train is 641
2019-04-26 19:23:37,586  The loss during training is  :: 0.06630440056324005 
2019-04-26 19:23:37,745  The global step train is 642
2019-04-26 19:23:37,871  The loss during training is  :: 0.07711537927389145 
2019-04-26 19:23:38,033  The global step train is 643
2019-04-26 19:23:38,159  The loss during training is  :: 0.18659359216690063 
2019-04-26 19:23:38,322  The global step train is 644
2019-04-26 19:23:38,454  The loss during training is  :: 0.11594844609498978 
2019-04-26 19:23:38,611  The global step train is 645
2019-04-26 19:23:38,742  The loss during training is  :: 0.07213111966848373 
2019-04-26 19:23:38,905  The global step train is 646
2019-04-26 19:23:39,033  The loss during training is  :: 0.11269177496433258 
2019-04-26 19:23:39,189  The global step train is 647
2019-04-26 19:23:39,316  The loss during training is  :: 0.0814867690205574 
2019-04-26 19:23:39,468  The global step train is 648
2019-04-26 19:23:39,597  The loss during training is  :: 0.11763347685337067 
2019-04-26 19:23:39,750  The global step train is 649
2019-04-26 19:23:39,878  The loss during training is  :: 0.07128389924764633 
2019-04-26 19:23:40,033  The global step train is 650
2019-04-26 19:23:40,157  The loss during training is  :: 0.041685543954372406 
2019-04-26 19:23:40,313  The global step train is 651
2019-04-26 19:23:40,443  The loss during training is  :: 0.09040280431509018 
2019-04-26 19:23:40,610  The global step train is 652
2019-04-26 19:23:40,737  The loss during training is  :: 0.07038940489292145 
2019-04-26 19:23:40,897  The global step train is 653
2019-04-26 19:23:41,025  The loss during training is  :: 0.13761135935783386 
2019-04-26 19:23:41,184  The global step train is 654
2019-04-26 19:23:41,309  The loss during training is  :: 0.11880283057689667 
2019-04-26 19:23:41,464  The global step train is 655
2019-04-26 19:23:41,587  The loss during training is  :: 0.1214606761932373 
2019-04-26 19:23:41,750  The global step train is 656
2019-04-26 19:23:41,877  The loss during training is  :: 0.11062062531709671 
2019-04-26 19:23:42,032  The global step train is 657
2019-04-26 19:23:42,155  The loss during training is  :: 0.0824069082736969 
2019-04-26 19:23:42,315  The global step train is 658
2019-04-26 19:23:42,444  The loss during training is  :: 0.04579922556877136 
2019-04-26 19:23:42,600  The global step train is 659
2019-04-26 19:23:42,725  The loss during training is  :: 0.08160857856273651 
2019-04-26 19:23:42,889  The global step train is 660
2019-04-26 19:23:43,017  The loss during training is  :: 0.12852734327316284 
2019-04-26 19:23:43,180  The global step train is 661
2019-04-26 19:23:43,311  The loss during training is  :: 0.10796081274747849 
2019-04-26 19:23:43,471  The global step train is 662
2019-04-26 19:23:43,601  The loss during training is  :: 0.13331368565559387 
2019-04-26 19:23:43,760  The global step train is 663
2019-04-26 19:23:43,888  The loss during training is  :: 0.12987302243709564 
2019-04-26 19:23:44,056  The global step train is 664
2019-04-26 19:23:44,182  The loss during training is  :: 0.04083793982863426 
2019-04-26 19:23:44,341  The global step train is 665
2019-04-26 19:23:44,473  The loss during training is  :: 0.04947016015648842 
2019-04-26 19:23:44,634  The global step train is 666
2019-04-26 19:23:44,759  The loss during training is  :: 0.10112806409597397 
2019-04-26 19:23:44,917  The global step train is 667
2019-04-26 19:23:45,047  The loss during training is  :: 0.11180933564901352 
2019-04-26 19:23:45,209  The global step train is 668
2019-04-26 19:23:45,338  The loss during training is  :: 0.09703820198774338 
2019-04-26 19:23:45,495  The global step train is 669
2019-04-26 19:23:45,618  The loss during training is  :: 0.10157883912324905 
2019-04-26 19:23:45,777  The global step train is 670
2019-04-26 19:23:45,902  The loss during training is  :: 0.054130781441926956 
2019-04-26 19:23:46,055  The global step train is 671
2019-04-26 19:23:46,189  The loss during training is  :: 0.0562504380941391 
2019-04-26 19:23:46,354  The global step train is 672
2019-04-26 19:23:46,357  Starting evaluation 
2019-04-26 19:23:46,494  The loss during eval_loss is  :: 0.18488655984401703
2019-04-26 19:23:46,496  The global step eval is 113
2019-04-26 19:23:46,634  The loss during eval_loss is  :: 0.10625220835208893
2019-04-26 19:23:46,636  The global step eval is 114
2019-04-26 19:23:46,741  The loss during eval_loss is  :: 0.09905695915222168
2019-04-26 19:23:46,742  The global step eval is 115
2019-04-26 19:23:46,849  The loss during eval_loss is  :: 0.0824427679181099
2019-04-26 19:23:46,851  The global step eval is 116
2019-04-26 19:23:46,951  The loss during eval_loss is  :: 0.14159996807575226
2019-04-26 19:23:46,953  The global step eval is 117
2019-04-26 19:23:47,062  The loss during eval_loss is  :: 0.1793041229248047
2019-04-26 19:23:47,064  The global step eval is 118
2019-04-26 19:23:47,169  The loss during eval_loss is  :: 0.1411067694425583
2019-04-26 19:23:47,171  The global step eval is 119
2019-04-26 19:23:47,273  The loss during eval_loss is  :: 0.06423580646514893
2019-04-26 19:23:47,275  The global step eval is 120
2019-04-26 19:23:47,375  The loss during eval_loss is  :: 0.14736536145210266
2019-04-26 19:23:47,377  The global step eval is 121
2019-04-26 19:23:47,480  The loss during eval_loss is  :: 0.06418663263320923
2019-04-26 19:23:47,483  The global step eval is 122
2019-04-26 19:23:47,598  The loss during eval_loss is  :: 0.14220306277275085
2019-04-26 19:23:47,600  The global step eval is 123
2019-04-26 19:23:47,714  The loss during eval_loss is  :: 0.1075601726770401
2019-04-26 19:23:47,716  The global step eval is 124
2019-04-26 19:23:47,826  The loss during eval_loss is  :: 0.09155106544494629
2019-04-26 19:23:47,828  The global step eval is 125
2019-04-26 19:23:47,939  The loss during eval_loss is  :: 0.08975784480571747
2019-04-26 19:23:47,940  The global step eval is 126
2019-04-26 19:23:48,038  The loss during eval_loss is  :: 0.16376490890979767
2019-04-26 19:23:48,040  The global step eval is 127
2019-04-26 19:23:48,152  The loss during eval_loss is  :: 0.13925383985042572
2019-04-26 19:23:48,154  The global step eval is 128
2019-04-26 19:23:48,262  The loss during eval_loss is  :: 0.11978818476200104
2019-04-26 19:23:48,264  The global step eval is 129
2019-04-26 19:23:48,369  The loss during eval_loss is  :: 0.20854565501213074
2019-04-26 19:23:48,371  The global step eval is 130
2019-04-26 19:23:48,487  The loss during eval_loss is  :: 0.13071617484092712
2019-04-26 19:23:48,489  The global step eval is 131
2019-04-26 19:23:48,591  The loss during eval_loss is  :: 0.12003032863140106
2019-04-26 19:23:48,593  The global step eval is 132
2019-04-26 19:23:48,695  The loss during eval_loss is  :: 0.15143534541130066
2019-04-26 19:23:48,697  The global step eval is 133
2019-04-26 19:23:48,804  The loss during eval_loss is  :: 0.07985946536064148
2019-04-26 19:23:48,806  The global step eval is 134
2019-04-26 19:23:48,923  The loss during eval_loss is  :: 0.07072170078754425
2019-04-26 19:23:48,925  The global step eval is 135
2019-04-26 19:23:49,026  The loss during eval_loss is  :: 0.11739969998598099
2019-04-26 19:23:49,028  The global step eval is 136
2019-04-26 19:23:49,149  The loss during eval_loss is  :: 0.1044498160481453
2019-04-26 19:23:49,151  The global step eval is 137
2019-04-26 19:23:49,260  The loss during eval_loss is  :: 0.10026795417070389
2019-04-26 19:23:49,263  The global step eval is 138
2019-04-26 19:23:49,362  The loss during eval_loss is  :: 0.12956614792346954
2019-04-26 19:23:49,364  The global step eval is 139
2019-04-26 19:23:49,471  The loss during eval_loss is  :: 0.0981077253818512
2019-04-26 19:23:49,474  The global step eval is 140
2019-04-26 19:23:49,573  The loss during eval_loss is  :: 0.082632876932621
2019-04-26 19:23:49,575  The global step eval is 141
2019-04-26 19:23:49,697  The loss during eval_loss is  :: 0.10603836923837662
2019-04-26 19:23:49,699  The global step eval is 142
2019-04-26 19:23:49,805  The loss during eval_loss is  :: 0.06752034276723862
2019-04-26 19:23:49,807  The global step eval is 143
2019-04-26 19:23:49,915  The loss during eval_loss is  :: 0.1215653195977211
2019-04-26 19:23:49,916  The global step eval is 144
2019-04-26 19:23:50,025  The loss during eval_loss is  :: 0.1488247960805893
2019-04-26 19:23:50,026  The global step eval is 145
2019-04-26 19:23:50,132  The loss during eval_loss is  :: 0.21022771298885345
2019-04-26 19:23:50,133  The global step eval is 146
2019-04-26 19:23:50,237  The loss during eval_loss is  :: 0.0929160788655281
2019-04-26 19:23:50,238  The global step eval is 147
2019-04-26 19:23:50,359  The loss during eval_loss is  :: 0.12725119292736053
2019-04-26 19:23:50,360  The global step eval is 148
2019-04-26 19:23:50,464  The loss during eval_loss is  :: 0.16614694893360138
2019-04-26 19:23:50,466  The global step eval is 149
2019-04-26 19:23:50,576  The loss during eval_loss is  :: 0.09952083975076675
2019-04-26 19:23:50,578  The global step eval is 150
2019-04-26 19:23:50,686  The loss during eval_loss is  :: 0.09721244871616364
2019-04-26 19:23:50,688  The global step eval is 151
2019-04-26 19:23:50,792  The loss during eval_loss is  :: 0.09464056044816971
2019-04-26 19:23:50,794  The global step eval is 152
2019-04-26 19:23:50,906  The loss during eval_loss is  :: 0.11455276608467102
2019-04-26 19:23:50,908  The global step eval is 153
2019-04-26 19:23:51,019  The loss during eval_loss is  :: 0.08414647728204727
2019-04-26 19:23:51,021  The global step eval is 154
2019-04-26 19:23:51,136  The loss during eval_loss is  :: 0.16017118096351624
2019-04-26 19:23:51,138  The global step eval is 155
2019-04-26 19:23:51,247  The loss during eval_loss is  :: 0.10819623619318008
2019-04-26 19:23:51,249  The global step eval is 156
2019-04-26 19:23:51,357  The loss during eval_loss is  :: 0.19658724963665009
2019-04-26 19:23:51,359  The global step eval is 157
2019-04-26 19:23:51,461  The loss during eval_loss is  :: 0.09075913578271866
2019-04-26 19:23:51,463  The global step eval is 158
2019-04-26 19:23:51,569  The loss during eval_loss is  :: 0.12313303351402283
2019-04-26 19:23:51,571  The global step eval is 159
2019-04-26 19:23:51,678  The loss during eval_loss is  :: 0.1456107497215271
2019-04-26 19:23:51,679  The global step eval is 160
2019-04-26 19:23:51,784  The loss during eval_loss is  :: 0.10114384442567825
2019-04-26 19:23:51,786  The global step eval is 161
2019-04-26 19:23:51,892  The loss during eval_loss is  :: 0.16223399341106415
2019-04-26 19:23:51,894  The global step eval is 162
2019-04-26 19:23:51,997  The loss during eval_loss is  :: 0.16900481283664703
2019-04-26 19:23:51,999  The global step eval is 163
2019-04-26 19:23:52,100  The loss during eval_loss is  :: 0.11136291176080704
2019-04-26 19:23:52,102  The global step eval is 164
2019-04-26 19:23:52,211  The loss during eval_loss is  :: 0.14932385087013245
2019-04-26 19:23:52,213  The global step eval is 165
2019-04-26 19:23:52,321  The loss during eval_loss is  :: 0.08699607849121094
2019-04-26 19:23:52,323  The global step eval is 166
2019-04-26 19:23:52,422  The loss during eval_loss is  :: 0.14422503113746643
2019-04-26 19:23:52,424  The global step eval is 167
2019-04-26 19:23:52,540  The loss during eval_loss is  :: 0.16096438467502594
2019-04-26 19:23:52,542  The global step eval is 168
2019-04-26 19:23:52,558  Saved checkpoint: ./trained_model\step_2.pth.tar
2019-04-26 19:23:52,669  The loss during training is  :: 0.11259559541940689 
2019-04-26 19:23:52,825  The global step train is 673
2019-04-26 19:23:52,949  The loss during training is  :: 0.051922429352998734 
2019-04-26 19:23:53,109  The global step train is 674
2019-04-26 19:23:53,241  The loss during training is  :: 0.1366591453552246 
2019-04-26 19:23:53,400  The global step train is 675
2019-04-26 19:23:53,528  The loss during training is  :: 0.0802198126912117 
2019-04-26 19:23:53,689  The global step train is 676
2019-04-26 19:23:53,819  The loss during training is  :: 0.12350397557020187 
2019-04-26 19:23:53,981  The global step train is 677
2019-04-26 19:23:54,112  The loss during training is  :: 0.05609942227602005 
2019-04-26 19:23:54,274  The global step train is 678
2019-04-26 19:23:54,404  The loss during training is  :: 0.09021732211112976 
2019-04-26 19:23:54,566  The global step train is 679
2019-04-26 19:23:54,696  The loss during training is  :: 0.07604296505451202 
2019-04-26 19:23:54,858  The global step train is 680
2019-04-26 19:23:54,986  The loss during training is  :: 0.057104770094156265 
2019-04-26 19:23:55,158  The global step train is 681
2019-04-26 19:23:55,290  The loss during training is  :: 0.0984267070889473 
2019-04-26 19:23:55,448  The global step train is 682
2019-04-26 19:23:55,576  The loss during training is  :: 0.10310401022434235 
2019-04-26 19:23:55,733  The global step train is 683
2019-04-26 19:23:55,865  The loss during training is  :: 0.05854031816124916 
2019-04-26 19:23:56,026  The global step train is 684
2019-04-26 19:23:56,153  The loss during training is  :: 0.06820520758628845 
2019-04-26 19:23:56,313  The global step train is 685
2019-04-26 19:23:56,441  The loss during training is  :: 0.11709310114383698 
2019-04-26 19:23:56,604  The global step train is 686
2019-04-26 19:23:56,731  The loss during training is  :: 0.05291593074798584 
2019-04-26 19:23:56,895  The global step train is 687
2019-04-26 19:23:57,025  The loss during training is  :: 0.12501771748065948 
2019-04-26 19:23:57,186  The global step train is 688
2019-04-26 19:23:57,317  The loss during training is  :: 0.07518140971660614 
2019-04-26 19:23:57,482  The global step train is 689
2019-04-26 19:23:57,609  The loss during training is  :: 0.19058258831501007 
2019-04-26 19:23:57,769  The global step train is 690
2019-04-26 19:23:57,911  The loss during training is  :: 0.06352633237838745 
2019-04-26 19:23:58,073  The global step train is 691
2019-04-26 19:23:58,204  The loss during training is  :: 0.0734250545501709 
2019-04-26 19:23:58,365  The global step train is 692
2019-04-26 19:23:58,491  The loss during training is  :: 0.1008794978260994 
2019-04-26 19:23:58,648  The global step train is 693
2019-04-26 19:23:58,780  The loss during training is  :: 0.09201431274414062 
2019-04-26 19:23:58,944  The global step train is 694
2019-04-26 19:23:59,072  The loss during training is  :: 0.09248800575733185 
2019-04-26 19:23:59,241  The global step train is 695
2019-04-26 19:23:59,369  The loss during training is  :: 0.06073025241494179 
2019-04-26 19:23:59,522  The global step train is 696
2019-04-26 19:23:59,652  The loss during training is  :: 0.036241739988327026 
2019-04-26 19:23:59,812  The global step train is 697
2019-04-26 19:23:59,943  The loss during training is  :: 0.09801042079925537 
2019-04-26 19:24:00,109  The global step train is 698
2019-04-26 19:24:00,238  The loss during training is  :: 0.15337683260440826 
2019-04-26 19:24:00,400  The global step train is 699
2019-04-26 19:24:00,520  The loss during training is  :: 0.10379654914140701 
2019-04-26 19:24:00,681  The global step train is 700
2019-04-26 19:24:00,812  The loss during training is  :: 0.07522429525852203 
2019-04-26 19:24:00,973  The global step train is 701
2019-04-26 19:24:01,104  The loss during training is  :: 0.15802480280399323 
2019-04-26 19:24:01,268  The global step train is 702
2019-04-26 19:24:01,399  The loss during training is  :: 0.07351358234882355 
2019-04-26 19:24:01,559  The global step train is 703
2019-04-26 19:24:01,687  The loss during training is  :: 0.03484445810317993 
2019-04-26 19:24:01,851  The global step train is 704
2019-04-26 19:24:01,973  The loss during training is  :: 0.1086786687374115 
2019-04-26 19:24:02,135  The global step train is 705
2019-04-26 19:24:02,263  The loss during training is  :: 0.09581783413887024 
2019-04-26 19:24:02,425  The global step train is 706
2019-04-26 19:24:02,550  The loss during training is  :: 0.1490839570760727 
2019-04-26 19:24:02,712  The global step train is 707
2019-04-26 19:24:02,839  The loss during training is  :: 0.06868969649076462 
2019-04-26 19:24:03,000  The global step train is 708
2019-04-26 19:24:03,129  The loss during training is  :: 0.033855438232421875 
2019-04-26 19:24:03,291  The global step train is 709
2019-04-26 19:24:03,420  The loss during training is  :: 0.1472303718328476 
2019-04-26 19:24:03,581  The global step train is 710
2019-04-26 19:24:03,705  The loss during training is  :: 0.10554298013448715 
2019-04-26 19:24:03,873  The global step train is 711
2019-04-26 19:24:04,004  The loss during training is  :: 0.08393155783414841 
2019-04-26 19:24:04,172  The global step train is 712
2019-04-26 19:24:04,303  The loss during training is  :: 0.07630021125078201 
2019-04-26 19:24:04,461  The global step train is 713
2019-04-26 19:24:04,590  The loss during training is  :: 0.09973324090242386 
2019-04-26 19:24:04,747  The global step train is 714
2019-04-26 19:24:04,877  The loss during training is  :: 0.08491098880767822 
2019-04-26 19:24:05,035  The global step train is 715
2019-04-26 19:24:05,165  The loss during training is  :: 0.10183292627334595 
2019-04-26 19:24:05,322  The global step train is 716
2019-04-26 19:24:05,447  The loss during training is  :: 0.04760582745075226 
2019-04-26 19:24:05,614  The global step train is 717
2019-04-26 19:24:05,741  The loss during training is  :: 0.059297967702150345 
2019-04-26 19:24:05,902  The global step train is 718
2019-04-26 19:24:06,033  The loss during training is  :: 0.14913487434387207 
2019-04-26 19:24:06,196  The global step train is 719
2019-04-26 19:24:06,328  The loss during training is  :: 0.13890796899795532 
2019-04-26 19:24:06,494  The global step train is 720
2019-04-26 19:24:06,619  The loss during training is  :: 0.04847273975610733 
2019-04-26 19:24:06,780  The global step train is 721
2019-04-26 19:24:06,909  The loss during training is  :: 0.1411452293395996 
2019-04-26 19:24:07,062  The global step train is 722
2019-04-26 19:24:07,190  The loss during training is  :: 0.04407265782356262 
2019-04-26 19:24:07,351  The global step train is 723
2019-04-26 19:24:07,480  The loss during training is  :: 0.1557619422674179 
2019-04-26 19:24:07,641  The global step train is 724
2019-04-26 19:24:07,764  The loss during training is  :: 0.09146197885274887 
2019-04-26 19:24:07,930  The global step train is 725
2019-04-26 19:24:08,053  The loss during training is  :: 0.09838245809078217 
2019-04-26 19:24:08,226  The global step train is 726
2019-04-26 19:24:08,355  The loss during training is  :: 0.05898908153176308 
2019-04-26 19:24:08,517  The global step train is 727
2019-04-26 19:24:08,643  The loss during training is  :: 0.03848402947187424 
2019-04-26 19:24:08,804  The global step train is 728
2019-04-26 19:24:08,934  The loss during training is  :: 0.08056733012199402 
2019-04-26 19:24:09,098  The global step train is 729
2019-04-26 19:24:09,228  The loss during training is  :: 0.08672959357500076 
2019-04-26 19:24:09,393  The global step train is 730
2019-04-26 19:24:09,520  The loss during training is  :: 0.06275661289691925 
2019-04-26 19:24:09,686  The global step train is 731
2019-04-26 19:24:09,812  The loss during training is  :: 0.055705197155475616 
2019-04-26 19:24:09,972  The global step train is 732
2019-04-26 19:24:10,103  The loss during training is  :: 0.05366835743188858 
2019-04-26 19:24:10,266  The global step train is 733
2019-04-26 19:24:10,391  The loss during training is  :: 0.07500504702329636 
2019-04-26 19:24:10,550  The global step train is 734
2019-04-26 19:24:10,677  The loss during training is  :: 0.0551447868347168 
2019-04-26 19:24:10,842  The global step train is 735
2019-04-26 19:24:10,973  The loss during training is  :: 0.0543917715549469 
2019-04-26 19:24:11,132  The global step train is 736
2019-04-26 19:24:11,263  The loss during training is  :: 0.10498038679361343 
2019-04-26 19:24:11,422  The global step train is 737
2019-04-26 19:24:11,555  The loss during training is  :: 0.0935717299580574 
2019-04-26 19:24:11,718  The global step train is 738
2019-04-26 19:24:11,842  The loss during training is  :: 0.09827803820371628 
2019-04-26 19:24:12,000  The global step train is 739
2019-04-26 19:24:12,125  The loss during training is  :: 0.06180696561932564 
2019-04-26 19:24:12,290  The global step train is 740
2019-04-26 19:24:12,420  The loss during training is  :: 0.06499902158975601 
2019-04-26 19:24:12,581  The global step train is 741
2019-04-26 19:24:12,710  The loss during training is  :: 0.09258332848548889 
2019-04-26 19:24:12,868  The global step train is 742
2019-04-26 19:24:12,995  The loss during training is  :: 0.1872115284204483 
2019-04-26 19:24:13,153  The global step train is 743
2019-04-26 19:24:13,285  The loss during training is  :: 0.1037827804684639 
2019-04-26 19:24:13,456  The global step train is 744
2019-04-26 19:24:13,583  The loss during training is  :: 0.08099217712879181 
2019-04-26 19:24:13,742  The global step train is 745
2019-04-26 19:24:13,874  The loss during training is  :: 0.09835483878850937 
2019-04-26 19:24:14,033  The global step train is 746
2019-04-26 19:24:14,163  The loss during training is  :: 0.05762893706560135 
2019-04-26 19:24:14,328  The global step train is 747
2019-04-26 19:24:14,458  The loss during training is  :: 0.077710822224617 
2019-04-26 19:24:14,622  The global step train is 748
2019-04-26 19:24:14,746  The loss during training is  :: 0.049577657133340836 
2019-04-26 19:24:14,907  The global step train is 749
2019-04-26 19:24:15,036  The loss during training is  :: 0.06542520225048065 
2019-04-26 19:24:15,207  The global step train is 750
2019-04-26 19:24:15,341  The loss during training is  :: 0.1329687237739563 
2019-04-26 19:24:15,500  The global step train is 751
2019-04-26 19:24:15,631  The loss during training is  :: 0.08196268230676651 
2019-04-26 19:24:15,797  The global step train is 752
2019-04-26 19:24:15,924  The loss during training is  :: 0.0420333631336689 
2019-04-26 19:24:16,085  The global step train is 753
2019-04-26 19:24:16,207  The loss during training is  :: 0.09973710030317307 
2019-04-26 19:24:16,371  The global step train is 754
2019-04-26 19:24:16,504  The loss during training is  :: 0.09841862320899963 
2019-04-26 19:24:16,667  The global step train is 755
2019-04-26 19:24:16,795  The loss during training is  :: 0.07127940654754639 
2019-04-26 19:24:16,951  The global step train is 756
2019-04-26 19:24:17,084  The loss during training is  :: 0.054369162768125534 
2019-04-26 19:24:17,245  The global step train is 757
2019-04-26 19:24:17,370  The loss during training is  :: 0.1550055891275406 
2019-04-26 19:24:17,533  The global step train is 758
2019-04-26 19:24:17,657  The loss during training is  :: 0.06568026542663574 
2019-04-26 19:24:17,822  The global step train is 759
2019-04-26 19:24:17,950  The loss during training is  :: 0.06607907265424728 
2019-04-26 19:24:18,112  The global step train is 760
2019-04-26 19:24:18,242  The loss during training is  :: 0.07470306009054184 
2019-04-26 19:24:18,405  The global step train is 761
2019-04-26 19:24:18,534  The loss during training is  :: 0.043964140117168427 
2019-04-26 19:24:18,696  The global step train is 762
2019-04-26 19:24:18,827  The loss during training is  :: 0.05757278949022293 
2019-04-26 19:24:18,988  The global step train is 763
2019-04-26 19:24:19,120  The loss during training is  :: 0.13415130972862244 
2019-04-26 19:24:19,280  The global step train is 764
2019-04-26 19:24:19,400  The loss during training is  :: 0.06540191918611526 
2019-04-26 19:24:19,567  The global step train is 765
2019-04-26 19:24:19,688  The loss during training is  :: 0.09252515435218811 
2019-04-26 19:24:19,848  The global step train is 766
2019-04-26 19:24:19,973  The loss during training is  :: 0.07967697083950043 
2019-04-26 19:24:20,131  The global step train is 767
2019-04-26 19:24:20,260  The loss during training is  :: 0.05658653378486633 
2019-04-26 19:24:20,417  The global step train is 768
2019-04-26 19:24:20,545  The loss during training is  :: 0.09490158408880234 
2019-04-26 19:24:20,708  The global step train is 769
2019-04-26 19:24:20,835  The loss during training is  :: 0.06485996395349503 
2019-04-26 19:24:20,997  The global step train is 770
2019-04-26 19:24:21,126  The loss during training is  :: 0.0656571313738823 
2019-04-26 19:24:21,288  The global step train is 771
2019-04-26 19:24:21,417  The loss during training is  :: 0.09226807951927185 
2019-04-26 19:24:21,585  The global step train is 772
2019-04-26 19:24:21,717  The loss during training is  :: 0.07628656178712845 
2019-04-26 19:24:21,872  The global step train is 773
2019-04-26 19:24:22,008  The loss during training is  :: 0.05554001405835152 
2019-04-26 19:24:22,177  The global step train is 774
2019-04-26 19:24:22,311  The loss during training is  :: 0.0372968427836895 
2019-04-26 19:24:22,471  The global step train is 775
2019-04-26 19:24:22,603  The loss during training is  :: 0.03445753827691078 
2019-04-26 19:24:22,763  The global step train is 776
2019-04-26 19:24:22,895  The loss during training is  :: 0.06675280630588531 
2019-04-26 19:24:23,052  The global step train is 777
2019-04-26 19:24:23,183  The loss during training is  :: 0.04608627408742905 
2019-04-26 19:24:23,349  The global step train is 778
2019-04-26 19:24:23,479  The loss during training is  :: 0.02720491960644722 
2019-04-26 19:24:23,638  The global step train is 779
2019-04-26 19:24:23,755  The loss during training is  :: 0.08265304565429688 
2019-04-26 19:24:23,918  The global step train is 780
2019-04-26 19:24:24,049  The loss during training is  :: 0.06195899844169617 
2019-04-26 19:24:24,212  The global step train is 781
2019-04-26 19:24:24,343  The loss during training is  :: 0.0750875249505043 
2019-04-26 19:24:24,506  The global step train is 782
2019-04-26 19:24:24,634  The loss during training is  :: 0.12764963507652283 
2019-04-26 19:24:24,790  The global step train is 783
2019-04-26 19:24:24,909  The loss during training is  :: 0.05430036038160324 
2019-04-26 19:24:25,070  The global step train is 784
2019-04-26 19:24:25,202  The loss during training is  :: 0.04705521836876869 
2019-04-26 19:24:25,367  The global step train is 785
2019-04-26 19:24:25,497  The loss during training is  :: 0.062520831823349 
2019-04-26 19:24:25,662  The global step train is 786
2019-04-26 19:24:25,794  The loss during training is  :: 0.1498735547065735 
2019-04-26 19:24:25,950  The global step train is 787
2019-04-26 19:24:26,076  The loss during training is  :: 0.13226746022701263 
2019-04-26 19:24:26,239  The global step train is 788
2019-04-26 19:24:26,369  The loss during training is  :: 0.0519585944712162 
2019-04-26 19:24:26,530  The global step train is 789
2019-04-26 19:24:26,654  The loss during training is  :: 0.12356569617986679 
2019-04-26 19:24:26,818  The global step train is 790
2019-04-26 19:24:26,944  The loss during training is  :: 0.06127149611711502 
2019-04-26 19:24:27,105  The global step train is 791
2019-04-26 19:24:27,234  The loss during training is  :: 0.11621648073196411 
2019-04-26 19:24:27,399  The global step train is 792
2019-04-26 19:24:27,526  The loss during training is  :: 0.10303651541471481 
2019-04-26 19:24:27,686  The global step train is 793
2019-04-26 19:24:27,815  The loss during training is  :: 0.059570908546447754 
2019-04-26 19:24:27,978  The global step train is 794
2019-04-26 19:24:28,108  The loss during training is  :: 0.027432477101683617 
2019-04-26 19:24:28,269  The global step train is 795
2019-04-26 19:24:28,401  The loss during training is  :: 0.09595086425542831 
2019-04-26 19:24:28,575  The global step train is 796
2019-04-26 19:24:28,697  The loss during training is  :: 0.09013916552066803 
2019-04-26 19:24:28,860  The global step train is 797
2019-04-26 19:24:28,985  The loss during training is  :: 0.09598208218812943 
2019-04-26 19:24:29,143  The global step train is 798
2019-04-26 19:24:29,274  The loss during training is  :: 0.16136468946933746 
2019-04-26 19:24:29,438  The global step train is 799
2019-04-26 19:24:29,566  The loss during training is  :: 0.030331499874591827 
2019-04-26 19:24:29,725  The global step train is 800
2019-04-26 19:24:29,853  The loss during training is  :: 0.06529394537210464 
2019-04-26 19:24:30,016  The global step train is 801
2019-04-26 19:24:30,141  The loss during training is  :: 0.07472572475671768 
2019-04-26 19:24:30,305  The global step train is 802
2019-04-26 19:24:30,435  The loss during training is  :: 0.04068519547581673 
2019-04-26 19:24:30,596  The global step train is 803
2019-04-26 19:24:30,725  The loss during training is  :: 0.07301100343465805 
2019-04-26 19:24:30,887  The global step train is 804
2019-04-26 19:24:31,016  The loss during training is  :: 0.08867008239030838 
2019-04-26 19:24:31,177  The global step train is 805
2019-04-26 19:24:31,307  The loss during training is  :: 0.08334393799304962 
2019-04-26 19:24:31,472  The global step train is 806
2019-04-26 19:24:31,592  The loss during training is  :: 0.11010042577981949 
2019-04-26 19:24:31,757  The global step train is 807
2019-04-26 19:24:31,881  The loss during training is  :: 0.08833306282758713 
2019-04-26 19:24:32,041  The global step train is 808
2019-04-26 19:24:32,170  The loss during training is  :: 0.05020790174603462 
2019-04-26 19:24:32,328  The global step train is 809
2019-04-26 19:24:32,458  The loss during training is  :: 0.04675094410777092 
2019-04-26 19:24:32,625  The global step train is 810
2019-04-26 19:24:32,749  The loss during training is  :: 0.0311372559517622 
2019-04-26 19:24:32,913  The global step train is 811
2019-04-26 19:24:33,041  The loss during training is  :: 0.055429793894290924 
2019-04-26 19:24:33,199  The global step train is 812
2019-04-26 19:24:33,325  The loss during training is  :: 0.13094863295555115 
2019-04-26 19:24:33,485  The global step train is 813
2019-04-26 19:24:33,609  The loss during training is  :: 0.027464138343930244 
2019-04-26 19:24:33,774  The global step train is 814
2019-04-26 19:24:33,902  The loss during training is  :: 0.03590099886059761 
2019-04-26 19:24:34,057  The global step train is 815
2019-04-26 19:24:34,185  The loss during training is  :: 0.052678972482681274 
2019-04-26 19:24:34,349  The global step train is 816
2019-04-26 19:24:34,477  The loss during training is  :: 0.03671202063560486 
2019-04-26 19:24:34,638  The global step train is 817
2019-04-26 19:24:34,765  The loss during training is  :: 0.05293133854866028 
2019-04-26 19:24:34,925  The global step train is 818
2019-04-26 19:24:35,057  The loss during training is  :: 0.042685072869062424 
2019-04-26 19:24:35,227  The global step train is 819
2019-04-26 19:24:35,370  The loss during training is  :: 0.08555622398853302 
2019-04-26 19:24:35,536  The global step train is 820
2019-04-26 19:24:35,665  The loss during training is  :: 0.11227120459079742 
2019-04-26 19:24:35,824  The global step train is 821
2019-04-26 19:24:35,950  The loss during training is  :: 0.012568594887852669 
2019-04-26 19:24:36,110  The global step train is 822
2019-04-26 19:24:36,238  The loss during training is  :: 0.076304130256176 
2019-04-26 19:24:36,402  The global step train is 823
2019-04-26 19:24:36,529  The loss during training is  :: 0.09430878609418869 
2019-04-26 19:24:36,689  The global step train is 824
2019-04-26 19:24:36,815  The loss during training is  :: 0.11969108879566193 
2019-04-26 19:24:36,976  The global step train is 825
2019-04-26 19:24:37,106  The loss during training is  :: 0.07339444011449814 
2019-04-26 19:24:37,262  The global step train is 826
2019-04-26 19:24:37,388  The loss during training is  :: 0.08656863868236542 
2019-04-26 19:24:37,543  The global step train is 827
2019-04-26 19:24:37,670  The loss during training is  :: 0.049539681524038315 
2019-04-26 19:24:37,829  The global step train is 828
2019-04-26 19:24:37,957  The loss during training is  :: 0.1357649713754654 
2019-04-26 19:24:38,119  The global step train is 829
2019-04-26 19:24:38,246  The loss during training is  :: 0.08849397301673889 
2019-04-26 19:24:38,408  The global step train is 830
2019-04-26 19:24:38,538  The loss during training is  :: 0.05511081591248512 
2019-04-26 19:24:38,704  The global step train is 831
2019-04-26 19:24:38,834  The loss during training is  :: 0.16961653530597687 
2019-04-26 19:24:38,995  The global step train is 832
2019-04-26 19:24:39,125  The loss during training is  :: 0.07979326695203781 
2019-04-26 19:24:39,280  The global step train is 833
2019-04-26 19:24:39,409  The loss during training is  :: 0.05502321943640709 
2019-04-26 19:24:39,573  The global step train is 834
2019-04-26 19:24:39,704  The loss during training is  :: 0.09821780771017075 
2019-04-26 19:24:39,862  The global step train is 835
2019-04-26 19:24:39,993  The loss during training is  :: 0.0709720253944397 
2019-04-26 19:24:40,155  The global step train is 836
2019-04-26 19:24:40,289  The loss during training is  :: 0.13097329437732697 
2019-04-26 19:24:40,455  The global step train is 837
2019-04-26 19:24:40,582  The loss during training is  :: 0.0789182111620903 
2019-04-26 19:24:40,744  The global step train is 838
2019-04-26 19:24:40,873  The loss during training is  :: 0.06753198802471161 
2019-04-26 19:24:41,034  The global step train is 839
2019-04-26 19:24:41,161  The loss during training is  :: 0.08016469329595566 
2019-04-26 19:24:41,323  The global step train is 840
2019-04-26 19:24:41,455  The loss during training is  :: 0.04906745254993439 
2019-04-26 19:24:41,616  The global step train is 841
2019-04-26 19:24:41,741  The loss during training is  :: 0.049730896949768066 
2019-04-26 19:24:41,900  The global step train is 842
2019-04-26 19:24:42,029  The loss during training is  :: 0.05770198255777359 
2019-04-26 19:24:42,192  The global step train is 843
2019-04-26 19:24:42,319  The loss during training is  :: 0.08837909996509552 
2019-04-26 19:24:42,479  The global step train is 844
2019-04-26 19:24:42,612  The loss during training is  :: 0.11090204864740372 
2019-04-26 19:24:42,772  The global step train is 845
2019-04-26 19:24:42,897  The loss during training is  :: 0.06149906665086746 
2019-04-26 19:24:43,060  The global step train is 846
2019-04-26 19:24:43,182  The loss during training is  :: 0.13230831921100616 
2019-04-26 19:24:43,344  The global step train is 847
2019-04-26 19:24:43,472  The loss during training is  :: 0.06185133755207062 
2019-04-26 19:24:43,626  The global step train is 848
2019-04-26 19:24:43,749  The loss during training is  :: 0.10363666713237762 
2019-04-26 19:24:43,907  The global step train is 849
2019-04-26 19:24:44,036  The loss during training is  :: 0.04261384159326553 
2019-04-26 19:24:44,190  The global step train is 850
2019-04-26 19:24:44,320  The loss during training is  :: 0.08237757533788681 
2019-04-26 19:24:44,483  The global step train is 851
2019-04-26 19:24:44,610  The loss during training is  :: 0.04137413203716278 
2019-04-26 19:24:44,763  The global step train is 852
2019-04-26 19:24:44,892  The loss during training is  :: 0.06654420495033264 
2019-04-26 19:24:45,051  The global step train is 853
2019-04-26 19:24:45,176  The loss during training is  :: 0.03912431746721268 
2019-04-26 19:24:45,337  The global step train is 854
2019-04-26 19:24:45,463  The loss during training is  :: 0.04545331373810768 
2019-04-26 19:24:45,627  The global step train is 855
2019-04-26 19:24:45,754  The loss during training is  :: 0.090109683573246 
2019-04-26 19:24:45,909  The global step train is 856
2019-04-26 19:24:46,036  The loss during training is  :: 0.12546798586845398 
2019-04-26 19:24:46,195  The global step train is 857
2019-04-26 19:24:46,326  The loss during training is  :: 0.06353423744440079 
2019-04-26 19:24:46,489  The global step train is 858
2019-04-26 19:24:46,617  The loss during training is  :: 0.028589967638254166 
2019-04-26 19:24:46,778  The global step train is 859
2019-04-26 19:24:46,908  The loss during training is  :: 0.048452988266944885 
2019-04-26 19:24:47,067  The global step train is 860
2019-04-26 19:24:47,202  The loss during training is  :: 0.08956022560596466 
2019-04-26 19:24:47,366  The global step train is 861
2019-04-26 19:24:47,499  The loss during training is  :: 0.03497389331459999 
2019-04-26 19:24:47,661  The global step train is 862
2019-04-26 19:24:47,791  The loss during training is  :: 0.028728313744068146 
2019-04-26 19:24:47,946  The global step train is 863
2019-04-26 19:24:48,070  The loss during training is  :: 0.04605802893638611 
2019-04-26 19:24:48,230  The global step train is 864
2019-04-26 19:24:48,357  The loss during training is  :: 0.06312552094459534 
2019-04-26 19:24:48,520  The global step train is 865
2019-04-26 19:24:48,648  The loss during training is  :: 0.021381692960858345 
2019-04-26 19:24:48,815  The global step train is 866
2019-04-26 19:24:48,945  The loss during training is  :: 0.09484071284532547 
2019-04-26 19:24:49,111  The global step train is 867
2019-04-26 19:24:49,238  The loss during training is  :: 0.08083970844745636 
2019-04-26 19:24:49,398  The global step train is 868
2019-04-26 19:24:49,524  The loss during training is  :: 0.04492928832769394 
2019-04-26 19:24:49,687  The global step train is 869
2019-04-26 19:24:49,810  The loss during training is  :: 0.0569571889936924 
2019-04-26 19:24:49,969  The global step train is 870
2019-04-26 19:24:50,098  The loss during training is  :: 0.07724948972463608 
2019-04-26 19:24:50,262  The global step train is 871
2019-04-26 19:24:50,398  The loss during training is  :: 0.07005253434181213 
2019-04-26 19:24:50,568  The global step train is 872
2019-04-26 19:24:50,692  The loss during training is  :: 0.06965756416320801 
2019-04-26 19:24:50,857  The global step train is 873
2019-04-26 19:24:50,986  The loss during training is  :: 0.05964040011167526 
2019-04-26 19:24:51,149  The global step train is 874
2019-04-26 19:24:51,275  The loss during training is  :: 0.034634724259376526 
2019-04-26 19:24:51,433  The global step train is 875
2019-04-26 19:24:51,563  The loss during training is  :: 0.06371757388114929 
2019-04-26 19:24:51,719  The global step train is 876
2019-04-26 19:24:51,847  The loss during training is  :: 0.0718645378947258 
2019-04-26 19:24:52,004  The global step train is 877
2019-04-26 19:24:52,129  The loss during training is  :: 0.0756041407585144 
2019-04-26 19:24:52,296  The global step train is 878
2019-04-26 19:24:52,421  The loss during training is  :: 0.08172464370727539 
2019-04-26 19:24:52,581  The global step train is 879
2019-04-26 19:24:52,708  The loss during training is  :: 0.10680966824293137 
2019-04-26 19:24:52,872  The global step train is 880
2019-04-26 19:24:52,997  The loss during training is  :: 0.07423344999551773 
2019-04-26 19:24:53,153  The global step train is 881
2019-04-26 19:24:53,286  The loss during training is  :: 0.07596507668495178 
2019-04-26 19:24:53,457  The global step train is 882
2019-04-26 19:24:53,590  The loss during training is  :: 0.02638392522931099 
2019-04-26 19:24:53,740  The global step train is 883
2019-04-26 19:24:53,870  The loss during training is  :: 0.147726371884346 
2019-04-26 19:24:54,033  The global step train is 884
2019-04-26 19:24:54,162  The loss during training is  :: 0.047964926809072495 
2019-04-26 19:24:54,321  The global step train is 885
2019-04-26 19:24:54,445  The loss during training is  :: 0.06359853595495224 
2019-04-26 19:24:54,600  The global step train is 886
2019-04-26 19:24:54,728  The loss during training is  :: 0.06013331189751625 
2019-04-26 19:24:54,891  The global step train is 887
2019-04-26 19:24:55,019  The loss during training is  :: 0.0500628799200058 
2019-04-26 19:24:55,180  The global step train is 888
2019-04-26 19:24:55,311  The loss during training is  :: 0.0776999443769455 
2019-04-26 19:24:55,476  The global step train is 889
2019-04-26 19:24:55,603  The loss during training is  :: 0.03370195999741554 
2019-04-26 19:24:55,769  The global step train is 890
2019-04-26 19:24:55,890  The loss during training is  :: 0.12055771052837372 
2019-04-26 19:24:56,049  The global step train is 891
2019-04-26 19:24:56,176  The loss during training is  :: 0.06941314041614532 
2019-04-26 19:24:56,341  The global step train is 892
2019-04-26 19:24:56,469  The loss during training is  :: 0.06771303713321686 
2019-04-26 19:24:56,623  The global step train is 893
2019-04-26 19:24:56,754  The loss during training is  :: 0.017121566459536552 
2019-04-26 19:24:56,916  The global step train is 894
2019-04-26 19:24:57,045  The loss during training is  :: 0.03337988257408142 
2019-04-26 19:24:57,202  The global step train is 895
2019-04-26 19:24:57,329  The loss during training is  :: 0.023674821481108665 
2019-04-26 19:24:57,494  The global step train is 896
2019-04-26 19:24:57,496  Starting evaluation 
2019-04-26 19:24:57,632  The loss during eval_loss is  :: 0.091431625187397
2019-04-26 19:24:57,634  The global step eval is 169
2019-04-26 19:24:57,766  The loss during eval_loss is  :: 0.0625743642449379
2019-04-26 19:24:57,768  The global step eval is 170
2019-04-26 19:24:57,885  The loss during eval_loss is  :: 0.03614027798175812
2019-04-26 19:24:57,888  The global step eval is 171
2019-04-26 19:24:58,003  The loss during eval_loss is  :: 0.05233204737305641
2019-04-26 19:24:58,005  The global step eval is 172
2019-04-26 19:24:58,117  The loss during eval_loss is  :: 0.08018394559621811
2019-04-26 19:24:58,119  The global step eval is 173
2019-04-26 19:24:58,231  The loss during eval_loss is  :: 0.11780797690153122
2019-04-26 19:24:58,233  The global step eval is 174
2019-04-26 19:24:58,344  The loss during eval_loss is  :: 0.1262543648481369
2019-04-26 19:24:58,345  The global step eval is 175
2019-04-26 19:24:58,453  The loss during eval_loss is  :: 0.015022296458482742
2019-04-26 19:24:58,455  The global step eval is 176
2019-04-26 19:24:58,567  The loss during eval_loss is  :: 0.09177207946777344
2019-04-26 19:24:58,569  The global step eval is 177
2019-04-26 19:24:58,676  The loss during eval_loss is  :: 0.03712503984570503
2019-04-26 19:24:58,677  The global step eval is 178
2019-04-26 19:24:58,781  The loss during eval_loss is  :: 0.10820239037275314
2019-04-26 19:24:58,783  The global step eval is 179
2019-04-26 19:24:58,891  The loss during eval_loss is  :: 0.054154690355062485
2019-04-26 19:24:58,893  The global step eval is 180
2019-04-26 19:24:59,007  The loss during eval_loss is  :: 0.038479533046483994
2019-04-26 19:24:59,009  The global step eval is 181
2019-04-26 19:24:59,131  The loss during eval_loss is  :: 0.05813231319189072
2019-04-26 19:24:59,133  The global step eval is 182
2019-04-26 19:24:59,250  The loss during eval_loss is  :: 0.07878855615854263
2019-04-26 19:24:59,251  The global step eval is 183
2019-04-26 19:24:59,361  The loss during eval_loss is  :: 0.12076665461063385
2019-04-26 19:24:59,363  The global step eval is 184
2019-04-26 19:24:59,481  The loss during eval_loss is  :: 0.09187336266040802
2019-04-26 19:24:59,483  The global step eval is 185
2019-04-26 19:24:59,589  The loss during eval_loss is  :: 0.1512930542230606
2019-04-26 19:24:59,591  The global step eval is 186
2019-04-26 19:24:59,697  The loss during eval_loss is  :: 0.05513043701648712
2019-04-26 19:24:59,699  The global step eval is 187
2019-04-26 19:24:59,817  The loss during eval_loss is  :: 0.07536336034536362
2019-04-26 19:24:59,818  The global step eval is 188
2019-04-26 19:24:59,932  The loss during eval_loss is  :: 0.09443792700767517
2019-04-26 19:24:59,934  The global step eval is 189
2019-04-26 19:25:00,044  The loss during eval_loss is  :: 0.06371380388736725
2019-04-26 19:25:00,045  The global step eval is 190
2019-04-26 19:25:00,157  The loss during eval_loss is  :: 0.04785545542836189
2019-04-26 19:25:00,158  The global step eval is 191
2019-04-26 19:25:00,260  The loss during eval_loss is  :: 0.04753480106592178
2019-04-26 19:25:00,261  The global step eval is 192
2019-04-26 19:25:00,372  The loss during eval_loss is  :: 0.04715060815215111
2019-04-26 19:25:00,374  The global step eval is 193
2019-04-26 19:25:00,485  The loss during eval_loss is  :: 0.039525412023067474
2019-04-26 19:25:00,487  The global step eval is 194
2019-04-26 19:25:00,594  The loss during eval_loss is  :: 0.053731225430965424
2019-04-26 19:25:00,596  The global step eval is 195
2019-04-26 19:25:00,710  The loss during eval_loss is  :: 0.07018222659826279
2019-04-26 19:25:00,712  The global step eval is 196
2019-04-26 19:25:00,815  The loss during eval_loss is  :: 0.06789208948612213
2019-04-26 19:25:00,816  The global step eval is 197
2019-04-26 19:25:00,932  The loss during eval_loss is  :: 0.04198519513010979
2019-04-26 19:25:00,933  The global step eval is 198
2019-04-26 19:25:01,050  The loss during eval_loss is  :: 0.04172395169734955
2019-04-26 19:25:01,052  The global step eval is 199
2019-04-26 19:25:01,166  The loss during eval_loss is  :: 0.10377482324838638
2019-04-26 19:25:01,167  The global step eval is 200
2019-04-26 19:25:01,277  The loss during eval_loss is  :: 0.1160430908203125
2019-04-26 19:25:01,279  The global step eval is 201
2019-04-26 19:25:01,390  The loss during eval_loss is  :: 0.1443866491317749
2019-04-26 19:25:01,392  The global step eval is 202
2019-04-26 19:25:01,492  The loss during eval_loss is  :: 0.06546377390623093
2019-04-26 19:25:01,494  The global step eval is 203
2019-04-26 19:25:01,596  The loss during eval_loss is  :: 0.10190550237894058
2019-04-26 19:25:01,598  The global step eval is 204
2019-04-26 19:25:01,696  The loss during eval_loss is  :: 0.12436040490865707
2019-04-26 19:25:01,698  The global step eval is 205
2019-04-26 19:25:01,808  The loss during eval_loss is  :: 0.07374147325754166
2019-04-26 19:25:01,809  The global step eval is 206
2019-04-26 19:25:01,922  The loss during eval_loss is  :: 0.045334283262491226
2019-04-26 19:25:01,924  The global step eval is 207
2019-04-26 19:25:02,024  The loss during eval_loss is  :: 0.046674568206071854
2019-04-26 19:25:02,026  The global step eval is 208
2019-04-26 19:25:02,140  The loss during eval_loss is  :: 0.07243215292692184
2019-04-26 19:25:02,142  The global step eval is 209
2019-04-26 19:25:02,247  The loss during eval_loss is  :: 0.0487421378493309
2019-04-26 19:25:02,248  The global step eval is 210
2019-04-26 19:25:02,360  The loss during eval_loss is  :: 0.11334694921970367
2019-04-26 19:25:02,362  The global step eval is 211
2019-04-26 19:25:02,473  The loss during eval_loss is  :: 0.059059325605630875
2019-04-26 19:25:02,475  The global step eval is 212
2019-04-26 19:25:02,587  The loss during eval_loss is  :: 0.16611215472221375
2019-04-26 19:25:02,589  The global step eval is 213
2019-04-26 19:25:02,696  The loss during eval_loss is  :: 0.05746534466743469
2019-04-26 19:25:02,698  The global step eval is 214
2019-04-26 19:25:02,817  The loss during eval_loss is  :: 0.10252957791090012
2019-04-26 19:25:02,819  The global step eval is 215
2019-04-26 19:25:02,929  The loss during eval_loss is  :: 0.12353279441595078
2019-04-26 19:25:02,931  The global step eval is 216
2019-04-26 19:25:03,037  The loss during eval_loss is  :: 0.04498130828142166
2019-04-26 19:25:03,038  The global step eval is 217
2019-04-26 19:25:03,149  The loss during eval_loss is  :: 0.12626469135284424
2019-04-26 19:25:03,151  The global step eval is 218
2019-04-26 19:25:03,264  The loss during eval_loss is  :: 0.08361843973398209
2019-04-26 19:25:03,265  The global step eval is 219
2019-04-26 19:25:03,384  The loss during eval_loss is  :: 0.07353702187538147
2019-04-26 19:25:03,385  The global step eval is 220
2019-04-26 19:25:03,533  The loss during eval_loss is  :: 0.0639682337641716
2019-04-26 19:25:03,535  The global step eval is 221
2019-04-26 19:25:03,673  The loss during eval_loss is  :: 0.04715728387236595
2019-04-26 19:25:03,675  The global step eval is 222
2019-04-26 19:25:03,791  The loss during eval_loss is  :: 0.09423460811376572
2019-04-26 19:25:03,793  The global step eval is 223
2019-04-26 19:25:03,915  The loss during eval_loss is  :: 0.05000012740492821
2019-04-26 19:25:03,917  The global step eval is 224
2019-04-26 19:25:03,928  Saved checkpoint: ./trained_model\step_3.pth.tar
2019-04-26 19:25:04,039  The loss during training is  :: 0.1497390866279602 
2019-04-26 19:25:04,192  The global step train is 897
2019-04-26 19:25:04,318  The loss during training is  :: 0.03579012304544449 
2019-04-26 19:25:04,478  The global step train is 898
2019-04-26 19:25:04,617  The loss during training is  :: 0.12453394383192062 
2019-04-26 19:25:04,786  The global step train is 899
2019-04-26 19:25:04,912  The loss during training is  :: 0.0414464995265007 
2019-04-26 19:25:05,074  The global step train is 900
2019-04-26 19:25:05,204  The loss during training is  :: 0.03613312542438507 
2019-04-26 19:25:05,366  The global step train is 901
2019-04-26 19:25:05,496  The loss during training is  :: 0.1110140010714531 
2019-04-26 19:25:05,657  The global step train is 902
2019-04-26 19:25:05,780  The loss during training is  :: 0.05986994877457619 
2019-04-26 19:25:05,939  The global step train is 903
2019-04-26 19:25:06,070  The loss during training is  :: 0.0715312659740448 
2019-04-26 19:25:06,235  The global step train is 904
2019-04-26 19:25:06,363  The loss during training is  :: 0.06469134986400604 
2019-04-26 19:25:06,522  The global step train is 905
2019-04-26 19:25:06,646  The loss during training is  :: 0.09750773012638092 
2019-04-26 19:25:06,809  The global step train is 906
2019-04-26 19:25:06,935  The loss during training is  :: 0.05152881145477295 
2019-04-26 19:25:07,096  The global step train is 907
2019-04-26 19:25:07,227  The loss during training is  :: 0.08604574203491211 
2019-04-26 19:25:07,392  The global step train is 908
2019-04-26 19:25:07,520  The loss during training is  :: 0.08393697440624237 
2019-04-26 19:25:07,683  The global step train is 909
2019-04-26 19:25:07,815  The loss during training is  :: 0.030972572043538094 
2019-04-26 19:25:07,979  The global step train is 910
2019-04-26 19:25:08,109  The loss during training is  :: 0.026382487267255783 
2019-04-26 19:25:08,272  The global step train is 911
2019-04-26 19:25:08,402  The loss during training is  :: 0.031152969226241112 
2019-04-26 19:25:08,568  The global step train is 912
2019-04-26 19:25:08,697  The loss during training is  :: 0.07614409923553467 
2019-04-26 19:25:08,863  The global step train is 913
2019-04-26 19:25:08,991  The loss during training is  :: 0.05668186768889427 
2019-04-26 19:25:09,154  The global step train is 914
2019-04-26 19:25:09,288  The loss during training is  :: 0.051732782274484634 
2019-04-26 19:25:09,451  The global step train is 915
2019-04-26 19:25:09,578  The loss during training is  :: 0.08417467772960663 
2019-04-26 19:25:09,739  The global step train is 916
2019-04-26 19:25:09,867  The loss during training is  :: 0.04126696661114693 
2019-04-26 19:25:10,027  The global step train is 917
2019-04-26 19:25:10,157  The loss during training is  :: 0.1216675341129303 
2019-04-26 19:25:10,318  The global step train is 918
2019-04-26 19:25:10,447  The loss during training is  :: 0.0493624210357666 
2019-04-26 19:25:10,608  The global step train is 919
2019-04-26 19:25:10,737  The loss during training is  :: 0.04145020991563797 
2019-04-26 19:25:10,899  The global step train is 920
2019-04-26 19:25:11,032  The loss during training is  :: 0.0759444385766983 
2019-04-26 19:25:11,191  The global step train is 921
2019-04-26 19:25:11,326  The loss during training is  :: 0.019913438707590103 
2019-04-26 19:25:11,491  The global step train is 922
2019-04-26 19:25:11,630  The loss during training is  :: 0.0779242217540741 
2019-04-26 19:25:11,798  The global step train is 923
2019-04-26 19:25:11,936  The loss during training is  :: 0.027181755751371384 
2019-04-26 19:25:12,106  The global step train is 924
2019-04-26 19:25:12,241  The loss during training is  :: 0.08334248512983322 
2019-04-26 19:25:12,402  The global step train is 925
2019-04-26 19:25:12,533  The loss during training is  :: 0.03214169293642044 
2019-04-26 19:25:12,695  The global step train is 926
2019-04-26 19:25:12,819  The loss during training is  :: 0.09470105171203613 
2019-04-26 19:25:12,985  The global step train is 927
2019-04-26 19:25:13,116  The loss during training is  :: 0.12850333750247955 
2019-04-26 19:25:13,282  The global step train is 928
2019-04-26 19:25:13,409  The loss during training is  :: 0.08952421694993973 
2019-04-26 19:25:13,568  The global step train is 929
2019-04-26 19:25:13,698  The loss during training is  :: 0.03071458265185356 
2019-04-26 19:25:13,862  The global step train is 930
2019-04-26 19:25:13,987  The loss during training is  :: 0.10826881229877472 
2019-04-26 19:25:14,149  The global step train is 931
2019-04-26 19:25:14,271  The loss during training is  :: 0.041075315326452255 
2019-04-26 19:25:14,430  The global step train is 932
2019-04-26 19:25:14,562  The loss during training is  :: 0.11620774865150452 
2019-04-26 19:25:14,727  The global step train is 933
2019-04-26 19:25:14,854  The loss during training is  :: 0.11747045814990997 
2019-04-26 19:25:15,017  The global step train is 934
2019-04-26 19:25:15,145  The loss during training is  :: 0.0901651605963707 
2019-04-26 19:25:15,307  The global step train is 935
2019-04-26 19:25:15,436  The loss during training is  :: 0.05553264543414116 
2019-04-26 19:25:15,594  The global step train is 936
2019-04-26 19:25:15,718  The loss during training is  :: 0.05976219102740288 
2019-04-26 19:25:15,882  The global step train is 937
2019-04-26 19:25:16,009  The loss during training is  :: 0.03049018792808056 
2019-04-26 19:25:16,166  The global step train is 938
2019-04-26 19:25:16,294  The loss during training is  :: 0.053002629429101944 
2019-04-26 19:25:16,458  The global step train is 939
2019-04-26 19:25:16,586  The loss during training is  :: 0.08138377219438553 
2019-04-26 19:25:16,746  The global step train is 940
2019-04-26 19:25:16,872  The loss during training is  :: 0.0512692891061306 
2019-04-26 19:25:17,034  The global step train is 941
2019-04-26 19:25:17,166  The loss during training is  :: 0.02068130485713482 
2019-04-26 19:25:17,330  The global step train is 942
2019-04-26 19:25:17,459  The loss during training is  :: 0.08795583993196487 
2019-04-26 19:25:17,619  The global step train is 943
2019-04-26 19:25:17,750  The loss during training is  :: 0.06804721057415009 
2019-04-26 19:25:17,911  The global step train is 944
2019-04-26 19:25:18,040  The loss during training is  :: 0.07239897549152374 
2019-04-26 19:25:18,197  The global step train is 945
2019-04-26 19:25:18,325  The loss during training is  :: 0.057605940848588943 
2019-04-26 19:25:18,487  The global step train is 946
2019-04-26 19:25:18,615  The loss during training is  :: 0.11687451601028442 
2019-04-26 19:25:18,774  The global step train is 947
2019-04-26 19:25:18,904  The loss during training is  :: 0.055626168847084045 
2019-04-26 19:25:19,068  The global step train is 948
2019-04-26 19:25:19,196  The loss during training is  :: 0.04935561493039131 
2019-04-26 19:25:19,359  The global step train is 949
2019-04-26 19:25:19,487  The loss during training is  :: 0.06346002221107483 
2019-04-26 19:25:19,646  The global step train is 950
2019-04-26 19:25:19,773  The loss during training is  :: 0.05351746082305908 
2019-04-26 19:25:19,938  The global step train is 951
2019-04-26 19:25:20,064  The loss during training is  :: 0.04989861324429512 
2019-04-26 19:25:20,233  The global step train is 952
2019-04-26 19:25:20,373  The loss during training is  :: 0.04670264571905136 
2019-04-26 19:25:20,543  The global step train is 953
2019-04-26 19:25:20,684  The loss during training is  :: 0.08842699229717255 
2019-04-26 19:25:20,855  The global step train is 954
2019-04-26 19:25:20,995  The loss during training is  :: 0.08389510959386826 
2019-04-26 19:25:21,168  The global step train is 955
2019-04-26 19:25:21,307  The loss during training is  :: 0.04269493371248245 
2019-04-26 19:25:21,478  The global step train is 956
2019-04-26 19:25:21,618  The loss during training is  :: 0.03811775892972946 
2019-04-26 19:25:21,786  The global step train is 957
2019-04-26 19:25:21,926  The loss during training is  :: 0.033327680081129074 
2019-04-26 19:25:22,094  The global step train is 958
2019-04-26 19:25:22,236  The loss during training is  :: 0.05646897479891777 
2019-04-26 19:25:22,406  The global step train is 959
2019-04-26 19:25:22,545  The loss during training is  :: 0.0847245380282402 
2019-04-26 19:25:22,715  The global step train is 960
2019-04-26 19:25:22,849  The loss during training is  :: 0.04344121366739273 
2019-04-26 19:25:23,014  The global step train is 961
2019-04-26 19:25:23,146  The loss during training is  :: 0.08712253719568253 
2019-04-26 19:25:23,305  The global step train is 962
2019-04-26 19:25:23,438  The loss during training is  :: 0.05988084152340889 
2019-04-26 19:25:23,600  The global step train is 963
2019-04-26 19:25:23,728  The loss during training is  :: 0.09592188149690628 
2019-04-26 19:25:23,891  The global step train is 964
2019-04-26 19:25:24,020  The loss during training is  :: 0.04070121794939041 
2019-04-26 19:25:24,183  The global step train is 965
2019-04-26 19:25:24,314  The loss during training is  :: 0.07561086863279343 
2019-04-26 19:25:24,471  The global step train is 966
2019-04-26 19:25:24,600  The loss during training is  :: 0.03743164986371994 
2019-04-26 19:25:24,762  The global step train is 967
2019-04-26 19:25:24,894  The loss during training is  :: 0.10993635654449463 
2019-04-26 19:25:25,056  The global step train is 968
2019-04-26 19:25:25,185  The loss during training is  :: 0.06400357931852341 
2019-04-26 19:25:25,346  The global step train is 969
2019-04-26 19:25:25,477  The loss during training is  :: 0.02800324745476246 
2019-04-26 19:25:25,634  The global step train is 970
2019-04-26 19:25:25,758  The loss during training is  :: 0.036987755447626114 
2019-04-26 19:25:25,918  The global step train is 971
2019-04-26 19:25:26,045  The loss during training is  :: 0.06256067007780075 
2019-04-26 19:25:26,207  The global step train is 972
2019-04-26 19:25:26,341  The loss during training is  :: 0.10604720562696457 
2019-04-26 19:25:26,493  The global step train is 973
2019-04-26 19:25:26,620  The loss during training is  :: 0.04716170206665993 
2019-04-26 19:25:26,781  The global step train is 974
2019-04-26 19:25:26,907  The loss during training is  :: 0.04256335273385048 
2019-04-26 19:25:27,068  The global step train is 975
2019-04-26 19:25:27,203  The loss during training is  :: 0.04112907871603966 
2019-04-26 19:25:27,369  The global step train is 976
2019-04-26 19:25:27,499  The loss during training is  :: 0.07805781066417694 
2019-04-26 19:25:27,657  The global step train is 977
2019-04-26 19:25:27,790  The loss during training is  :: 0.09808235615491867 
2019-04-26 19:25:27,953  The global step train is 978
2019-04-26 19:25:28,079  The loss during training is  :: 0.03342370688915253 
2019-04-26 19:25:28,239  The global step train is 979
2019-04-26 19:25:28,369  The loss during training is  :: 0.07838770747184753 
2019-04-26 19:25:28,528  The global step train is 980
2019-04-26 19:25:28,656  The loss during training is  :: 0.0249310415238142 
2019-04-26 19:25:28,818  The global step train is 981
2019-04-26 19:25:28,948  The loss during training is  :: 0.051121730357408524 
2019-04-26 19:25:29,107  The global step train is 982
2019-04-26 19:25:29,232  The loss during training is  :: 0.043649688363075256 
2019-04-26 19:25:29,396  The global step train is 983
2019-04-26 19:25:29,525  The loss during training is  :: 0.15301677584648132 
2019-04-26 19:25:29,689  The global step train is 984
2019-04-26 19:25:29,817  The loss during training is  :: 0.018419688567519188 
2019-04-26 19:25:29,981  The global step train is 985
2019-04-26 19:25:30,110  The loss during training is  :: 0.06424203515052795 
2019-04-26 19:25:30,276  The global step train is 986
2019-04-26 19:25:30,407  The loss during training is  :: 0.06205610930919647 
2019-04-26 19:25:30,567  The global step train is 987
2019-04-26 19:25:30,692  The loss during training is  :: 0.12924809753894806 
2019-04-26 19:25:30,851  The global step train is 988
2019-04-26 19:25:30,978  The loss during training is  :: 0.026169616729021072 
2019-04-26 19:25:31,133  The global step train is 989
2019-04-26 19:25:31,259  The loss during training is  :: 0.0512668676674366 
2019-04-26 19:25:31,419  The global step train is 990
2019-04-26 19:25:31,541  The loss during training is  :: 0.040492672473192215 
2019-04-26 19:25:31,706  The global step train is 991
2019-04-26 19:25:31,834  The loss during training is  :: 0.03212614357471466 
2019-04-26 19:25:31,995  The global step train is 992
2019-04-26 19:25:32,125  The loss during training is  :: 0.08358463644981384 
2019-04-26 19:25:32,289  The global step train is 993
2019-04-26 19:25:32,418  The loss during training is  :: 0.06106726825237274 
2019-04-26 19:25:32,578  The global step train is 994
2019-04-26 19:25:32,708  The loss during training is  :: 0.09266522526741028 
2019-04-26 19:25:32,866  The global step train is 995
2019-04-26 19:25:32,994  The loss during training is  :: 0.04463454335927963 
2019-04-26 19:25:33,158  The global step train is 996
2019-04-26 19:25:33,289  The loss during training is  :: 0.1803380846977234 
2019-04-26 19:25:33,454  The global step train is 997
2019-04-26 19:25:33,578  The loss during training is  :: 0.08995084464550018 
2019-04-26 19:25:33,739  The global step train is 998
2019-04-26 19:25:33,868  The loss during training is  :: 0.05910663679242134 
2019-04-26 19:25:34,026  The global step train is 999
2019-04-26 19:25:34,156  The loss during training is  :: 0.04890745133161545 
2019-04-26 19:25:34,319  The global step train is 1000
2019-04-26 19:25:34,444  The loss during training is  :: 0.04782262444496155 
2019-04-26 19:25:34,607  The global step train is 1001
2019-04-26 19:25:34,735  The loss during training is  :: 0.07011719048023224 
2019-04-26 19:25:34,897  The global step train is 1002
2019-04-26 19:25:35,029  The loss during training is  :: 0.054804619401693344 
2019-04-26 19:25:35,186  The global step train is 1003
2019-04-26 19:25:35,318  The loss during training is  :: 0.03572159633040428 
2019-04-26 19:25:35,479  The global step train is 1004
2019-04-26 19:25:35,598  The loss during training is  :: 0.0554596446454525 
2019-04-26 19:25:35,764  The global step train is 1005
2019-04-26 19:25:35,897  The loss during training is  :: 0.11086499691009521 
2019-04-26 19:25:36,057  The global step train is 1006
2019-04-26 19:25:36,188  The loss during training is  :: 0.06168917939066887 
2019-04-26 19:25:36,350  The global step train is 1007
2019-04-26 19:25:36,483  The loss during training is  :: 0.06078273057937622 
2019-04-26 19:25:36,645  The global step train is 1008
2019-04-26 19:25:36,776  The loss during training is  :: 0.06277741491794586 
2019-04-26 19:25:36,937  The global step train is 1009
2019-04-26 19:25:37,065  The loss during training is  :: 0.098836250603199 
2019-04-26 19:25:37,231  The global step train is 1010
2019-04-26 19:25:37,361  The loss during training is  :: 0.04952998459339142 
2019-04-26 19:25:37,518  The global step train is 1011
2019-04-26 19:25:37,647  The loss during training is  :: 0.11637797951698303 
2019-04-26 19:25:37,807  The global step train is 1012
2019-04-26 19:25:37,936  The loss during training is  :: 0.07308779656887054 
2019-04-26 19:25:38,095  The global step train is 1013
2019-04-26 19:25:38,229  The loss during training is  :: 0.10981091856956482 
2019-04-26 19:25:38,392  The global step train is 1014
2019-04-26 19:25:38,516  The loss during training is  :: 0.10448388010263443 
2019-04-26 19:25:38,679  The global step train is 1015
2019-04-26 19:25:38,810  The loss during training is  :: 0.040206391364336014 
2019-04-26 19:25:38,972  The global step train is 1016
2019-04-26 19:25:39,100  The loss during training is  :: 0.03203138709068298 
2019-04-26 19:25:39,263  The global step train is 1017
2019-04-26 19:25:39,387  The loss during training is  :: 0.10954874753952026 
2019-04-26 19:25:39,546  The global step train is 1018
2019-04-26 19:25:39,663  The loss during training is  :: 0.046419523656368256 
2019-04-26 19:25:39,829  The global step train is 1019
2019-04-26 19:25:39,955  The loss during training is  :: 0.03395562618970871 
2019-04-26 19:25:40,114  The global step train is 1020
2019-04-26 19:25:40,243  The loss during training is  :: 0.09902693331241608 
2019-04-26 19:25:40,402  The global step train is 1021
2019-04-26 19:25:40,529  The loss during training is  :: 0.019816003739833832 
2019-04-26 19:25:40,686  The global step train is 1022
2019-04-26 19:25:40,817  The loss during training is  :: 0.07258990406990051 
2019-04-26 19:25:40,974  The global step train is 1023
2019-04-26 19:25:41,106  The loss during training is  :: 0.028030328452587128 
2019-04-26 19:25:41,267  The global step train is 1024
2019-04-26 19:25:41,395  The loss during training is  :: 0.05040678009390831 
2019-04-26 19:25:41,554  The global step train is 1025
2019-04-26 19:25:41,683  The loss during training is  :: 0.08251668512821198 
2019-04-26 19:25:41,845  The global step train is 1026
2019-04-26 19:25:41,977  The loss during training is  :: 0.07433688640594482 
2019-04-26 19:25:42,139  The global step train is 1027
2019-04-26 19:25:42,265  The loss during training is  :: 0.0900694876909256 
2019-04-26 19:25:42,429  The global step train is 1028
2019-04-26 19:25:42,549  The loss during training is  :: 0.0646381601691246 
2019-04-26 19:25:42,704  The global step train is 1029
2019-04-26 19:25:42,836  The loss during training is  :: 0.023623883724212646 
2019-04-26 19:25:42,997  The global step train is 1030
2019-04-26 19:25:43,130  The loss during training is  :: 0.05277508124709129 
2019-04-26 19:25:43,293  The global step train is 1031
2019-04-26 19:25:43,424  The loss during training is  :: 0.05777527019381523 
2019-04-26 19:25:43,588  The global step train is 1032
2019-04-26 19:25:43,715  The loss during training is  :: 0.04166204109787941 
2019-04-26 19:25:43,877  The global step train is 1033
2019-04-26 19:25:44,002  The loss during training is  :: 0.03907142952084541 
2019-04-26 19:25:44,163  The global step train is 1034
2019-04-26 19:25:44,295  The loss during training is  :: 0.0408257320523262 
2019-04-26 19:25:44,451  The global step train is 1035
2019-04-26 19:25:44,580  The loss during training is  :: 0.09701991081237793 
2019-04-26 19:25:44,736  The global step train is 1036
2019-04-26 19:25:44,864  The loss during training is  :: 0.04757305607199669 
2019-04-26 19:25:45,026  The global step train is 1037
2019-04-26 19:25:45,156  The loss during training is  :: 0.020795123651623726 
2019-04-26 19:25:45,317  The global step train is 1038
2019-04-26 19:25:45,448  The loss during training is  :: 0.03971792384982109 
2019-04-26 19:25:45,611  The global step train is 1039
2019-04-26 19:25:45,736  The loss during training is  :: 0.028243055567145348 
2019-04-26 19:25:45,900  The global step train is 1040
2019-04-26 19:25:46,027  The loss during training is  :: 0.02044803649187088 
2019-04-26 19:25:46,186  The global step train is 1041
2019-04-26 19:25:46,316  The loss during training is  :: 0.08172450959682465 
2019-04-26 19:25:46,477  The global step train is 1042
2019-04-26 19:25:46,606  The loss during training is  :: 0.11093106865882874 
2019-04-26 19:25:46,763  The global step train is 1043
2019-04-26 19:25:46,893  The loss during training is  :: 0.03493520990014076 
2019-04-26 19:25:47,056  The global step train is 1044
2019-04-26 19:25:47,185  The loss during training is  :: 0.019926993176341057 
2019-04-26 19:25:47,348  The global step train is 1045
2019-04-26 19:25:47,478  The loss during training is  :: 0.08016802370548248 
2019-04-26 19:25:47,642  The global step train is 1046
2019-04-26 19:25:47,768  The loss during training is  :: 0.06694045662879944 
2019-04-26 19:25:47,928  The global step train is 1047
2019-04-26 19:25:48,059  The loss during training is  :: 0.054585013538599014 
2019-04-26 19:25:48,218  The global step train is 1048
2019-04-26 19:25:48,346  The loss during training is  :: 0.018210461363196373 
2019-04-26 19:25:48,510  The global step train is 1049
2019-04-26 19:25:48,636  The loss during training is  :: 0.11437205225229263 
2019-04-26 19:25:48,795  The global step train is 1050
2019-04-26 19:25:48,920  The loss during training is  :: 0.05844247341156006 
2019-04-26 19:25:49,080  The global step train is 1051
2019-04-26 19:25:49,203  The loss during training is  :: 0.0574980303645134 
2019-04-26 19:25:49,364  The global step train is 1052
2019-04-26 19:25:49,490  The loss during training is  :: 0.03417680785059929 
2019-04-26 19:25:49,645  The global step train is 1053
2019-04-26 19:25:49,776  The loss during training is  :: 0.05446469038724899 
2019-04-26 19:25:49,940  The global step train is 1054
2019-04-26 19:25:50,067  The loss during training is  :: 0.057219360023736954 
2019-04-26 19:25:50,238  The global step train is 1055
2019-04-26 19:25:50,371  The loss during training is  :: 0.06187283247709274 
2019-04-26 19:25:50,538  The global step train is 1056
2019-04-26 19:25:50,669  The loss during training is  :: 0.029973912984132767 
2019-04-26 19:25:50,830  The global step train is 1057
2019-04-26 19:25:50,962  The loss during training is  :: 0.05057588219642639 
2019-04-26 19:25:51,123  The global step train is 1058
2019-04-26 19:25:51,256  The loss during training is  :: 0.051711808890104294 
2019-04-26 19:25:51,416  The global step train is 1059
2019-04-26 19:25:51,542  The loss during training is  :: 0.11950983852148056 
2019-04-26 19:25:51,702  The global step train is 1060
2019-04-26 19:25:51,832  The loss during training is  :: 0.06754609197378159 
2019-04-26 19:25:51,993  The global step train is 1061
2019-04-26 19:25:52,123  The loss during training is  :: 0.0902044028043747 
2019-04-26 19:25:52,277  The global step train is 1062
2019-04-26 19:25:52,406  The loss during training is  :: 0.04754199832677841 
2019-04-26 19:25:52,565  The global step train is 1063
2019-04-26 19:25:52,690  The loss during training is  :: 0.10355227440595627 
2019-04-26 19:25:52,854  The global step train is 1064
2019-04-26 19:25:52,985  The loss during training is  :: 0.02319907583296299 
2019-04-26 19:25:53,155  The global step train is 1065
2019-04-26 19:25:53,289  The loss during training is  :: 0.04372935742139816 
2019-04-26 19:25:53,449  The global step train is 1066
2019-04-26 19:25:53,578  The loss during training is  :: 0.04269210994243622 
2019-04-26 19:25:53,743  The global step train is 1067
2019-04-26 19:25:53,874  The loss during training is  :: 0.0591125413775444 
2019-04-26 19:25:54,039  The global step train is 1068
2019-04-26 19:25:54,163  The loss during training is  :: 0.04609408229589462 
2019-04-26 19:25:54,324  The global step train is 1069
2019-04-26 19:25:54,455  The loss during training is  :: 0.03518161177635193 
2019-04-26 19:25:54,622  The global step train is 1070
2019-04-26 19:25:54,743  The loss during training is  :: 0.044999416917562485 
2019-04-26 19:25:54,906  The global step train is 1071
2019-04-26 19:25:55,034  The loss during training is  :: 0.08780980110168457 
2019-04-26 19:25:55,195  The global step train is 1072
2019-04-26 19:25:55,324  The loss during training is  :: 0.02834436669945717 
2019-04-26 19:25:55,482  The global step train is 1073
2019-04-26 19:25:55,609  The loss during training is  :: 0.06820034235715866 
2019-04-26 19:25:55,766  The global step train is 1074
2019-04-26 19:25:55,895  The loss during training is  :: 0.0708700641989708 
2019-04-26 19:25:56,056  The global step train is 1075
2019-04-26 19:25:56,186  The loss during training is  :: 0.042861126363277435 
2019-04-26 19:25:56,348  The global step train is 1076
2019-04-26 19:25:56,474  The loss during training is  :: 0.03032795898616314 
2019-04-26 19:25:56,631  The global step train is 1077
2019-04-26 19:25:56,761  The loss during training is  :: 0.05726978927850723 
2019-04-26 19:25:56,925  The global step train is 1078
2019-04-26 19:25:57,056  The loss during training is  :: 0.06676653772592545 
2019-04-26 19:25:57,217  The global step train is 1079
2019-04-26 19:25:57,345  The loss during training is  :: 0.02099945954978466 
2019-04-26 19:25:57,505  The global step train is 1080
2019-04-26 19:25:57,634  The loss during training is  :: 0.0674753338098526 
2019-04-26 19:25:57,797  The global step train is 1081
2019-04-26 19:25:57,929  The loss during training is  :: 0.04257597774267197 
2019-04-26 19:25:58,085  The global step train is 1082
2019-04-26 19:25:58,219  The loss during training is  :: 0.09098132699728012 
2019-04-26 19:25:58,385  The global step train is 1083
2019-04-26 19:25:58,518  The loss during training is  :: 0.10005760192871094 
2019-04-26 19:25:58,680  The global step train is 1084
2019-04-26 19:25:58,810  The loss during training is  :: 0.03560104966163635 
2019-04-26 19:25:58,972  The global step train is 1085
2019-04-26 19:25:59,102  The loss during training is  :: 0.11329378932714462 
2019-04-26 19:25:59,268  The global step train is 1086
2019-04-26 19:25:59,395  The loss during training is  :: 0.035290151834487915 
2019-04-26 19:25:59,553  The global step train is 1087
2019-04-26 19:25:59,682  The loss during training is  :: 0.033175066113471985 
2019-04-26 19:25:59,837  The global step train is 1088
2019-04-26 19:25:59,960  The loss during training is  :: 0.05714940279722214 
2019-04-26 19:26:00,122  The global step train is 1089
2019-04-26 19:26:00,254  The loss during training is  :: 0.03246757388114929 
2019-04-26 19:26:00,417  The global step train is 1090
2019-04-26 19:26:00,543  The loss during training is  :: 0.05779873579740524 
2019-04-26 19:26:00,705  The global step train is 1091
2019-04-26 19:26:00,836  The loss during training is  :: 0.04762817919254303 
2019-04-26 19:26:00,993  The global step train is 1092
2019-04-26 19:26:01,125  The loss during training is  :: 0.015187189914286137 
2019-04-26 19:26:01,288  The global step train is 1093
2019-04-26 19:26:01,415  The loss during training is  :: 0.014870443381369114 
2019-04-26 19:26:01,575  The global step train is 1094
2019-04-26 19:26:01,703  The loss during training is  :: 0.08620298653841019 
2019-04-26 19:26:01,867  The global step train is 1095
2019-04-26 19:26:01,993  The loss during training is  :: 0.09014558047056198 
2019-04-26 19:26:02,150  The global step train is 1096
2019-04-26 19:26:02,276  The loss during training is  :: 0.12081937491893768 
2019-04-26 19:26:02,441  The global step train is 1097
2019-04-26 19:26:02,574  The loss during training is  :: 0.07486392557621002 
2019-04-26 19:26:02,736  The global step train is 1098
2019-04-26 19:26:02,866  The loss during training is  :: 0.09165669977664948 
2019-04-26 19:26:03,030  The global step train is 1099
2019-04-26 19:26:03,160  The loss during training is  :: 0.20200707018375397 
2019-04-26 19:26:03,321  The global step train is 1100
2019-04-26 19:26:03,452  The loss during training is  :: 0.09845614433288574 
2019-04-26 19:26:03,613  The global step train is 1101
2019-04-26 19:26:03,746  The loss during training is  :: 0.0871269553899765 
2019-04-26 19:26:03,918  The global step train is 1102
2019-04-26 19:26:04,044  The loss during training is  :: 0.05230958014726639 
2019-04-26 19:26:04,204  The global step train is 1103
2019-04-26 19:26:04,339  The loss during training is  :: 0.026149295270442963 
2019-04-26 19:26:04,502  The global step train is 1104
2019-04-26 19:26:04,627  The loss during training is  :: 0.06947445869445801 
2019-04-26 19:26:04,793  The global step train is 1105
2019-04-26 19:26:04,920  The loss during training is  :: 0.039150599390268326 
2019-04-26 19:26:05,079  The global step train is 1106
2019-04-26 19:26:05,209  The loss during training is  :: 0.06262901425361633 
2019-04-26 19:26:05,371  The global step train is 1107
2019-04-26 19:26:05,498  The loss during training is  :: 0.05813300609588623 
2019-04-26 19:26:05,659  The global step train is 1108
2019-04-26 19:26:05,790  The loss during training is  :: 0.15623053908348083 
2019-04-26 19:26:05,952  The global step train is 1109
2019-04-26 19:26:06,082  The loss during training is  :: 0.05910569056868553 
2019-04-26 19:26:06,246  The global step train is 1110
2019-04-26 19:26:06,378  The loss during training is  :: 0.06416631489992142 
2019-04-26 19:26:06,545  The global step train is 1111
2019-04-26 19:26:06,669  The loss during training is  :: 0.06713059544563293 
2019-04-26 19:26:06,833  The global step train is 1112
2019-04-26 19:26:06,960  The loss during training is  :: 0.019166195765137672 
2019-04-26 19:26:07,127  The global step train is 1113
2019-04-26 19:26:07,256  The loss during training is  :: 0.02947501465678215 
2019-04-26 19:26:07,419  The global step train is 1114
2019-04-26 19:26:07,546  The loss during training is  :: 0.08861208707094193 
2019-04-26 19:26:07,707  The global step train is 1115
2019-04-26 19:26:07,832  The loss during training is  :: 0.13155141472816467 
2019-04-26 19:26:07,995  The global step train is 1116
2019-04-26 19:26:08,120  The loss during training is  :: 0.052501436322927475 
2019-04-26 19:26:08,289  The global step train is 1117
2019-04-26 19:26:08,419  The loss during training is  :: 0.07192803174257278 
2019-04-26 19:26:08,572  The global step train is 1118
2019-04-26 19:26:08,697  The loss during training is  :: 0.07426190376281738 
2019-04-26 19:26:08,862  The global step train is 1119
2019-04-26 19:26:08,992  The loss during training is  :: 0.13088631629943848 
2019-04-26 19:26:09,155  The global step train is 1120
2019-04-26 19:26:09,157  Starting evaluation 
2019-04-26 19:26:09,301  The loss during eval_loss is  :: 0.08344373852014542
2019-04-26 19:26:09,303  The global step eval is 225
2019-04-26 19:26:09,426  The loss during eval_loss is  :: 0.05212601274251938
2019-04-26 19:26:09,428  The global step eval is 226
2019-04-26 19:26:09,538  The loss during eval_loss is  :: 0.03052796609699726
2019-04-26 19:26:09,540  The global step eval is 227
2019-04-26 19:26:09,647  The loss during eval_loss is  :: 0.041767023503780365
2019-04-26 19:26:09,649  The global step eval is 228
2019-04-26 19:26:09,762  The loss during eval_loss is  :: 0.07950565218925476
2019-04-26 19:26:09,764  The global step eval is 229
2019-04-26 19:26:09,881  The loss during eval_loss is  :: 0.09829968214035034
2019-04-26 19:26:09,883  The global step eval is 230
2019-04-26 19:26:09,986  The loss during eval_loss is  :: 0.12183387577533722
2019-04-26 19:26:09,988  The global step eval is 231
2019-04-26 19:26:10,108  The loss during eval_loss is  :: 0.016207825392484665
2019-04-26 19:26:10,109  The global step eval is 232
2019-04-26 19:26:10,218  The loss during eval_loss is  :: 0.11793937534093857
2019-04-26 19:26:10,221  The global step eval is 233
2019-04-26 19:26:10,332  The loss during eval_loss is  :: 0.033099714666604996
2019-04-26 19:26:10,334  The global step eval is 234
2019-04-26 19:26:10,445  The loss during eval_loss is  :: 0.12469484657049179
2019-04-26 19:26:10,447  The global step eval is 235
2019-04-26 19:26:10,552  The loss during eval_loss is  :: 0.05992668867111206
2019-04-26 19:26:10,553  The global step eval is 236
2019-04-26 19:26:10,663  The loss during eval_loss is  :: 0.032637447118759155
2019-04-26 19:26:10,665  The global step eval is 237
2019-04-26 19:26:10,777  The loss during eval_loss is  :: 0.0588872991502285
2019-04-26 19:26:10,779  The global step eval is 238
2019-04-26 19:26:10,884  The loss during eval_loss is  :: 0.08668405562639236
2019-04-26 19:26:10,887  The global step eval is 239
2019-04-26 19:26:10,991  The loss during eval_loss is  :: 0.11884219199419022
2019-04-26 19:26:10,993  The global step eval is 240
2019-04-26 19:26:11,101  The loss during eval_loss is  :: 0.09613503515720367
2019-04-26 19:26:11,103  The global step eval is 241
2019-04-26 19:26:11,210  The loss during eval_loss is  :: 0.16774702072143555
2019-04-26 19:26:11,212  The global step eval is 242
2019-04-26 19:26:11,327  The loss during eval_loss is  :: 0.05382018908858299
2019-04-26 19:26:11,328  The global step eval is 243
2019-04-26 19:26:11,440  The loss during eval_loss is  :: 0.06597284972667694
2019-04-26 19:26:11,441  The global step eval is 244
2019-04-26 19:26:11,557  The loss during eval_loss is  :: 0.08253786712884903
2019-04-26 19:26:11,559  The global step eval is 245
2019-04-26 19:26:11,660  The loss during eval_loss is  :: 0.06640437245368958
2019-04-26 19:26:11,662  The global step eval is 246
2019-04-26 19:26:11,781  The loss during eval_loss is  :: 0.05390841141343117
2019-04-26 19:26:11,783  The global step eval is 247
2019-04-26 19:26:11,885  The loss during eval_loss is  :: 0.07261274009943008
2019-04-26 19:26:11,887  The global step eval is 248
2019-04-26 19:26:11,988  The loss during eval_loss is  :: 0.048557378351688385
2019-04-26 19:26:11,990  The global step eval is 249
2019-04-26 19:26:12,105  The loss during eval_loss is  :: 0.042654912918806076
2019-04-26 19:26:12,107  The global step eval is 250
2019-04-26 19:26:12,208  The loss during eval_loss is  :: 0.07556944340467453
2019-04-26 19:26:12,210  The global step eval is 251
2019-04-26 19:26:12,323  The loss during eval_loss is  :: 0.06518617272377014
2019-04-26 19:26:12,325  The global step eval is 252
2019-04-26 19:26:12,434  The loss during eval_loss is  :: 0.0729743167757988
2019-04-26 19:26:12,436  The global step eval is 253
2019-04-26 19:26:12,534  The loss during eval_loss is  :: 0.06166065111756325
2019-04-26 19:26:12,536  The global step eval is 254
2019-04-26 19:26:12,649  The loss during eval_loss is  :: 0.04429701343178749
2019-04-26 19:26:12,651  The global step eval is 255
2019-04-26 19:26:12,765  The loss during eval_loss is  :: 0.09344102442264557
2019-04-26 19:26:12,767  The global step eval is 256
2019-04-26 19:26:12,882  The loss during eval_loss is  :: 0.09174802899360657
2019-04-26 19:26:12,884  The global step eval is 257
2019-04-26 19:26:12,995  The loss during eval_loss is  :: 0.1448241025209427
2019-04-26 19:26:12,997  The global step eval is 258
2019-04-26 19:26:13,109  The loss during eval_loss is  :: 0.05027960240840912
2019-04-26 19:26:13,111  The global step eval is 259
2019-04-26 19:26:13,217  The loss during eval_loss is  :: 0.09763122349977493
2019-04-26 19:26:13,219  The global step eval is 260
2019-04-26 19:26:13,328  The loss during eval_loss is  :: 0.10267467796802521
2019-04-26 19:26:13,330  The global step eval is 261
2019-04-26 19:26:13,440  The loss during eval_loss is  :: 0.07353192567825317
2019-04-26 19:26:13,442  The global step eval is 262
2019-04-26 19:26:13,553  The loss during eval_loss is  :: 0.03595651313662529
2019-04-26 19:26:13,555  The global step eval is 263
2019-04-26 19:26:13,661  The loss during eval_loss is  :: 0.03387552127242088
2019-04-26 19:26:13,663  The global step eval is 264
2019-04-26 19:26:13,762  The loss during eval_loss is  :: 0.05484490096569061
2019-04-26 19:26:13,764  The global step eval is 265
2019-04-26 19:26:13,866  The loss during eval_loss is  :: 0.04243643209338188
2019-04-26 19:26:13,868  The global step eval is 266
2019-04-26 19:26:13,971  The loss during eval_loss is  :: 0.08753891289234161
2019-04-26 19:26:13,972  The global step eval is 267
2019-04-26 19:26:14,083  The loss during eval_loss is  :: 0.06250306963920593
2019-04-26 19:26:14,085  The global step eval is 268
2019-04-26 19:26:14,196  The loss during eval_loss is  :: 0.14985592663288116
2019-04-26 19:26:14,198  The global step eval is 269
2019-04-26 19:26:14,321  The loss during eval_loss is  :: 0.05506374314427376
2019-04-26 19:26:14,323  The global step eval is 270
2019-04-26 19:26:14,423  The loss during eval_loss is  :: 0.09054256230592728
2019-04-26 19:26:14,425  The global step eval is 271
2019-04-26 19:26:14,534  The loss during eval_loss is  :: 0.10365375131368637
2019-04-26 19:26:14,535  The global step eval is 272
2019-04-26 19:26:14,655  The loss during eval_loss is  :: 0.046346720308065414
2019-04-26 19:26:14,657  The global step eval is 273
2019-04-26 19:26:14,769  The loss during eval_loss is  :: 0.11510622501373291
2019-04-26 19:26:14,770  The global step eval is 274
2019-04-26 19:26:14,869  The loss during eval_loss is  :: 0.09929478913545609
2019-04-26 19:26:14,871  The global step eval is 275
2019-04-26 19:26:14,979  The loss during eval_loss is  :: 0.07000231742858887
2019-04-26 19:26:14,981  The global step eval is 276
2019-04-26 19:26:15,093  The loss during eval_loss is  :: 0.07136489450931549
2019-04-26 19:26:15,095  The global step eval is 277
2019-04-26 19:26:15,200  The loss during eval_loss is  :: 0.03524596989154816
2019-04-26 19:26:15,202  The global step eval is 278
2019-04-26 19:26:15,311  The loss during eval_loss is  :: 0.08824864029884338
2019-04-26 19:26:15,313  The global step eval is 279
2019-04-26 19:26:15,428  The loss during eval_loss is  :: 0.04745221883058548
2019-04-26 19:26:15,430  The global step eval is 280
2019-04-26 19:26:15,451  Saved checkpoint: ./trained_model\step_4.pth.tar
2019-04-26 19:26:15,452  Removed checkpoint: ./trained_model\step_0.pth.tar
2019-04-26 19:26:15,565  The loss during training is  :: 0.03449225798249245 
2019-04-26 19:26:15,716  The global step train is 1121
2019-04-26 19:26:15,834  The loss during training is  :: 0.03943822532892227 
2019-04-26 19:26:15,997  The global step train is 1122
2019-04-26 19:26:16,128  The loss during training is  :: 0.06764805316925049 
2019-04-26 19:26:16,291  The global step train is 1123
2019-04-26 19:26:16,417  The loss during training is  :: 0.06203078478574753 
2019-04-26 19:26:16,575  The global step train is 1124
2019-04-26 19:26:16,703  The loss during training is  :: 0.11681307107210159 
2019-04-26 19:26:16,864  The global step train is 1125
2019-04-26 19:26:16,996  The loss during training is  :: 0.07933402061462402 
2019-04-26 19:26:17,155  The global step train is 1126
2019-04-26 19:26:17,284  The loss during training is  :: 0.04890493303537369 
2019-04-26 19:26:17,447  The global step train is 1127
2019-04-26 19:26:17,577  The loss during training is  :: 0.04524600878357887 
2019-04-26 19:26:17,737  The global step train is 1128
2019-04-26 19:26:17,862  The loss during training is  :: 0.036990851163864136 
2019-04-26 19:26:18,026  The global step train is 1129
2019-04-26 19:26:18,155  The loss during training is  :: 0.07133184373378754 
2019-04-26 19:26:18,316  The global step train is 1130
2019-04-26 19:26:18,447  The loss during training is  :: 0.032664284110069275 
2019-04-26 19:26:18,607  The global step train is 1131
2019-04-26 19:26:18,737  The loss during training is  :: 0.03108797036111355 
2019-04-26 19:26:18,896  The global step train is 1132
2019-04-26 19:26:19,031  The loss during training is  :: 0.03208939731121063 
2019-04-26 19:26:19,193  The global step train is 1133
2019-04-26 19:26:19,325  The loss during training is  :: 0.02978385053575039 
2019-04-26 19:26:19,491  The global step train is 1134
2019-04-26 19:26:19,617  The loss during training is  :: 0.10387711226940155 
2019-04-26 19:26:19,780  The global step train is 1135
2019-04-26 19:26:19,909  The loss during training is  :: 0.04852261021733284 
2019-04-26 19:26:20,070  The global step train is 1136
2019-04-26 19:26:20,203  The loss during training is  :: 0.021014785394072533 
2019-04-26 19:26:20,366  The global step train is 1137
2019-04-26 19:26:20,490  The loss during training is  :: 0.0398288369178772 
2019-04-26 19:26:20,654  The global step train is 1138
2019-04-26 19:26:20,780  The loss during training is  :: 0.07549039274454117 
2019-04-26 19:26:20,945  The global step train is 1139
2019-04-26 19:26:21,069  The loss during training is  :: 0.08749937266111374 
2019-04-26 19:26:21,240  The global step train is 1140
2019-04-26 19:26:21,364  The loss during training is  :: 0.027256812900304794 
2019-04-26 19:26:21,526  The global step train is 1141
2019-04-26 19:26:21,647  The loss during training is  :: 0.06831623613834381 
2019-04-26 19:26:21,809  The global step train is 1142
2019-04-26 19:26:21,940  The loss during training is  :: 0.03664642572402954 
2019-04-26 19:26:22,103  The global step train is 1143
2019-04-26 19:26:22,233  The loss during training is  :: 0.06571894139051437 
2019-04-26 19:26:22,394  The global step train is 1144
2019-04-26 19:26:22,523  The loss during training is  :: 0.06590869277715683 
2019-04-26 19:26:22,684  The global step train is 1145
2019-04-26 19:26:22,814  The loss during training is  :: 0.08773431181907654 
2019-04-26 19:26:22,975  The global step train is 1146
2019-04-26 19:26:23,103  The loss during training is  :: 0.04250765219330788 
2019-04-26 19:26:23,268  The global step train is 1147
2019-04-26 19:26:23,399  The loss during training is  :: 0.10642462223768234 
2019-04-26 19:26:23,561  The global step train is 1148
2019-04-26 19:26:23,687  The loss during training is  :: 0.032479122281074524 
2019-04-26 19:26:23,847  The global step train is 1149
2019-04-26 19:26:23,976  The loss during training is  :: 0.04829629883170128 
2019-04-26 19:26:24,137  The global step train is 1150
2019-04-26 19:26:24,271  The loss during training is  :: 0.06895628571510315 
2019-04-26 19:26:24,429  The global step train is 1151
2019-04-26 19:26:24,551  The loss during training is  :: 0.05495298281311989 
2019-04-26 19:26:24,712  The global step train is 1152
2019-04-26 19:26:24,834  The loss during training is  :: 0.13471880555152893 
2019-04-26 19:26:24,996  The global step train is 1153
2019-04-26 19:26:25,122  The loss during training is  :: 0.06749632954597473 
2019-04-26 19:26:25,286  The global step train is 1154
2019-04-26 19:26:25,417  The loss during training is  :: 0.04556775465607643 
2019-04-26 19:26:25,569  The global step train is 1155
2019-04-26 19:26:25,700  The loss during training is  :: 0.06551662087440491 
2019-04-26 19:26:25,857  The global step train is 1156
2019-04-26 19:26:25,983  The loss during training is  :: 0.04684188961982727 
2019-04-26 19:26:26,145  The global step train is 1157
2019-04-26 19:26:26,277  The loss during training is  :: 0.06111123412847519 
2019-04-26 19:26:26,440  The global step train is 1158
2019-04-26 19:26:26,564  The loss during training is  :: 0.14934639632701874 
2019-04-26 19:26:26,726  The global step train is 1159
2019-04-26 19:26:26,858  The loss during training is  :: 0.09722447395324707 
2019-04-26 19:26:27,015  The global step train is 1160
2019-04-26 19:26:27,143  The loss during training is  :: 0.03017706796526909 
2019-04-26 19:26:27,306  The global step train is 1161
2019-04-26 19:26:27,436  The loss during training is  :: 0.019592193886637688 
2019-04-26 19:26:27,595  The global step train is 1162
2019-04-26 19:26:27,725  The loss during training is  :: 0.07513491809368134 
2019-04-26 19:26:27,887  The global step train is 1163
2019-04-26 19:26:28,014  The loss during training is  :: 0.10362956672906876 
2019-04-26 19:26:28,178  The global step train is 1164
2019-04-26 19:26:28,311  The loss during training is  :: 0.03759721666574478 
2019-04-26 19:26:28,473  The global step train is 1165
2019-04-26 19:26:28,603  The loss during training is  :: 0.05503236874938011 
2019-04-26 19:26:28,769  The global step train is 1166
2019-04-26 19:26:28,897  The loss during training is  :: 0.03228386491537094 
2019-04-26 19:26:29,059  The global step train is 1167
2019-04-26 19:26:29,186  The loss during training is  :: 0.04493250325322151 
2019-04-26 19:26:29,348  The global step train is 1168
2019-04-26 19:26:29,473  The loss during training is  :: 0.037893619388341904 
2019-04-26 19:26:29,634  The global step train is 1169
2019-04-26 19:26:29,762  The loss during training is  :: 0.1604083925485611 
2019-04-26 19:26:29,923  The global step train is 1170
2019-04-26 19:26:30,055  The loss during training is  :: 0.04753600433468819 
2019-04-26 19:26:30,220  The global step train is 1171
2019-04-26 19:26:30,349  The loss during training is  :: 0.0749783143401146 
2019-04-26 19:26:30,509  The global step train is 1172
2019-04-26 19:26:30,636  The loss during training is  :: 0.03841552883386612 
2019-04-26 19:26:30,800  The global step train is 1173
2019-04-26 19:26:30,930  The loss during training is  :: 0.0706808790564537 
2019-04-26 19:26:31,091  The global step train is 1174
2019-04-26 19:26:31,216  The loss during training is  :: 0.0157796498388052 
2019-04-26 19:26:31,383  The global step train is 1175
2019-04-26 19:26:31,513  The loss during training is  :: 0.058347996324300766 
2019-04-26 19:26:31,670  The global step train is 1176
2019-04-26 19:26:31,798  The loss during training is  :: 0.01752845197916031 
2019-04-26 19:26:31,958  The global step train is 1177
2019-04-26 19:26:32,083  The loss during training is  :: 0.10049749165773392 
2019-04-26 19:26:32,248  The global step train is 1178
2019-04-26 19:26:32,378  The loss during training is  :: 0.03612254932522774 
2019-04-26 19:26:32,538  The global step train is 1179
2019-04-26 19:26:32,667  The loss during training is  :: 0.012701216153800488 
2019-04-26 19:26:32,827  The global step train is 1180
2019-04-26 19:26:32,957  The loss during training is  :: 0.032456174492836 
2019-04-26 19:26:33,120  The global step train is 1181
2019-04-26 19:26:33,256  The loss during training is  :: 0.049155477434396744 
2019-04-26 19:26:33,417  The global step train is 1182
2019-04-26 19:26:33,547  The loss during training is  :: 0.01482777576893568 
2019-04-26 19:26:33,718  The global step train is 1183
2019-04-26 19:26:33,847  The loss during training is  :: 0.057980041950941086 
2019-04-26 19:26:34,014  The global step train is 1184
2019-04-26 19:26:34,144  The loss during training is  :: 0.025086581707000732 
2019-04-26 19:26:34,304  The global step train is 1185
2019-04-26 19:26:34,432  The loss during training is  :: 0.057676613330841064 
2019-04-26 19:26:34,596  The global step train is 1186
2019-04-26 19:26:34,722  The loss during training is  :: 0.08780169486999512 
2019-04-26 19:26:34,880  The global step train is 1187
2019-04-26 19:26:35,008  The loss during training is  :: 0.03306916728615761 
2019-04-26 19:26:35,171  The global step train is 1188
2019-04-26 19:26:35,294  The loss during training is  :: 0.04109223559498787 
2019-04-26 19:26:35,454  The global step train is 1189
2019-04-26 19:26:35,577  The loss during training is  :: 0.052641380578279495 
2019-04-26 19:26:35,736  The global step train is 1190
2019-04-26 19:26:35,866  The loss during training is  :: 0.03756635636091232 
2019-04-26 19:26:36,025  The global step train is 1191
2019-04-26 19:26:36,155  The loss during training is  :: 0.02642151527106762 
2019-04-26 19:26:36,316  The global step train is 1192
2019-04-26 19:26:36,446  The loss during training is  :: 0.05401376262307167 
2019-04-26 19:26:36,607  The global step train is 1193
2019-04-26 19:26:36,737  The loss during training is  :: 0.0355115570127964 
2019-04-26 19:26:36,898  The global step train is 1194
2019-04-26 19:26:37,019  The loss during training is  :: 0.08856227993965149 
2019-04-26 19:26:37,188  The global step train is 1195
2019-04-26 19:26:37,312  The loss during training is  :: 0.10964629799127579 
2019-04-26 19:26:37,474  The global step train is 1196
2019-04-26 19:26:37,601  The loss during training is  :: 0.06186487898230553 
2019-04-26 19:26:37,764  The global step train is 1197
2019-04-26 19:26:37,893  The loss during training is  :: 0.06904599815607071 
2019-04-26 19:26:38,059  The global step train is 1198
2019-04-26 19:26:38,190  The loss during training is  :: 0.05019158497452736 
2019-04-26 19:26:38,351  The global step train is 1199
2019-04-26 19:26:38,482  The loss during training is  :: 0.06924791634082794 
2019-04-26 19:26:38,643  The global step train is 1200
2019-04-26 19:26:38,775  The loss during training is  :: 0.0680326297879219 
2019-04-26 19:26:38,931  The global step train is 1201
2019-04-26 19:26:39,060  The loss during training is  :: 0.06234736740589142 
2019-04-26 19:26:39,227  The global step train is 1202
2019-04-26 19:26:39,356  The loss during training is  :: 0.058990541845560074 
2019-04-26 19:26:39,518  The global step train is 1203
2019-04-26 19:26:39,647  The loss during training is  :: 0.029725002124905586 
2019-04-26 19:26:39,805  The global step train is 1204
2019-04-26 19:26:39,935  The loss during training is  :: 0.052481263875961304 
2019-04-26 19:26:40,095  The global step train is 1205
2019-04-26 19:26:40,229  The loss during training is  :: 0.04480840638279915 
2019-04-26 19:26:40,403  The global step train is 1206
2019-04-26 19:26:40,534  The loss during training is  :: 0.02939346618950367 
2019-04-26 19:26:40,695  The global step train is 1207
2019-04-26 19:26:40,824  The loss during training is  :: 0.06468270719051361 
2019-04-26 19:26:40,987  The global step train is 1208
2019-04-26 19:26:41,120  The loss during training is  :: 0.0786241814494133 
2019-04-26 19:26:41,292  The global step train is 1209
2019-04-26 19:26:41,451  The loss during training is  :: 0.06942849606275558 
2019-04-26 19:26:41,638  The global step train is 1210
2019-04-26 19:26:41,784  The loss during training is  :: 0.05569080263376236 
2019-04-26 19:26:41,959  The global step train is 1211
2019-04-26 19:26:42,110  The loss during training is  :: 0.0745520144701004 
2019-04-26 19:26:42,295  The global step train is 1212
2019-04-26 19:26:42,445  The loss during training is  :: 0.017003441229462624 
2019-04-26 19:26:42,622  The global step train is 1213
2019-04-26 19:26:42,763  The loss during training is  :: 0.023983024060726166 
2019-04-26 19:26:42,944  The global step train is 1214
2019-04-26 19:26:43,087  The loss during training is  :: 0.02829173393547535 
2019-04-26 19:26:43,267  The global step train is 1215
2019-04-26 19:26:43,410  The loss during training is  :: 0.03535475954413414 
2019-04-26 19:26:43,592  The global step train is 1216
2019-04-26 19:26:43,726  The loss during training is  :: 0.050637613981962204 
2019-04-26 19:26:43,887  The global step train is 1217
2019-04-26 19:26:44,008  The loss during training is  :: 0.050304848700761795 
2019-04-26 19:26:44,171  The global step train is 1218
2019-04-26 19:26:44,302  The loss during training is  :: 0.034783750772476196 
2019-04-26 19:26:44,462  The global step train is 1219
2019-04-26 19:26:44,590  The loss during training is  :: 0.11433205008506775 
2019-04-26 19:26:44,751  The global step train is 1220
2019-04-26 19:26:44,882  The loss during training is  :: 0.041122738271951675 
2019-04-26 19:26:45,045  The global step train is 1221
2019-04-26 19:26:45,177  The loss during training is  :: 0.03282086178660393 
2019-04-26 19:26:45,342  The global step train is 1222
2019-04-26 19:26:45,471  The loss during training is  :: 0.02682080864906311 
2019-04-26 19:26:45,631  The global step train is 1223
2019-04-26 19:26:45,759  The loss during training is  :: 0.06546399742364883 
2019-04-26 19:26:45,922  The global step train is 1224
2019-04-26 19:26:46,051  The loss during training is  :: 0.020190410315990448 
2019-04-26 19:26:46,215  The global step train is 1225
2019-04-26 19:26:46,348  The loss during training is  :: 0.05908437818288803 
2019-04-26 19:26:46,513  The global step train is 1226
2019-04-26 19:26:46,639  The loss during training is  :: 0.05718217045068741 
2019-04-26 19:26:46,800  The global step train is 1227
2019-04-26 19:26:46,929  The loss during training is  :: 0.022951237857341766 
2019-04-26 19:26:47,093  The global step train is 1228
2019-04-26 19:26:47,227  The loss during training is  :: 0.07191194593906403 
2019-04-26 19:26:47,391  The global step train is 1229
2019-04-26 19:26:47,517  The loss during training is  :: 0.05170433968305588 
2019-04-26 19:26:47,674  The global step train is 1230
2019-04-26 19:26:47,805  The loss during training is  :: 0.09090152382850647 
2019-04-26 19:26:47,959  The global step train is 1231
2019-04-26 19:26:48,089  The loss during training is  :: 0.09227496385574341 
2019-04-26 19:26:48,254  The global step train is 1232
2019-04-26 19:26:48,380  The loss during training is  :: 0.06565841287374496 
2019-04-26 19:26:48,541  The global step train is 1233
2019-04-26 19:26:48,669  The loss during training is  :: 0.03567490726709366 
2019-04-26 19:26:48,828  The global step train is 1234
2019-04-26 19:26:48,959  The loss during training is  :: 0.06372746080160141 
2019-04-26 19:26:49,121  The global step train is 1235
2019-04-26 19:26:49,240  The loss during training is  :: 0.03710552677512169 
2019-04-26 19:26:49,401  The global step train is 1236
2019-04-26 19:26:49,528  The loss during training is  :: 0.04905077442526817 
2019-04-26 19:26:49,688  The global step train is 1237
2019-04-26 19:26:49,810  The loss during training is  :: 0.022107688710093498 
2019-04-26 19:26:49,974  The global step train is 1238
2019-04-26 19:26:50,106  The loss during training is  :: 0.03204239532351494 
2019-04-26 19:26:50,264  The global step train is 1239
2019-04-26 19:26:50,400  The loss during training is  :: 0.025458602234721184 
2019-04-26 19:26:50,565  The global step train is 1240
2019-04-26 19:26:50,697  The loss during training is  :: 0.04893960803747177 
2019-04-26 19:26:50,856  The global step train is 1241
2019-04-26 19:26:50,985  The loss during training is  :: 0.02384626679122448 
2019-04-26 19:26:51,151  The global step train is 1242
2019-04-26 19:26:51,290  The loss during training is  :: 0.03593519330024719 
2019-04-26 19:26:51,461  The global step train is 1243
2019-04-26 19:26:51,594  The loss during training is  :: 0.049312688410282135 
2019-04-26 19:26:51,759  The global step train is 1244
2019-04-26 19:26:51,891  The loss during training is  :: 0.07034529000520706 
2019-04-26 19:26:52,057  The global step train is 1245
2019-04-26 19:26:52,201  The loss during training is  :: 0.0365506187081337 
2019-04-26 19:26:52,375  The global step train is 1246
2019-04-26 19:26:52,516  The loss during training is  :: 0.034062135964632034 
2019-04-26 19:26:52,697  The global step train is 1247
2019-04-26 19:26:52,830  The loss during training is  :: 0.022226139903068542 
2019-04-26 19:26:53,005  The global step train is 1248
2019-04-26 19:26:53,143  The loss during training is  :: 0.05628421902656555 
2019-04-26 19:26:53,317  The global step train is 1249
2019-04-26 19:26:53,451  The loss during training is  :: 0.07518775016069412 
2019-04-26 19:26:53,615  The global step train is 1250
2019-04-26 19:26:53,747  The loss during training is  :: 0.036861591041088104 
2019-04-26 19:26:53,907  The global step train is 1251
2019-04-26 19:26:54,031  The loss during training is  :: 0.05369533598423004 
2019-04-26 19:26:54,196  The global step train is 1252
2019-04-26 19:26:54,323  The loss during training is  :: 0.041879620403051376 
2019-04-26 19:26:54,488  The global step train is 1253
2019-04-26 19:26:54,616  The loss during training is  :: 0.05470402538776398 
2019-04-26 19:26:54,772  The global step train is 1254
2019-04-26 19:26:54,901  The loss during training is  :: 0.03862617909908295 
2019-04-26 19:26:55,050  The global step train is 1255
2019-04-26 19:26:55,181  The loss during training is  :: 0.07550925761461258 
2019-04-26 19:26:55,347  The global step train is 1256
2019-04-26 19:26:55,479  The loss during training is  :: 0.026397624984383583 
2019-04-26 19:26:55,638  The global step train is 1257
2019-04-26 19:26:55,769  The loss during training is  :: 0.04694627597928047 
2019-04-26 19:26:55,928  The global step train is 1258
2019-04-26 19:26:56,056  The loss during training is  :: 0.060692042112350464 
2019-04-26 19:26:56,209  The global step train is 1259
2019-04-26 19:26:56,343  The loss during training is  :: 0.05526335537433624 
2019-04-26 19:26:56,509  The global step train is 1260
2019-04-26 19:26:56,636  The loss during training is  :: 0.08162160217761993 
2019-04-26 19:26:56,800  The global step train is 1261
2019-04-26 19:26:56,931  The loss during training is  :: 0.07891059666872025 
2019-04-26 19:26:57,103  The global step train is 1262
2019-04-26 19:26:57,234  The loss during training is  :: 0.03341531381011009 
2019-04-26 19:26:57,397  The global step train is 1263
2019-04-26 19:26:57,528  The loss during training is  :: 0.05307780206203461 
2019-04-26 19:26:57,689  The global step train is 1264
2019-04-26 19:26:57,820  The loss during training is  :: 0.04918678477406502 
2019-04-26 19:26:57,980  The global step train is 1265
2019-04-26 19:26:58,114  The loss during training is  :: 0.0823865607380867 
2019-04-26 19:26:58,282  The global step train is 1266
2019-04-26 19:26:58,412  The loss during training is  :: 0.038135826587677 
2019-04-26 19:26:58,573  The global step train is 1267
2019-04-26 19:26:58,708  The loss during training is  :: 0.09698519110679626 
2019-04-26 19:26:58,870  The global step train is 1268
2019-04-26 19:26:58,993  The loss during training is  :: 0.05148117244243622 
2019-04-26 19:26:59,157  The global step train is 1269
2019-04-26 19:26:59,291  The loss during training is  :: 0.08276553452014923 
2019-04-26 19:26:59,455  The global step train is 1270
2019-04-26 19:26:59,586  The loss during training is  :: 0.0496806800365448 
2019-04-26 19:26:59,745  The global step train is 1271
2019-04-26 19:26:59,874  The loss during training is  :: 0.050741709768772125 
2019-04-26 19:27:00,033  The global step train is 1272
2019-04-26 19:27:00,158  The loss during training is  :: 0.06751535832881927 
2019-04-26 19:27:00,322  The global step train is 1273
2019-04-26 19:27:00,450  The loss during training is  :: 0.0512038916349411 
2019-04-26 19:27:00,616  The global step train is 1274
2019-04-26 19:27:00,744  The loss during training is  :: 0.05157550796866417 
2019-04-26 19:27:00,911  The global step train is 1275
2019-04-26 19:27:01,035  The loss during training is  :: 0.03925471380352974 
2019-04-26 19:27:01,196  The global step train is 1276
2019-04-26 19:27:01,322  The loss during training is  :: 0.09089654684066772 
2019-04-26 19:27:01,491  The global step train is 1277
2019-04-26 19:27:01,619  The loss during training is  :: 0.06088671833276749 
2019-04-26 19:27:01,780  The global step train is 1278
2019-04-26 19:27:01,907  The loss during training is  :: 0.022679198533296585 
2019-04-26 19:27:02,070  The global step train is 1279
2019-04-26 19:27:02,203  The loss during training is  :: 0.020639680325984955 
2019-04-26 19:27:02,369  The global step train is 1280
2019-04-26 19:27:02,501  The loss during training is  :: 0.10899391025304794 
2019-04-26 19:27:02,661  The global step train is 1281
2019-04-26 19:27:02,788  The loss during training is  :: 0.056062646210193634 
2019-04-26 19:27:02,943  The global step train is 1282
2019-04-26 19:27:03,070  The loss during training is  :: 0.04490601271390915 
2019-04-26 19:27:03,234  The global step train is 1283
2019-04-26 19:27:03,362  The loss during training is  :: 0.056531574577093124 
2019-04-26 19:27:03,520  The global step train is 1284
2019-04-26 19:27:03,647  The loss during training is  :: 0.048025306314229965 
2019-04-26 19:27:03,809  The global step train is 1285
2019-04-26 19:27:03,942  The loss during training is  :: 0.048130664974451065 
2019-04-26 19:27:04,102  The global step train is 1286
2019-04-26 19:27:04,232  The loss during training is  :: 0.08651025593280792 
2019-04-26 19:27:04,392  The global step train is 1287
2019-04-26 19:27:04,520  The loss during training is  :: 0.020091483369469643 
2019-04-26 19:27:04,680  The global step train is 1288
2019-04-26 19:27:04,810  The loss during training is  :: 0.0180131234228611 
2019-04-26 19:27:04,972  The global step train is 1289
2019-04-26 19:27:05,102  The loss during training is  :: 0.01704946905374527 
2019-04-26 19:27:05,264  The global step train is 1290
2019-04-26 19:27:05,395  The loss during training is  :: 0.060012828558683395 
2019-04-26 19:27:05,558  The global step train is 1291
2019-04-26 19:27:05,681  The loss during training is  :: 0.021736253052949905 
2019-04-26 19:27:05,847  The global step train is 1292
2019-04-26 19:27:05,977  The loss during training is  :: 0.02132943458855152 
2019-04-26 19:27:06,135  The global step train is 1293
2019-04-26 19:27:06,266  The loss during training is  :: 0.03691034018993378 
2019-04-26 19:27:06,431  The global step train is 1294
2019-04-26 19:27:06,563  The loss during training is  :: 0.018967024981975555 
2019-04-26 19:27:06,720  The global step train is 1295
2019-04-26 19:27:06,850  The loss during training is  :: 0.049372099339962006 
2019-04-26 19:27:07,014  The global step train is 1296
2019-04-26 19:27:07,138  The loss during training is  :: 0.03073749504983425 
2019-04-26 19:27:07,304  The global step train is 1297
2019-04-26 19:27:07,435  The loss during training is  :: 0.03878524899482727 
2019-04-26 19:27:07,595  The global step train is 1298
2019-04-26 19:27:07,724  The loss during training is  :: 0.06060194596648216 
2019-04-26 19:27:07,887  The global step train is 1299
2019-04-26 19:27:08,016  The loss during training is  :: 0.07896952331066132 
2019-04-26 19:27:08,178  The global step train is 1300
2019-04-26 19:27:08,307  The loss during training is  :: 0.07297684997320175 
2019-04-26 19:27:08,471  The global step train is 1301
2019-04-26 19:27:08,602  The loss during training is  :: 0.028760064393281937 
2019-04-26 19:27:08,765  The global step train is 1302
2019-04-26 19:27:08,887  The loss during training is  :: 0.05666168034076691 
2019-04-26 19:27:09,057  The global step train is 1303
2019-04-26 19:27:09,189  The loss during training is  :: 0.11507777124643326 
2019-04-26 19:27:09,350  The global step train is 1304
2019-04-26 19:27:09,482  The loss during training is  :: 0.009631697088479996 
2019-04-26 19:27:09,642  The global step train is 1305
2019-04-26 19:27:09,771  The loss during training is  :: 0.07787366211414337 
2019-04-26 19:27:09,929  The global step train is 1306
2019-04-26 19:27:10,060  The loss during training is  :: 0.030287085101008415 
2019-04-26 19:27:10,229  The global step train is 1307
2019-04-26 19:27:10,362  The loss during training is  :: 0.05558300018310547 
2019-04-26 19:27:10,523  The global step train is 1308
2019-04-26 19:27:10,654  The loss during training is  :: 0.07192859798669815 
2019-04-26 19:27:10,818  The global step train is 1309
2019-04-26 19:27:10,946  The loss during training is  :: 0.1114557757973671 
2019-04-26 19:27:11,103  The global step train is 1310
2019-04-26 19:27:11,231  The loss during training is  :: 0.03724534437060356 
2019-04-26 19:27:11,396  The global step train is 1311
2019-04-26 19:27:11,526  The loss during training is  :: 0.044060394167900085 
2019-04-26 19:27:11,689  The global step train is 1312
2019-04-26 19:27:11,816  The loss during training is  :: 0.014561675488948822 
2019-04-26 19:27:11,976  The global step train is 1313
2019-04-26 19:27:12,105  The loss during training is  :: 0.04552673175930977 
2019-04-26 19:27:12,264  The global step train is 1314
2019-04-26 19:27:12,393  The loss during training is  :: 0.016480201855301857 
2019-04-26 19:27:12,559  The global step train is 1315
2019-04-26 19:27:12,685  The loss during training is  :: 0.04296112805604935 
2019-04-26 19:27:12,845  The global step train is 1316
2019-04-26 19:27:12,976  The loss during training is  :: 0.08197309821844101 
2019-04-26 19:27:13,138  The global step train is 1317
2019-04-26 19:27:13,270  The loss during training is  :: 0.08852504938840866 
2019-04-26 19:27:13,432  The global step train is 1318
2019-04-26 19:27:13,561  The loss during training is  :: 0.07431814819574356 
2019-04-26 19:27:13,714  The global step train is 1319
2019-04-26 19:27:13,845  The loss during training is  :: 0.0787191092967987 
2019-04-26 19:27:14,004  The global step train is 1320
2019-04-26 19:27:14,129  The loss during training is  :: 0.03658333420753479 
2019-04-26 19:27:14,292  The global step train is 1321
2019-04-26 19:27:14,426  The loss during training is  :: 0.03030923567712307 
2019-04-26 19:27:14,596  The global step train is 1322
2019-04-26 19:27:14,724  The loss during training is  :: 0.03974195197224617 
2019-04-26 19:27:14,885  The global step train is 1323
2019-04-26 19:27:15,014  The loss during training is  :: 0.057581957429647446 
2019-04-26 19:27:15,172  The global step train is 1324
2019-04-26 19:27:15,305  The loss during training is  :: 0.03495076298713684 
2019-04-26 19:27:15,471  The global step train is 1325
2019-04-26 19:27:15,613  The loss during training is  :: 0.0690443143248558 
2019-04-26 19:27:15,784  The global step train is 1326
2019-04-26 19:27:15,923  The loss during training is  :: 0.02831193618476391 
2019-04-26 19:27:16,095  The global step train is 1327
2019-04-26 19:27:16,236  The loss during training is  :: 0.06507448852062225 
2019-04-26 19:27:16,405  The global step train is 1328
2019-04-26 19:27:16,547  The loss during training is  :: 0.07080637663602829 
2019-04-26 19:27:16,711  The global step train is 1329
2019-04-26 19:27:16,840  The loss during training is  :: 0.04519941285252571 
2019-04-26 19:27:17,004  The global step train is 1330
2019-04-26 19:27:17,131  The loss during training is  :: 0.11810292303562164 
2019-04-26 19:27:17,297  The global step train is 1331
2019-04-26 19:27:17,427  The loss during training is  :: 0.004395449999719858 
2019-04-26 19:27:17,591  The global step train is 1332
2019-04-26 19:27:17,720  The loss during training is  :: 0.03660057112574577 
2019-04-26 19:27:17,890  The global step train is 1333
2019-04-26 19:27:18,022  The loss during training is  :: 0.025892473757267 
2019-04-26 19:27:18,199  The global step train is 1334
2019-04-26 19:27:18,337  The loss during training is  :: 0.033476684242486954 
2019-04-26 19:27:18,508  The global step train is 1335
2019-04-26 19:27:18,648  The loss during training is  :: 0.03677557408809662 
2019-04-26 19:27:18,817  The global step train is 1336
2019-04-26 19:27:18,949  The loss during training is  :: 0.028668377548456192 
2019-04-26 19:27:19,115  The global step train is 1337
2019-04-26 19:27:19,250  The loss during training is  :: 0.0278819240629673 
2019-04-26 19:27:19,411  The global step train is 1338
2019-04-26 19:27:19,540  The loss during training is  :: 0.041584428399801254 
2019-04-26 19:27:19,698  The global step train is 1339
2019-04-26 19:27:19,826  The loss during training is  :: 0.07317253947257996 
2019-04-26 19:27:19,997  The global step train is 1340
2019-04-26 19:27:20,129  The loss during training is  :: 0.04733351245522499 
2019-04-26 19:27:20,291  The global step train is 1341
2019-04-26 19:27:20,422  The loss during training is  :: 0.04168113321065903 
2019-04-26 19:27:20,598  The global step train is 1342
2019-04-26 19:27:20,724  The loss during training is  :: 0.15429554879665375 
2019-04-26 19:27:20,884  The global step train is 1343
2019-04-26 19:27:21,011  The loss during training is  :: 0.03265037387609482 
2019-04-26 19:27:21,181  The global step train is 1344
2019-04-26 19:27:21,183  Starting evaluation 
2019-04-26 19:27:21,332  The loss during eval_loss is  :: 0.07997783273458481
2019-04-26 19:27:21,334  The global step eval is 281
2019-04-26 19:27:21,465  The loss during eval_loss is  :: 0.043852709233760834
2019-04-26 19:27:21,468  The global step eval is 282
2019-04-26 19:27:21,579  The loss during eval_loss is  :: 0.03326085954904556
2019-04-26 19:27:21,581  The global step eval is 283
2019-04-26 19:27:21,701  The loss during eval_loss is  :: 0.03117799386382103
2019-04-26 19:27:21,702  The global step eval is 284
2019-04-26 19:27:21,811  The loss during eval_loss is  :: 0.0652521476149559
2019-04-26 19:27:21,812  The global step eval is 285
2019-04-26 19:27:21,920  The loss during eval_loss is  :: 0.08844412118196487
2019-04-26 19:27:21,922  The global step eval is 286
2019-04-26 19:27:22,029  The loss during eval_loss is  :: 0.10787875205278397
2019-04-26 19:27:22,031  The global step eval is 287
2019-04-26 19:27:22,152  The loss during eval_loss is  :: 0.01148110069334507
2019-04-26 19:27:22,154  The global step eval is 288
2019-04-26 19:27:22,269  The loss during eval_loss is  :: 0.08610299229621887
2019-04-26 19:27:22,271  The global step eval is 289
2019-04-26 19:27:22,384  The loss during eval_loss is  :: 0.020292233675718307
2019-04-26 19:27:22,386  The global step eval is 290
2019-04-26 19:27:22,500  The loss during eval_loss is  :: 0.1009875237941742
2019-04-26 19:27:22,502  The global step eval is 291
2019-04-26 19:27:22,619  The loss during eval_loss is  :: 0.0356307215988636
2019-04-26 19:27:22,621  The global step eval is 292
2019-04-26 19:27:22,720  The loss during eval_loss is  :: 0.0338078998029232
2019-04-26 19:27:22,722  The global step eval is 293
2019-04-26 19:27:22,831  The loss during eval_loss is  :: 0.049943674355745316
2019-04-26 19:27:22,831  The global step eval is 294
2019-04-26 19:27:22,947  The loss during eval_loss is  :: 0.06400956958532333
2019-04-26 19:27:22,948  The global step eval is 295
2019-04-26 19:27:23,058  The loss during eval_loss is  :: 0.1243663802742958
2019-04-26 19:27:23,061  The global step eval is 296
2019-04-26 19:27:23,194  The loss during eval_loss is  :: 0.07033519446849823
2019-04-26 19:27:23,196  The global step eval is 297
2019-04-26 19:27:23,352  The loss during eval_loss is  :: 0.1498258411884308
2019-04-26 19:27:23,354  The global step eval is 298
2019-04-26 19:27:23,484  The loss during eval_loss is  :: 0.03208179771900177
2019-04-26 19:27:23,486  The global step eval is 299
2019-04-26 19:27:23,598  The loss during eval_loss is  :: 0.05613655224442482
2019-04-26 19:27:23,600  The global step eval is 300
2019-04-26 19:27:23,714  The loss during eval_loss is  :: 0.09075431525707245
2019-04-26 19:27:23,716  The global step eval is 301
2019-04-26 19:27:23,827  The loss during eval_loss is  :: 0.07484860718250275
2019-04-26 19:27:23,829  The global step eval is 302
2019-04-26 19:27:23,938  The loss during eval_loss is  :: 0.033271219581365585
2019-04-26 19:27:23,940  The global step eval is 303
2019-04-26 19:27:24,051  The loss during eval_loss is  :: 0.04466422647237778
2019-04-26 19:27:24,053  The global step eval is 304
2019-04-26 19:27:24,168  The loss during eval_loss is  :: 0.034212276339530945
2019-04-26 19:27:24,170  The global step eval is 305
2019-04-26 19:27:24,286  The loss during eval_loss is  :: 0.02835327759385109
2019-04-26 19:27:24,288  The global step eval is 306
2019-04-26 19:27:24,396  The loss during eval_loss is  :: 0.06735978275537491
2019-04-26 19:27:24,398  The global step eval is 307
2019-04-26 19:27:24,515  The loss during eval_loss is  :: 0.06250490248203278
2019-04-26 19:27:24,517  The global step eval is 308
2019-04-26 19:27:24,618  The loss during eval_loss is  :: 0.05912347882986069
2019-04-26 19:27:24,620  The global step eval is 309
2019-04-26 19:27:24,735  The loss during eval_loss is  :: 0.05381212756037712
2019-04-26 19:27:24,736  The global step eval is 310
2019-04-26 19:27:24,849  The loss during eval_loss is  :: 0.039824388921260834
2019-04-26 19:27:24,851  The global step eval is 311
2019-04-26 19:27:24,956  The loss during eval_loss is  :: 0.08573462069034576
2019-04-26 19:27:24,958  The global step eval is 312
2019-04-26 19:27:25,069  The loss during eval_loss is  :: 0.06763974577188492
2019-04-26 19:27:25,070  The global step eval is 313
2019-04-26 19:27:25,186  The loss during eval_loss is  :: 0.12931197881698608
2019-04-26 19:27:25,187  The global step eval is 314
2019-04-26 19:27:25,302  The loss during eval_loss is  :: 0.05801461637020111
2019-04-26 19:27:25,304  The global step eval is 315
2019-04-26 19:27:25,411  The loss during eval_loss is  :: 0.09402137994766235
2019-04-26 19:27:25,412  The global step eval is 316
2019-04-26 19:27:25,530  The loss during eval_loss is  :: 0.08453448861837387
2019-04-26 19:27:25,532  The global step eval is 317
2019-04-26 19:27:25,649  The loss during eval_loss is  :: 0.06414585560560226
2019-04-26 19:27:25,650  The global step eval is 318
2019-04-26 19:27:25,763  The loss during eval_loss is  :: 0.020176859572529793
2019-04-26 19:27:25,765  The global step eval is 319
2019-04-26 19:27:25,875  The loss during eval_loss is  :: 0.022333307191729546
2019-04-26 19:27:25,876  The global step eval is 320
2019-04-26 19:27:25,986  The loss during eval_loss is  :: 0.041628554463386536
2019-04-26 19:27:25,988  The global step eval is 321
2019-04-26 19:27:26,097  The loss during eval_loss is  :: 0.03875988349318504
2019-04-26 19:27:26,099  The global step eval is 322
2019-04-26 19:27:26,207  The loss during eval_loss is  :: 0.07622534036636353
2019-04-26 19:27:26,209  The global step eval is 323
2019-04-26 19:27:26,328  The loss during eval_loss is  :: 0.04942231997847557
2019-04-26 19:27:26,330  The global step eval is 324
2019-04-26 19:27:26,439  The loss during eval_loss is  :: 0.15012258291244507
2019-04-26 19:27:26,440  The global step eval is 325
2019-04-26 19:27:26,562  The loss during eval_loss is  :: 0.05416260287165642
2019-04-26 19:27:26,563  The global step eval is 326
2019-04-26 19:27:26,669  The loss during eval_loss is  :: 0.09597380459308624
2019-04-26 19:27:26,671  The global step eval is 327
2019-04-26 19:27:26,782  The loss during eval_loss is  :: 0.11586291342973709
2019-04-26 19:27:26,783  The global step eval is 328
2019-04-26 19:27:26,887  The loss during eval_loss is  :: 0.019258495420217514
2019-04-26 19:27:26,889  The global step eval is 329
2019-04-26 19:27:26,990  The loss during eval_loss is  :: 0.10475937277078629
2019-04-26 19:27:26,992  The global step eval is 330
2019-04-26 19:27:27,103  The loss during eval_loss is  :: 0.07898688316345215
2019-04-26 19:27:27,105  The global step eval is 331
2019-04-26 19:27:27,210  The loss during eval_loss is  :: 0.06232034042477608
2019-04-26 19:27:27,212  The global step eval is 332
2019-04-26 19:27:27,328  The loss during eval_loss is  :: 0.060176849365234375
2019-04-26 19:27:27,330  The global step eval is 333
2019-04-26 19:27:27,438  The loss during eval_loss is  :: 0.028640199452638626
2019-04-26 19:27:27,440  The global step eval is 334
2019-04-26 19:27:27,549  The loss during eval_loss is  :: 0.053022194653749466
2019-04-26 19:27:27,551  The global step eval is 335
2019-04-26 19:27:27,660  The loss during eval_loss is  :: 0.0482049323618412
2019-04-26 19:27:27,662  The global step eval is 336
2019-04-26 19:27:27,684  Saved checkpoint: ./trained_model\step_5.pth.tar
2019-04-26 19:27:27,684  Removed checkpoint: ./trained_model\step_1.pth.tar
2019-04-26 19:27:27,792  The loss during training is  :: 0.06308839470148087 
2019-04-26 19:27:27,946  The global step train is 1345
2019-04-26 19:27:28,070  The loss during training is  :: 0.01095589343458414 
2019-04-26 19:27:28,231  The global step train is 1346
2019-04-26 19:27:28,360  The loss during training is  :: 0.02696138434112072 
2019-04-26 19:27:28,523  The global step train is 1347
2019-04-26 19:27:28,686  The loss during training is  :: 0.09803244471549988 
2019-04-26 19:27:28,859  The global step train is 1348
2019-04-26 19:27:28,994  The loss during training is  :: 0.06103932857513428 
2019-04-26 19:27:29,154  The global step train is 1349
2019-04-26 19:27:29,288  The loss during training is  :: 0.028355561196804047 
2019-04-26 19:27:29,450  The global step train is 1350
2019-04-26 19:27:29,581  The loss during training is  :: 0.02732931822538376 
2019-04-26 19:27:29,742  The global step train is 1351
2019-04-26 19:27:29,875  The loss during training is  :: 0.051588501781225204 
2019-04-26 19:27:30,039  The global step train is 1352
2019-04-26 19:27:30,167  The loss during training is  :: 0.10561174154281616 
2019-04-26 19:27:30,329  The global step train is 1353
2019-04-26 19:27:30,462  The loss during training is  :: 0.04002336040139198 
2019-04-26 19:27:30,623  The global step train is 1354
2019-04-26 19:27:30,754  The loss during training is  :: 0.06618673354387283 
2019-04-26 19:27:30,915  The global step train is 1355
2019-04-26 19:27:31,044  The loss during training is  :: 0.024174461141228676 
2019-04-26 19:27:31,205  The global step train is 1356
2019-04-26 19:27:31,333  The loss during training is  :: 0.023150503635406494 
2019-04-26 19:27:31,491  The global step train is 1357
2019-04-26 19:27:31,619  The loss during training is  :: 0.06813213974237442 
2019-04-26 19:27:31,783  The global step train is 1358
2019-04-26 19:27:31,916  The loss during training is  :: 0.012161461636424065 
2019-04-26 19:27:32,076  The global step train is 1359
2019-04-26 19:27:32,202  The loss during training is  :: 0.05533752590417862 
2019-04-26 19:27:32,363  The global step train is 1360
2019-04-26 19:27:32,496  The loss during training is  :: 0.055519185960292816 
2019-04-26 19:27:32,659  The global step train is 1361
2019-04-26 19:27:32,786  The loss during training is  :: 0.03048579767346382 
2019-04-26 19:27:32,957  The global step train is 1362
2019-04-26 19:27:33,086  The loss during training is  :: 0.019417671486735344 
2019-04-26 19:27:33,246  The global step train is 1363
2019-04-26 19:27:33,380  The loss during training is  :: 0.06667758524417877 
2019-04-26 19:27:33,543  The global step train is 1364
2019-04-26 19:27:33,674  The loss during training is  :: 0.022351669147610664 
2019-04-26 19:27:33,836  The global step train is 1365
2019-04-26 19:27:33,966  The loss during training is  :: 0.07568410784006119 
2019-04-26 19:27:34,127  The global step train is 1366
2019-04-26 19:27:34,256  The loss during training is  :: 0.024135306477546692 
2019-04-26 19:27:34,416  The global step train is 1367
2019-04-26 19:27:34,550  The loss during training is  :: 0.04081795737147331 
2019-04-26 19:27:34,709  The global step train is 1368
2019-04-26 19:27:34,838  The loss during training is  :: 0.01608816161751747 
2019-04-26 19:27:34,999  The global step train is 1369
2019-04-26 19:27:35,149  The loss during training is  :: 0.044353265315294266 
2019-04-26 19:27:35,342  The global step train is 1370
2019-04-26 19:27:35,481  The loss during training is  :: 0.06680566072463989 
2019-04-26 19:27:35,644  The global step train is 1371
2019-04-26 19:27:35,775  The loss during training is  :: 0.06191699206829071 
2019-04-26 19:27:35,936  The global step train is 1372
2019-04-26 19:27:36,067  The loss during training is  :: 0.03950056806206703 
2019-04-26 19:27:36,233  The global step train is 1373
2019-04-26 19:27:36,360  The loss during training is  :: 0.025691410526633263 
2019-04-26 19:27:36,516  The global step train is 1374
2019-04-26 19:27:36,642  The loss during training is  :: 0.01513509452342987 
2019-04-26 19:27:36,808  The global step train is 1375
2019-04-26 19:27:36,930  The loss during training is  :: 0.027668623253703117 
2019-04-26 19:27:37,096  The global step train is 1376
2019-04-26 19:27:37,228  The loss during training is  :: 0.02154894545674324 
2019-04-26 19:27:37,391  The global step train is 1377
2019-04-26 19:27:37,519  The loss during training is  :: 0.06681210547685623 
2019-04-26 19:27:37,677  The global step train is 1378
2019-04-26 19:27:37,803  The loss during training is  :: 0.04073198139667511 
2019-04-26 19:27:37,969  The global step train is 1379
2019-04-26 19:27:38,094  The loss during training is  :: 0.10966585576534271 
2019-04-26 19:27:38,258  The global step train is 1380
2019-04-26 19:27:38,389  The loss during training is  :: 0.05358259752392769 
2019-04-26 19:27:38,551  The global step train is 1381
2019-04-26 19:27:38,683  The loss during training is  :: 0.037470363080501556 
2019-04-26 19:27:38,841  The global step train is 1382
2019-04-26 19:27:38,973  The loss during training is  :: 0.0441327840089798 
2019-04-26 19:27:39,133  The global step train is 1383
2019-04-26 19:27:39,268  The loss during training is  :: 0.024481697008013725 
2019-04-26 19:27:39,436  The global step train is 1384
2019-04-26 19:27:39,568  The loss during training is  :: 0.09834535419940948 
2019-04-26 19:27:39,726  The global step train is 1385
2019-04-26 19:27:39,848  The loss during training is  :: 0.06814640015363693 
2019-04-26 19:27:40,011  The global step train is 1386
2019-04-26 19:27:40,140  The loss during training is  :: 0.01455574668943882 
2019-04-26 19:27:40,295  The global step train is 1387
2019-04-26 19:27:40,422  The loss during training is  :: 0.06860067695379257 
2019-04-26 19:27:40,589  The global step train is 1388
2019-04-26 19:27:40,712  The loss during training is  :: 0.03768186643719673 
2019-04-26 19:27:40,877  The global step train is 1389
2019-04-26 19:27:41,008  The loss during training is  :: 0.12493831664323807 
2019-04-26 19:27:41,170  The global step train is 1390
2019-04-26 19:27:41,308  The loss during training is  :: 0.05041108652949333 
2019-04-26 19:27:41,474  The global step train is 1391
2019-04-26 19:27:41,599  The loss during training is  :: 0.048984888941049576 
2019-04-26 19:27:41,762  The global step train is 1392
2019-04-26 19:27:41,893  The loss during training is  :: 0.054479822516441345 
2019-04-26 19:27:42,058  The global step train is 1393
2019-04-26 19:27:42,182  The loss during training is  :: 0.015233307145535946 
2019-04-26 19:27:42,348  The global step train is 1394
2019-04-26 19:27:42,477  The loss during training is  :: 0.0607120655477047 
2019-04-26 19:27:42,641  The global step train is 1395
2019-04-26 19:27:42,775  The loss during training is  :: 0.051119402050971985 
2019-04-26 19:27:42,933  The global step train is 1396
2019-04-26 19:27:43,061  The loss during training is  :: 0.10147750377655029 
2019-04-26 19:27:43,227  The global step train is 1397
2019-04-26 19:27:43,354  The loss during training is  :: 0.026968397200107574 
2019-04-26 19:27:43,511  The global step train is 1398
2019-04-26 19:27:43,644  The loss during training is  :: 0.0595448762178421 
2019-04-26 19:27:43,798  The global step train is 1399
2019-04-26 19:27:43,930  The loss during training is  :: 0.07310809195041656 
2019-04-26 19:27:44,094  The global step train is 1400
2019-04-26 19:27:44,224  The loss during training is  :: 0.047518763691186905 
2019-04-26 19:27:44,395  The global step train is 1401
2019-04-26 19:27:44,526  The loss during training is  :: 0.043254755437374115 
2019-04-26 19:27:44,688  The global step train is 1402
2019-04-26 19:27:44,815  The loss during training is  :: 0.03481663763523102 
2019-04-26 19:27:44,978  The global step train is 1403
2019-04-26 19:27:45,107  The loss during training is  :: 0.03886617347598076 
2019-04-26 19:27:45,268  The global step train is 1404
2019-04-26 19:27:45,396  The loss during training is  :: 0.05176844075322151 
2019-04-26 19:27:45,560  The global step train is 1405
2019-04-26 19:27:45,689  The loss during training is  :: 0.04793928563594818 
2019-04-26 19:27:45,850  The global step train is 1406
2019-04-26 19:27:45,974  The loss during training is  :: 0.023924674838781357 
2019-04-26 19:27:46,137  The global step train is 1407
2019-04-26 19:27:46,268  The loss during training is  :: 0.022296978160738945 
2019-04-26 19:27:46,433  The global step train is 1408
2019-04-26 19:27:46,552  The loss during training is  :: 0.02416304312646389 
2019-04-26 19:27:46,707  The global step train is 1409
2019-04-26 19:27:46,838  The loss during training is  :: 0.0337178073823452 
2019-04-26 19:27:47,000  The global step train is 1410
2019-04-26 19:27:47,126  The loss during training is  :: 0.021929871290922165 
2019-04-26 19:27:47,288  The global step train is 1411
2019-04-26 19:27:47,413  The loss during training is  :: 0.11982566863298416 
2019-04-26 19:27:47,576  The global step train is 1412
2019-04-26 19:27:47,705  The loss during training is  :: 0.03989533707499504 
2019-04-26 19:27:47,865  The global step train is 1413
2019-04-26 19:27:47,997  The loss during training is  :: 0.028374195098876953 
2019-04-26 19:27:48,158  The global step train is 1414
2019-04-26 19:27:48,290  The loss during training is  :: 0.020795663818717003 
2019-04-26 19:27:48,456  The global step train is 1415
2019-04-26 19:27:48,586  The loss during training is  :: 0.013837737962603569 
2019-04-26 19:27:48,750  The global step train is 1416
2019-04-26 19:27:48,882  The loss during training is  :: 0.040328752249479294 
2019-04-26 19:27:49,038  The global step train is 1417
2019-04-26 19:27:49,169  The loss during training is  :: 0.0680520087480545 
2019-04-26 19:27:49,329  The global step train is 1418
2019-04-26 19:27:49,460  The loss during training is  :: 0.034339360892772675 
2019-04-26 19:27:49,627  The global step train is 1419
2019-04-26 19:27:49,758  The loss during training is  :: 0.046585679054260254 
2019-04-26 19:27:49,923  The global step train is 1420
2019-04-26 19:27:50,048  The loss during training is  :: 0.05407335236668587 
2019-04-26 19:27:50,210  The global step train is 1421
2019-04-26 19:27:50,358  The loss during training is  :: 0.06488201022148132 
2019-04-26 19:27:50,521  The global step train is 1422
2019-04-26 19:27:50,650  The loss during training is  :: 0.028123388066887856 
2019-04-26 19:27:50,815  The global step train is 1423
2019-04-26 19:27:50,945  The loss during training is  :: 0.013399740681052208 
2019-04-26 19:27:51,109  The global step train is 1424
2019-04-26 19:27:51,244  The loss during training is  :: 0.04860437661409378 
2019-04-26 19:27:51,407  The global step train is 1425
2019-04-26 19:27:51,540  The loss during training is  :: 0.04235830157995224 
2019-04-26 19:27:51,701  The global step train is 1426
2019-04-26 19:27:51,833  The loss during training is  :: 0.07581707835197449 
2019-04-26 19:27:52,003  The global step train is 1427
2019-04-26 19:27:52,135  The loss during training is  :: 0.05525832623243332 
2019-04-26 19:27:52,296  The global step train is 1428
2019-04-26 19:27:52,423  The loss during training is  :: 0.03704098239541054 
2019-04-26 19:27:52,587  The global step train is 1429
2019-04-26 19:27:52,719  The loss during training is  :: 0.054693691432476044 
2019-04-26 19:27:52,883  The global step train is 1430
2019-04-26 19:27:53,014  The loss during training is  :: 0.05256577953696251 
2019-04-26 19:27:53,179  The global step train is 1431
2019-04-26 19:27:53,310  The loss during training is  :: 0.06224576383829117 
2019-04-26 19:27:53,470  The global step train is 1432
2019-04-26 19:27:53,600  The loss during training is  :: 0.02533324807882309 
2019-04-26 19:27:53,762  The global step train is 1433
2019-04-26 19:27:53,895  The loss during training is  :: 0.04369008541107178 
2019-04-26 19:27:54,068  The global step train is 1434
2019-04-26 19:27:54,200  The loss during training is  :: 0.022516673430800438 
2019-04-26 19:27:54,362  The global step train is 1435
2019-04-26 19:27:54,489  The loss during training is  :: 0.03041955642402172 
2019-04-26 19:27:54,648  The global step train is 1436
2019-04-26 19:27:54,777  The loss during training is  :: 0.0754237174987793 
2019-04-26 19:27:54,930  The global step train is 1437
2019-04-26 19:27:55,054  The loss during training is  :: 0.05790305510163307 
2019-04-26 19:27:55,215  The global step train is 1438
2019-04-26 19:27:55,346  The loss during training is  :: 0.01041253749281168 
2019-04-26 19:27:55,506  The global step train is 1439
2019-04-26 19:27:55,637  The loss during training is  :: 0.077202707529068 
2019-04-26 19:27:55,803  The global step train is 1440
2019-04-26 19:27:55,932  The loss during training is  :: 0.026339666917920113 
2019-04-26 19:27:56,087  The global step train is 1441
2019-04-26 19:27:56,216  The loss during training is  :: 0.057744018733501434 
2019-04-26 19:27:56,374  The global step train is 1442
2019-04-26 19:27:56,503  The loss during training is  :: 0.044385090470314026 
2019-04-26 19:27:56,660  The global step train is 1443
2019-04-26 19:27:56,787  The loss during training is  :: 0.09249658137559891 
2019-04-26 19:27:56,945  The global step train is 1444
2019-04-26 19:27:57,077  The loss during training is  :: 0.05210641399025917 
2019-04-26 19:27:57,241  The global step train is 1445
2019-04-26 19:27:57,366  The loss during training is  :: 0.09759224206209183 
2019-04-26 19:27:57,526  The global step train is 1446
2019-04-26 19:27:57,658  The loss during training is  :: 0.031573113054037094 
2019-04-26 19:27:57,822  The global step train is 1447
2019-04-26 19:27:57,950  The loss during training is  :: 0.0314679853618145 
2019-04-26 19:27:58,108  The global step train is 1448
2019-04-26 19:27:58,241  The loss during training is  :: 0.008092072792351246 
2019-04-26 19:27:58,407  The global step train is 1449
2019-04-26 19:27:58,541  The loss during training is  :: 0.04418017715215683 
2019-04-26 19:27:58,700  The global step train is 1450
2019-04-26 19:27:58,830  The loss during training is  :: 0.03722994774580002 
2019-04-26 19:27:58,988  The global step train is 1451
2019-04-26 19:27:59,120  The loss during training is  :: 0.04638214036822319 
2019-04-26 19:27:59,284  The global step train is 1452
2019-04-26 19:27:59,418  The loss during training is  :: 0.012124573811888695 
2019-04-26 19:27:59,578  The global step train is 1453
2019-04-26 19:27:59,705  The loss during training is  :: 0.037006739526987076 
2019-04-26 19:27:59,864  The global step train is 1454
2019-04-26 19:27:59,995  The loss during training is  :: 0.0233498215675354 
2019-04-26 19:28:00,161  The global step train is 1455
2019-04-26 19:28:00,296  The loss during training is  :: 0.0248090922832489 
2019-04-26 19:28:00,457  The global step train is 1456
2019-04-26 19:28:00,589  The loss during training is  :: 0.053843092173337936 
2019-04-26 19:28:00,750  The global step train is 1457
2019-04-26 19:28:00,877  The loss during training is  :: 0.07839347422122955 
2019-04-26 19:28:01,042  The global step train is 1458
2019-04-26 19:28:01,170  The loss during training is  :: 0.062463752925395966 
2019-04-26 19:28:01,330  The global step train is 1459
2019-04-26 19:28:01,460  The loss during training is  :: 0.031512703746557236 
2019-04-26 19:28:01,620  The global step train is 1460
2019-04-26 19:28:01,748  The loss during training is  :: 0.01755610480904579 
2019-04-26 19:28:01,911  The global step train is 1461
2019-04-26 19:28:02,036  The loss during training is  :: 0.033494770526885986 
2019-04-26 19:28:02,195  The global step train is 1462
2019-04-26 19:28:02,328  The loss during training is  :: 0.12944737076759338 
2019-04-26 19:28:02,485  The global step train is 1463
2019-04-26 19:28:02,614  The loss during training is  :: 0.06297983229160309 
2019-04-26 19:28:02,774  The global step train is 1464
2019-04-26 19:28:02,905  The loss during training is  :: 0.03210689127445221 
2019-04-26 19:28:03,064  The global step train is 1465
2019-04-26 19:28:03,190  The loss during training is  :: 0.03361004590988159 
2019-04-26 19:28:03,349  The global step train is 1466
2019-04-26 19:28:03,483  The loss during training is  :: 0.031136441975831985 
2019-04-26 19:28:03,647  The global step train is 1467
2019-04-26 19:28:03,778  The loss during training is  :: 0.032312583178281784 
2019-04-26 19:28:03,951  The global step train is 1468
2019-04-26 19:28:04,086  The loss during training is  :: 0.058921411633491516 
2019-04-26 19:28:04,249  The global step train is 1469
2019-04-26 19:28:04,378  The loss during training is  :: 0.044373929500579834 
2019-04-26 19:28:04,541  The global step train is 1470
2019-04-26 19:28:04,672  The loss during training is  :: 0.05290625989437103 
2019-04-26 19:28:04,834  The global step train is 1471
2019-04-26 19:28:04,963  The loss during training is  :: 0.044248685240745544 
2019-04-26 19:28:05,124  The global step train is 1472
2019-04-26 19:28:05,254  The loss during training is  :: 0.02699211798608303 
2019-04-26 19:28:05,415  The global step train is 1473
2019-04-26 19:28:05,547  The loss during training is  :: 0.02599109709262848 
2019-04-26 19:28:05,702  The global step train is 1474
2019-04-26 19:28:05,833  The loss during training is  :: 0.05420130491256714 
2019-04-26 19:28:05,998  The global step train is 1475
2019-04-26 19:28:06,120  The loss during training is  :: 0.048320867121219635 
2019-04-26 19:28:06,282  The global step train is 1476
2019-04-26 19:28:06,413  The loss during training is  :: 0.0903153270483017 
2019-04-26 19:28:06,572  The global step train is 1477
2019-04-26 19:28:06,705  The loss during training is  :: 0.13380096852779388 
2019-04-26 19:28:06,863  The global step train is 1478
2019-04-26 19:28:06,993  The loss during training is  :: 0.024830007925629616 
2019-04-26 19:28:07,155  The global step train is 1479
2019-04-26 19:28:07,284  The loss during training is  :: 0.049560852348804474 
2019-04-26 19:28:07,450  The global step train is 1480
2019-04-26 19:28:07,578  The loss during training is  :: 0.08126568794250488 
2019-04-26 19:28:07,741  The global step train is 1481
2019-04-26 19:28:07,870  The loss during training is  :: 0.0336667001247406 
2019-04-26 19:28:08,034  The global step train is 1482
2019-04-26 19:28:08,167  The loss during training is  :: 0.04174811393022537 
2019-04-26 19:28:08,332  The global step train is 1483
2019-04-26 19:28:08,462  The loss during training is  :: 0.013076633214950562 
2019-04-26 19:28:08,624  The global step train is 1484
2019-04-26 19:28:08,754  The loss during training is  :: 0.020525945350527763 
2019-04-26 19:28:08,914  The global step train is 1485
2019-04-26 19:28:09,043  The loss during training is  :: 0.03901257365942001 
2019-04-26 19:28:09,203  The global step train is 1486
2019-04-26 19:28:09,337  The loss during training is  :: 0.07411753386259079 
2019-04-26 19:28:09,499  The global step train is 1487
2019-04-26 19:28:09,628  The loss during training is  :: 0.06204971298575401 
2019-04-26 19:28:09,794  The global step train is 1488
2019-04-26 19:28:09,925  The loss during training is  :: 0.060536835342645645 
2019-04-26 19:28:10,087  The global step train is 1489
2019-04-26 19:28:10,219  The loss during training is  :: 0.038829099386930466 
2019-04-26 19:28:10,380  The global step train is 1490
2019-04-26 19:28:10,507  The loss during training is  :: 0.021518908441066742 
2019-04-26 19:28:10,668  The global step train is 1491
2019-04-26 19:28:10,796  The loss during training is  :: 0.019728349521756172 
2019-04-26 19:28:10,957  The global step train is 1492
2019-04-26 19:28:11,085  The loss during training is  :: 0.0723104253411293 
2019-04-26 19:28:11,247  The global step train is 1493
2019-04-26 19:28:11,377  The loss during training is  :: 0.061973679810762405 
2019-04-26 19:28:11,541  The global step train is 1494
2019-04-26 19:28:11,668  The loss during training is  :: 0.07200954109430313 
2019-04-26 19:28:11,831  The global step train is 1495
2019-04-26 19:28:11,961  The loss during training is  :: 0.060816459357738495 
2019-04-26 19:28:12,123  The global step train is 1496
2019-04-26 19:28:12,257  The loss during training is  :: 0.05091088265180588 
2019-04-26 19:28:12,421  The global step train is 1497
2019-04-26 19:28:12,551  The loss during training is  :: 0.03995818272233009 
2019-04-26 19:28:12,710  The global step train is 1498
2019-04-26 19:28:12,838  The loss during training is  :: 0.020927654579281807 
2019-04-26 19:28:12,999  The global step train is 1499
2019-04-26 19:28:13,128  The loss during training is  :: 0.04143062233924866 
2019-04-26 19:28:13,290  The global step train is 1500
2019-04-26 19:28:13,421  The loss during training is  :: 0.025975195690989494 
2019-04-26 19:28:13,584  The global step train is 1501
2019-04-26 19:28:13,714  The loss during training is  :: 0.06821904331445694 
2019-04-26 19:28:13,873  The global step train is 1502
2019-04-26 19:28:14,004  The loss during training is  :: 0.07745567709207535 
2019-04-26 19:28:14,170  The global step train is 1503
2019-04-26 19:28:14,298  The loss during training is  :: 0.017891747877001762 
2019-04-26 19:28:14,464  The global step train is 1504
2019-04-26 19:28:14,590  The loss during training is  :: 0.05274686962366104 
2019-04-26 19:28:14,747  The global step train is 1505
2019-04-26 19:28:14,880  The loss during training is  :: 0.06393083930015564 
2019-04-26 19:28:15,038  The global step train is 1506
2019-04-26 19:28:15,169  The loss during training is  :: 0.050523627549409866 
2019-04-26 19:28:15,334  The global step train is 1507
2019-04-26 19:28:15,466  The loss during training is  :: 0.05393470078706741 
2019-04-26 19:28:15,640  The global step train is 1508
2019-04-26 19:28:15,772  The loss during training is  :: 0.07975520193576813 
2019-04-26 19:28:15,930  The global step train is 1509
2019-04-26 19:28:16,059  The loss during training is  :: 0.08168751746416092 
2019-04-26 19:28:16,219  The global step train is 1510
2019-04-26 19:28:16,349  The loss during training is  :: 0.07744107395410538 
2019-04-26 19:28:16,511  The global step train is 1511
2019-04-26 19:28:16,638  The loss during training is  :: 0.008505681529641151 
2019-04-26 19:28:16,798  The global step train is 1512
2019-04-26 19:28:16,928  The loss during training is  :: 0.031086470931768417 
2019-04-26 19:28:17,088  The global step train is 1513
2019-04-26 19:28:17,218  The loss during training is  :: 0.03094857931137085 
2019-04-26 19:28:17,390  The global step train is 1514
2019-04-26 19:28:17,523  The loss during training is  :: 0.045177459716796875 
2019-04-26 19:28:17,690  The global step train is 1515
2019-04-26 19:28:17,820  The loss during training is  :: 0.06840142607688904 
2019-04-26 19:28:17,989  The global step train is 1516
2019-04-26 19:28:18,116  The loss during training is  :: 0.10973507910966873 
2019-04-26 19:28:18,275  The global step train is 1517
2019-04-26 19:28:18,409  The loss during training is  :: 0.061735522001981735 
2019-04-26 19:28:18,571  The global step train is 1518
2019-04-26 19:28:18,694  The loss during training is  :: 0.022266356274485588 
2019-04-26 19:28:18,853  The global step train is 1519
2019-04-26 19:28:18,984  The loss during training is  :: 0.07906979322433472 
2019-04-26 19:28:19,146  The global step train is 1520
2019-04-26 19:28:19,276  The loss during training is  :: 0.02877049148082733 
2019-04-26 19:28:19,442  The global step train is 1521
2019-04-26 19:28:19,573  The loss during training is  :: 0.06591367721557617 
2019-04-26 19:28:19,739  The global step train is 1522
2019-04-26 19:28:19,870  The loss during training is  :: 0.043162863701581955 
2019-04-26 19:28:20,031  The global step train is 1523
2019-04-26 19:28:20,167  The loss during training is  :: 0.1352279633283615 
2019-04-26 19:28:20,329  The global step train is 1524
2019-04-26 19:28:20,463  The loss during training is  :: 0.05500245466828346 
2019-04-26 19:28:20,626  The global step train is 1525
2019-04-26 19:28:20,756  The loss during training is  :: 0.03224522992968559 
2019-04-26 19:28:20,917  The global step train is 1526
2019-04-26 19:28:21,048  The loss during training is  :: 0.051731377840042114 
2019-04-26 19:28:21,213  The global step train is 1527
2019-04-26 19:28:21,347  The loss during training is  :: 0.028158560395240784 
2019-04-26 19:28:21,507  The global step train is 1528
2019-04-26 19:28:21,639  The loss during training is  :: 0.06196506321430206 
2019-04-26 19:28:21,803  The global step train is 1529
2019-04-26 19:28:21,933  The loss during training is  :: 0.03302004560828209 
2019-04-26 19:28:22,100  The global step train is 1530
2019-04-26 19:28:22,239  The loss during training is  :: 0.06179934740066528 
2019-04-26 19:28:22,404  The global step train is 1531
2019-04-26 19:28:22,532  The loss during training is  :: 0.029696384444832802 
2019-04-26 19:28:22,696  The global step train is 1532
2019-04-26 19:28:22,827  The loss during training is  :: 0.025580812245607376 
2019-04-26 19:28:22,989  The global step train is 1533
2019-04-26 19:28:23,121  The loss during training is  :: 0.016255391761660576 
2019-04-26 19:28:23,282  The global step train is 1534
2019-04-26 19:28:23,416  The loss during training is  :: 0.0660477876663208 
2019-04-26 19:28:23,578  The global step train is 1535
2019-04-26 19:28:23,710  The loss during training is  :: 0.013557398691773415 
2019-04-26 19:28:23,875  The global step train is 1536
2019-04-26 19:28:24,009  The loss during training is  :: 0.10022082179784775 
2019-04-26 19:28:24,169  The global step train is 1537
2019-04-26 19:28:24,300  The loss during training is  :: 0.02659730240702629 
2019-04-26 19:28:24,458  The global step train is 1538
2019-04-26 19:28:24,589  The loss during training is  :: 0.021537860855460167 
2019-04-26 19:28:24,754  The global step train is 1539
2019-04-26 19:28:24,886  The loss during training is  :: 0.0655272901058197 
2019-04-26 19:28:25,044  The global step train is 1540
2019-04-26 19:28:25,174  The loss during training is  :: 0.02133936807513237 
2019-04-26 19:28:25,331  The global step train is 1541
2019-04-26 19:28:25,460  The loss during training is  :: 0.028075631707906723 
2019-04-26 19:28:25,618  The global step train is 1542
2019-04-26 19:28:25,750  The loss during training is  :: 0.017323758453130722 
2019-04-26 19:28:25,914  The global step train is 1543
2019-04-26 19:28:26,044  The loss during training is  :: 0.028656428679823875 
2019-04-26 19:28:26,206  The global step train is 1544
2019-04-26 19:28:26,331  The loss during training is  :: 0.0284865852445364 
2019-04-26 19:28:26,494  The global step train is 1545
2019-04-26 19:28:26,626  The loss during training is  :: 0.05105026066303253 
2019-04-26 19:28:26,788  The global step train is 1546
2019-04-26 19:28:26,918  The loss during training is  :: 0.020308248698711395 
2019-04-26 19:28:27,079  The global step train is 1547
2019-04-26 19:28:27,210  The loss during training is  :: 0.08342558890581131 
2019-04-26 19:28:27,373  The global step train is 1548
2019-04-26 19:28:27,498  The loss during training is  :: 0.050843387842178345 
2019-04-26 19:28:27,655  The global step train is 1549
2019-04-26 19:28:27,785  The loss during training is  :: 0.07480775564908981 
2019-04-26 19:28:27,943  The global step train is 1550
2019-04-26 19:28:28,065  The loss during training is  :: 0.040067777037620544 
2019-04-26 19:28:28,228  The global step train is 1551
2019-04-26 19:28:28,362  The loss during training is  :: 0.052969250828027725 
2019-04-26 19:28:28,526  The global step train is 1552
2019-04-26 19:28:28,657  The loss during training is  :: 0.043027132749557495 
2019-04-26 19:28:28,811  The global step train is 1553
2019-04-26 19:28:28,942  The loss during training is  :: 0.020264070481061935 
2019-04-26 19:28:29,104  The global step train is 1554
2019-04-26 19:28:29,233  The loss during training is  :: 0.07485464960336685 
2019-04-26 19:28:29,392  The global step train is 1555
2019-04-26 19:28:29,524  The loss during training is  :: 0.05819614976644516 
2019-04-26 19:28:29,681  The global step train is 1556
2019-04-26 19:28:29,815  The loss during training is  :: 0.040793538093566895 
2019-04-26 19:28:29,976  The global step train is 1557
2019-04-26 19:28:30,106  The loss during training is  :: 0.048820860683918 
2019-04-26 19:28:30,269  The global step train is 1558
2019-04-26 19:28:30,399  The loss during training is  :: 0.027645902708172798 
2019-04-26 19:28:30,557  The global step train is 1559
2019-04-26 19:28:30,686  The loss during training is  :: 0.05781606212258339 
2019-04-26 19:28:30,841  The global step train is 1560
2019-04-26 19:28:30,975  The loss during training is  :: 0.0696677640080452 
2019-04-26 19:28:31,132  The global step train is 1561
2019-04-26 19:28:31,254  The loss during training is  :: 0.05332188680768013 
2019-04-26 19:28:31,418  The global step train is 1562
2019-04-26 19:28:31,544  The loss during training is  :: 0.07574500143527985 
2019-04-26 19:28:31,702  The global step train is 1563
2019-04-26 19:28:31,832  The loss during training is  :: 0.03401251137256622 
2019-04-26 19:28:31,990  The global step train is 1564
2019-04-26 19:28:32,123  The loss during training is  :: 0.07396915555000305 
2019-04-26 19:28:32,285  The global step train is 1565
2019-04-26 19:28:32,412  The loss during training is  :: 0.03125539794564247 
2019-04-26 19:28:32,574  The global step train is 1566
2019-04-26 19:28:32,703  The loss during training is  :: 0.020663945004343987 
2019-04-26 19:28:32,858  The global step train is 1567
2019-04-26 19:28:32,991  The loss during training is  :: 0.037262968719005585 
2019-04-26 19:28:33,147  The global step train is 1568
2019-04-26 19:28:33,149  Starting evaluation 
2019-04-26 19:28:33,287  The loss during eval_loss is  :: 0.052559636533260345
2019-04-26 19:28:33,289  The global step eval is 337
2019-04-26 19:28:33,407  The loss during eval_loss is  :: 0.044547442346811295
2019-04-26 19:28:33,409  The global step eval is 338
2019-04-26 19:28:33,519  The loss during eval_loss is  :: 0.04062805324792862
2019-04-26 19:28:33,521  The global step eval is 339
2019-04-26 19:28:33,626  The loss during eval_loss is  :: 0.03926590830087662
2019-04-26 19:28:33,628  The global step eval is 340
2019-04-26 19:28:33,733  The loss during eval_loss is  :: 0.09194541722536087
2019-04-26 19:28:33,734  The global step eval is 341
2019-04-26 19:28:33,837  The loss during eval_loss is  :: 0.09902461618185043
2019-04-26 19:28:33,839  The global step eval is 342
2019-04-26 19:28:33,944  The loss during eval_loss is  :: 0.10103540122509003
2019-04-26 19:28:33,946  The global step eval is 343
2019-04-26 19:28:34,057  The loss during eval_loss is  :: 0.01595430076122284
2019-04-26 19:28:34,059  The global step eval is 344
2019-04-26 19:28:34,188  The loss during eval_loss is  :: 0.10382120311260223
2019-04-26 19:28:34,190  The global step eval is 345
2019-04-26 19:28:34,304  The loss during eval_loss is  :: 0.02734616957604885
2019-04-26 19:28:34,306  The global step eval is 346
2019-04-26 19:28:34,419  The loss during eval_loss is  :: 0.10206154733896255
2019-04-26 19:28:34,421  The global step eval is 347
2019-04-26 19:28:34,534  The loss during eval_loss is  :: 0.06818076968193054
2019-04-26 19:28:34,535  The global step eval is 348
2019-04-26 19:28:34,648  The loss during eval_loss is  :: 0.061086367815732956
2019-04-26 19:28:34,650  The global step eval is 349
2019-04-26 19:28:34,755  The loss during eval_loss is  :: 0.03786212578415871
2019-04-26 19:28:34,757  The global step eval is 350
2019-04-26 19:28:34,865  The loss during eval_loss is  :: 0.0712684914469719
2019-04-26 19:28:34,867  The global step eval is 351
2019-04-26 19:28:34,986  The loss during eval_loss is  :: 0.09311991184949875
2019-04-26 19:28:34,988  The global step eval is 352
2019-04-26 19:28:35,100  The loss during eval_loss is  :: 0.10300954431295395
2019-04-26 19:28:35,102  The global step eval is 353
2019-04-26 19:28:35,216  The loss during eval_loss is  :: 0.17509770393371582
2019-04-26 19:28:35,218  The global step eval is 354
2019-04-26 19:28:35,322  The loss during eval_loss is  :: 0.04150005802512169
2019-04-26 19:28:35,324  The global step eval is 355
2019-04-26 19:28:35,430  The loss during eval_loss is  :: 0.07378372550010681
2019-04-26 19:28:35,431  The global step eval is 356
2019-04-26 19:28:35,544  The loss during eval_loss is  :: 0.15516826510429382
2019-04-26 19:28:35,546  The global step eval is 357
2019-04-26 19:28:35,663  The loss during eval_loss is  :: 0.06866548955440521
2019-04-26 19:28:35,665  The global step eval is 358
2019-04-26 19:28:35,771  The loss during eval_loss is  :: 0.0508849062025547
2019-04-26 19:28:35,772  The global step eval is 359
2019-04-26 19:28:35,885  The loss during eval_loss is  :: 0.03720508888363838
2019-04-26 19:28:35,887  The global step eval is 360
2019-04-26 19:28:36,005  The loss during eval_loss is  :: 0.04403027892112732
2019-04-26 19:28:36,007  The global step eval is 361
2019-04-26 19:28:36,110  The loss during eval_loss is  :: 0.05374559387564659
2019-04-26 19:28:36,112  The global step eval is 362
2019-04-26 19:28:36,224  The loss during eval_loss is  :: 0.06115064024925232
2019-04-26 19:28:36,226  The global step eval is 363
2019-04-26 19:28:36,331  The loss during eval_loss is  :: 0.05742965638637543
2019-04-26 19:28:36,333  The global step eval is 364
2019-04-26 19:28:36,444  The loss during eval_loss is  :: 0.06828303635120392
2019-04-26 19:28:36,446  The global step eval is 365
2019-04-26 19:28:36,560  The loss during eval_loss is  :: 0.04403875023126602
2019-04-26 19:28:36,562  The global step eval is 366
2019-04-26 19:28:36,681  The loss during eval_loss is  :: 0.03933070972561836
2019-04-26 19:28:36,683  The global step eval is 367
2019-04-26 19:28:36,784  The loss during eval_loss is  :: 0.05996761843562126
2019-04-26 19:28:36,786  The global step eval is 368
2019-04-26 19:28:36,899  The loss during eval_loss is  :: 0.10680590569972992
2019-04-26 19:28:36,901  The global step eval is 369
2019-04-26 19:28:37,005  The loss during eval_loss is  :: 0.14568376541137695
2019-04-26 19:28:37,007  The global step eval is 370
2019-04-26 19:28:37,110  The loss during eval_loss is  :: 0.06626629084348679
2019-04-26 19:28:37,111  The global step eval is 371
2019-04-26 19:28:37,222  The loss during eval_loss is  :: 0.09346919506788254
2019-04-26 19:28:37,224  The global step eval is 372
2019-04-26 19:28:37,335  The loss during eval_loss is  :: 0.07290872931480408
2019-04-26 19:28:37,337  The global step eval is 373
2019-04-26 19:28:37,448  The loss during eval_loss is  :: 0.05486457794904709
2019-04-26 19:28:37,450  The global step eval is 374
2019-04-26 19:28:37,559  The loss during eval_loss is  :: 0.020644763484597206
2019-04-26 19:28:37,561  The global step eval is 375
2019-04-26 19:28:37,674  The loss during eval_loss is  :: 0.04826897755265236
2019-04-26 19:28:37,675  The global step eval is 376
2019-04-26 19:28:37,777  The loss during eval_loss is  :: 0.050967585295438766
2019-04-26 19:28:37,779  The global step eval is 377
2019-04-26 19:28:37,881  The loss during eval_loss is  :: 0.03238222375512123
2019-04-26 19:28:37,882  The global step eval is 378
2019-04-26 19:28:37,997  The loss during eval_loss is  :: 0.08453796058893204
2019-04-26 19:28:37,998  The global step eval is 379
2019-04-26 19:28:38,110  The loss during eval_loss is  :: 0.05298416316509247
2019-04-26 19:28:38,112  The global step eval is 380
2019-04-26 19:28:38,224  The loss during eval_loss is  :: 0.11312947422266006
2019-04-26 19:28:38,225  The global step eval is 381
2019-04-26 19:28:38,327  The loss during eval_loss is  :: 0.05647454038262367
2019-04-26 19:28:38,329  The global step eval is 382
2019-04-26 19:28:38,444  The loss during eval_loss is  :: 0.12850433588027954
2019-04-26 19:28:38,446  The global step eval is 383
2019-04-26 19:28:38,559  The loss during eval_loss is  :: 0.09543903917074203
2019-04-26 19:28:38,561  The global step eval is 384
2019-04-26 19:28:38,670  The loss during eval_loss is  :: 0.030671298503875732
2019-04-26 19:28:38,672  The global step eval is 385
2019-04-26 19:28:38,786  The loss during eval_loss is  :: 0.13637001812458038
2019-04-26 19:28:38,788  The global step eval is 386
2019-04-26 19:28:38,898  The loss during eval_loss is  :: 0.14897987246513367
2019-04-26 19:28:38,899  The global step eval is 387
2019-04-26 19:28:39,007  The loss during eval_loss is  :: 0.05382312089204788
2019-04-26 19:28:39,009  The global step eval is 388
2019-04-26 19:28:39,122  The loss during eval_loss is  :: 0.050052523612976074
2019-04-26 19:28:39,124  The global step eval is 389
2019-04-26 19:28:39,236  The loss during eval_loss is  :: 0.026793384924530983
2019-04-26 19:28:39,238  The global step eval is 390
2019-04-26 19:28:39,355  The loss during eval_loss is  :: 0.04250016435980797
2019-04-26 19:28:39,356  The global step eval is 391
2019-04-26 19:28:39,460  The loss during eval_loss is  :: 0.09798887372016907
2019-04-26 19:28:39,462  The global step eval is 392
2019-04-26 19:28:39,474  Saved checkpoint: ./trained_model\step_6.pth.tar
2019-04-26 19:28:39,475  Removed checkpoint: ./trained_model\step_2.pth.tar
2019-04-26 19:28:39,590  The loss during training is  :: 0.015372371301054955 
2019-04-26 19:28:39,736  The global step train is 1569
2019-04-26 19:28:39,866  The loss during training is  :: 0.011656459420919418 
2019-04-26 19:28:40,027  The global step train is 1570
2019-04-26 19:28:40,157  The loss during training is  :: 0.04090845584869385 
2019-04-26 19:28:40,321  The global step train is 1571
2019-04-26 19:28:40,444  The loss during training is  :: 0.02561871148645878 
2019-04-26 19:28:40,601  The global step train is 1572
2019-04-26 19:28:40,733  The loss during training is  :: 0.027056967839598656 
2019-04-26 19:28:40,909  The global step train is 1573
2019-04-26 19:28:41,038  The loss during training is  :: 0.021746892482042313 
2019-04-26 19:28:41,204  The global step train is 1574
2019-04-26 19:28:41,376  The loss during training is  :: 0.060331523418426514 
2019-04-26 19:28:41,538  The global step train is 1575
2019-04-26 19:28:41,669  The loss during training is  :: 0.05306020379066467 
2019-04-26 19:28:41,830  The global step train is 1576
2019-04-26 19:28:41,959  The loss during training is  :: 0.03544573485851288 
2019-04-26 19:28:42,118  The global step train is 1577
2019-04-26 19:28:42,246  The loss during training is  :: 0.033676937222480774 
2019-04-26 19:28:42,412  The global step train is 1578
2019-04-26 19:28:42,539  The loss during training is  :: 0.03169696033000946 
2019-04-26 19:28:42,701  The global step train is 1579
2019-04-26 19:28:42,833  The loss during training is  :: 0.009606453590095043 
2019-04-26 19:28:42,996  The global step train is 1580
2019-04-26 19:28:43,124  The loss during training is  :: 0.021041734144091606 
2019-04-26 19:28:43,288  The global step train is 1581
2019-04-26 19:28:43,417  The loss during training is  :: 0.07638995349407196 
2019-04-26 19:28:43,583  The global step train is 1582
2019-04-26 19:28:43,713  The loss during training is  :: 0.035752102732658386 
2019-04-26 19:28:43,872  The global step train is 1583
2019-04-26 19:28:44,004  The loss during training is  :: 0.030804269015789032 
2019-04-26 19:28:44,176  The global step train is 1584
2019-04-26 19:28:44,306  The loss during training is  :: 0.035529255867004395 
2019-04-26 19:28:44,474  The global step train is 1585
2019-04-26 19:28:44,605  The loss during training is  :: 0.0990968644618988 
2019-04-26 19:28:44,765  The global step train is 1586
2019-04-26 19:28:44,898  The loss during training is  :: 0.058846600353717804 
2019-04-26 19:28:45,060  The global step train is 1587
2019-04-26 19:28:45,185  The loss during training is  :: 0.07861015200614929 
2019-04-26 19:28:45,347  The global step train is 1588
2019-04-26 19:28:45,473  The loss during training is  :: 0.014016679488122463 
2019-04-26 19:28:45,635  The global step train is 1589
2019-04-26 19:28:45,763  The loss during training is  :: 0.02594861015677452 
2019-04-26 19:28:45,924  The global step train is 1590
2019-04-26 19:28:46,054  The loss during training is  :: 0.058458950370550156 
2019-04-26 19:28:46,216  The global step train is 1591
2019-04-26 19:28:46,347  The loss during training is  :: 0.03153396025300026 
2019-04-26 19:28:46,508  The global step train is 1592
2019-04-26 19:28:46,639  The loss during training is  :: 0.023516803979873657 
2019-04-26 19:28:46,799  The global step train is 1593
2019-04-26 19:28:46,933  The loss during training is  :: 0.029969142749905586 
2019-04-26 19:28:47,094  The global step train is 1594
2019-04-26 19:28:47,217  The loss during training is  :: 0.037322260439395905 
2019-04-26 19:28:47,381  The global step train is 1595
2019-04-26 19:28:47,513  The loss during training is  :: 0.026523832231760025 
2019-04-26 19:28:47,675  The global step train is 1596
2019-04-26 19:28:47,804  The loss during training is  :: 0.07420629262924194 
2019-04-26 19:28:47,959  The global step train is 1597
2019-04-26 19:28:48,092  The loss during training is  :: 0.011727981269359589 
2019-04-26 19:28:48,257  The global step train is 1598
2019-04-26 19:28:48,389  The loss during training is  :: 0.04325471073389053 
2019-04-26 19:28:48,551  The global step train is 1599
2019-04-26 19:28:48,679  The loss during training is  :: 0.03203873336315155 
2019-04-26 19:28:48,838  The global step train is 1600
2019-04-26 19:28:48,967  The loss during training is  :: 0.04443394020199776 
2019-04-26 19:28:49,126  The global step train is 1601
2019-04-26 19:28:49,259  The loss during training is  :: 0.1589464247226715 
2019-04-26 19:28:49,419  The global step train is 1602
2019-04-26 19:28:49,544  The loss during training is  :: 0.03076007217168808 
2019-04-26 19:28:49,704  The global step train is 1603
2019-04-26 19:28:49,834  The loss during training is  :: 0.044190745800733566 
2019-04-26 19:28:50,001  The global step train is 1604
2019-04-26 19:28:50,130  The loss during training is  :: 0.053051531314849854 
2019-04-26 19:28:50,296  The global step train is 1605
2019-04-26 19:28:50,429  The loss during training is  :: 0.03977316990494728 
2019-04-26 19:28:50,587  The global step train is 1606
2019-04-26 19:28:50,715  The loss during training is  :: 0.032432038336992264 
2019-04-26 19:28:50,878  The global step train is 1607
2019-04-26 19:28:51,009  The loss during training is  :: 0.017368528991937637 
2019-04-26 19:28:51,171  The global step train is 1608
2019-04-26 19:28:51,301  The loss during training is  :: 0.03125729411840439 
2019-04-26 19:28:51,464  The global step train is 1609
2019-04-26 19:28:51,595  The loss during training is  :: 0.08561643958091736 
2019-04-26 19:28:51,769  The global step train is 1610
2019-04-26 19:28:51,894  The loss during training is  :: 0.030535303056240082 
2019-04-26 19:28:52,053  The global step train is 1611
2019-04-26 19:28:52,187  The loss during training is  :: 0.012838630937039852 
2019-04-26 19:28:52,352  The global step train is 1612
2019-04-26 19:28:52,478  The loss during training is  :: 0.012343193404376507 
2019-04-26 19:28:52,636  The global step train is 1613
2019-04-26 19:28:52,768  The loss during training is  :: 0.018610341474413872 
2019-04-26 19:28:52,929  The global step train is 1614
2019-04-26 19:28:53,053  The loss during training is  :: 0.08277755975723267 
2019-04-26 19:28:53,220  The global step train is 1615
2019-04-26 19:28:53,348  The loss during training is  :: 0.033791881054639816 
2019-04-26 19:28:53,510  The global step train is 1616
2019-04-26 19:28:53,640  The loss during training is  :: 0.06508729606866837 
2019-04-26 19:28:53,805  The global step train is 1617
2019-04-26 19:28:53,935  The loss during training is  :: 0.03857919201254845 
2019-04-26 19:28:54,102  The global step train is 1618
2019-04-26 19:28:54,233  The loss during training is  :: 0.013698739930987358 
2019-04-26 19:28:54,394  The global step train is 1619
2019-04-26 19:28:54,528  The loss during training is  :: 0.02135712467133999 
2019-04-26 19:28:54,691  The global step train is 1620
2019-04-26 19:28:54,822  The loss during training is  :: 0.028599532321095467 
2019-04-26 19:28:54,986  The global step train is 1621
2019-04-26 19:28:55,116  The loss during training is  :: 0.024586305022239685 
2019-04-26 19:28:55,273  The global step train is 1622
2019-04-26 19:28:55,401  The loss during training is  :: 0.04375175014138222 
2019-04-26 19:28:55,564  The global step train is 1623
2019-04-26 19:28:55,693  The loss during training is  :: 0.024243593215942383 
2019-04-26 19:28:55,856  The global step train is 1624
2019-04-26 19:28:55,984  The loss during training is  :: 0.06939084082841873 
2019-04-26 19:28:56,141  The global step train is 1625
2019-04-26 19:28:56,272  The loss during training is  :: 0.056894365698099136 
2019-04-26 19:28:56,436  The global step train is 1626
2019-04-26 19:28:56,568  The loss during training is  :: 0.013222014531493187 
2019-04-26 19:28:56,730  The global step train is 1627
2019-04-26 19:28:56,860  The loss during training is  :: 0.03861118108034134 
2019-04-26 19:28:57,022  The global step train is 1628
2019-04-26 19:28:57,150  The loss during training is  :: 0.041698239743709564 
2019-04-26 19:28:57,311  The global step train is 1629
2019-04-26 19:28:57,441  The loss during training is  :: 0.055157680064439774 
2019-04-26 19:28:57,600  The global step train is 1630
2019-04-26 19:28:57,727  The loss during training is  :: 0.07465766370296478 
2019-04-26 19:28:57,887  The global step train is 1631
2019-04-26 19:28:58,018  The loss during training is  :: 0.03267192468047142 
2019-04-26 19:28:58,179  The global step train is 1632
2019-04-26 19:28:58,306  The loss during training is  :: 0.07567206770181656 
2019-04-26 19:28:58,469  The global step train is 1633
2019-04-26 19:28:58,595  The loss during training is  :: 0.023660933598876 
2019-04-26 19:28:58,764  The global step train is 1634
2019-04-26 19:28:58,895  The loss during training is  :: 0.027403997257351875 
2019-04-26 19:28:59,053  The global step train is 1635
2019-04-26 19:28:59,182  The loss during training is  :: 0.035698000341653824 
2019-04-26 19:28:59,341  The global step train is 1636
2019-04-26 19:28:59,469  The loss during training is  :: 0.06182032823562622 
2019-04-26 19:28:59,628  The global step train is 1637
2019-04-26 19:28:59,762  The loss during training is  :: 0.01910497434437275 
2019-04-26 19:28:59,925  The global step train is 1638
2019-04-26 19:29:00,061  The loss during training is  :: 0.02422321029007435 
2019-04-26 19:29:00,236  The global step train is 1639
2019-04-26 19:29:00,382  The loss during training is  :: 0.07361655682325363 
2019-04-26 19:29:00,560  The global step train is 1640
2019-04-26 19:29:00,700  The loss during training is  :: 0.09251204878091812 
2019-04-26 19:29:00,864  The global step train is 1641
2019-04-26 19:29:01,003  The loss during training is  :: 0.04476495459675789 
2019-04-26 19:29:01,169  The global step train is 1642
2019-04-26 19:29:01,303  The loss during training is  :: 0.06532356888055801 
2019-04-26 19:29:01,466  The global step train is 1643
2019-04-26 19:29:01,596  The loss during training is  :: 0.013620437122881413 
2019-04-26 19:29:01,761  The global step train is 1644
2019-04-26 19:29:01,892  The loss during training is  :: 0.04781481623649597 
2019-04-26 19:29:02,052  The global step train is 1645
2019-04-26 19:29:02,183  The loss during training is  :: 0.03674011304974556 
2019-04-26 19:29:02,348  The global step train is 1646
2019-04-26 19:29:02,467  The loss during training is  :: 0.07563058286905289 
2019-04-26 19:29:02,628  The global step train is 1647
2019-04-26 19:29:02,754  The loss during training is  :: 0.027480565011501312 
2019-04-26 19:29:02,918  The global step train is 1648
2019-04-26 19:29:03,046  The loss during training is  :: 0.09986525028944016 
2019-04-26 19:29:03,208  The global step train is 1649
2019-04-26 19:29:03,338  The loss during training is  :: 0.028101202100515366 
2019-04-26 19:29:03,498  The global step train is 1650
2019-04-26 19:29:03,632  The loss during training is  :: 0.040196798741817474 
2019-04-26 19:29:03,795  The global step train is 1651
2019-04-26 19:29:03,920  The loss during training is  :: 0.03023354522883892 
2019-04-26 19:29:04,080  The global step train is 1652
2019-04-26 19:29:04,211  The loss during training is  :: 0.03372630849480629 
2019-04-26 19:29:04,377  The global step train is 1653
2019-04-26 19:29:04,502  The loss during training is  :: 0.006077149882912636 
2019-04-26 19:29:04,664  The global step train is 1654
2019-04-26 19:29:04,795  The loss during training is  :: 0.045866817235946655 
2019-04-26 19:29:04,957  The global step train is 1655
2019-04-26 19:29:05,090  The loss during training is  :: 0.031036436557769775 
2019-04-26 19:29:05,252  The global step train is 1656
2019-04-26 19:29:05,384  The loss during training is  :: 0.0579540878534317 
2019-04-26 19:29:05,545  The global step train is 1657
2019-04-26 19:29:05,675  The loss during training is  :: 0.04831470921635628 
2019-04-26 19:29:05,842  The global step train is 1658
2019-04-26 19:29:05,967  The loss during training is  :: 0.039217207580804825 
2019-04-26 19:29:06,129  The global step train is 1659
2019-04-26 19:29:06,255  The loss during training is  :: 0.04093117266893387 
2019-04-26 19:29:06,414  The global step train is 1660
2019-04-26 19:29:06,538  The loss during training is  :: 0.014995507895946503 
2019-04-26 19:29:06,698  The global step train is 1661
2019-04-26 19:29:06,826  The loss during training is  :: 0.05412966385483742 
2019-04-26 19:29:06,991  The global step train is 1662
2019-04-26 19:29:07,120  The loss during training is  :: 0.020875679329037666 
2019-04-26 19:29:07,281  The global step train is 1663
2019-04-26 19:29:07,409  The loss during training is  :: 0.03690967708826065 
2019-04-26 19:29:07,570  The global step train is 1664
2019-04-26 19:29:07,702  The loss during training is  :: 0.022748464718461037 
2019-04-26 19:29:07,871  The global step train is 1665
2019-04-26 19:29:08,004  The loss during training is  :: 0.03162263706326485 
2019-04-26 19:29:08,166  The global step train is 1666
2019-04-26 19:29:08,296  The loss during training is  :: 0.020079946145415306 
2019-04-26 19:29:08,463  The global step train is 1667
2019-04-26 19:29:08,591  The loss during training is  :: 0.04737848415970802 
2019-04-26 19:29:08,751  The global step train is 1668
2019-04-26 19:29:08,882  The loss during training is  :: 0.08005493134260178 
2019-04-26 19:29:09,048  The global step train is 1669
2019-04-26 19:29:09,182  The loss during training is  :: 0.06237833574414253 
2019-04-26 19:29:09,347  The global step train is 1670
2019-04-26 19:29:09,480  The loss during training is  :: 0.016824668273329735 
2019-04-26 19:29:09,638  The global step train is 1671
2019-04-26 19:29:09,770  The loss during training is  :: 0.014555282890796661 
2019-04-26 19:29:09,933  The global step train is 1672
2019-04-26 19:29:10,061  The loss during training is  :: 0.02554861642420292 
2019-04-26 19:29:10,221  The global step train is 1673
2019-04-26 19:29:10,347  The loss during training is  :: 0.06146174296736717 
2019-04-26 19:29:10,506  The global step train is 1674
2019-04-26 19:29:10,634  The loss during training is  :: 0.10544058680534363 
2019-04-26 19:29:10,796  The global step train is 1675
2019-04-26 19:29:10,924  The loss during training is  :: 0.017549807205796242 
2019-04-26 19:29:11,083  The global step train is 1676
2019-04-26 19:29:11,208  The loss during training is  :: 0.004559040069580078 
2019-04-26 19:29:11,378  The global step train is 1677
2019-04-26 19:29:11,508  The loss during training is  :: 0.01636800728738308 
2019-04-26 19:29:11,667  The global step train is 1678
2019-04-26 19:29:11,798  The loss during training is  :: 0.03802132606506348 
2019-04-26 19:29:11,959  The global step train is 1679
2019-04-26 19:29:12,088  The loss during training is  :: 0.016012942418456078 
2019-04-26 19:29:12,250  The global step train is 1680
2019-04-26 19:29:12,380  The loss during training is  :: 0.0354229100048542 
2019-04-26 19:29:12,543  The global step train is 1681
2019-04-26 19:29:12,665  The loss during training is  :: 0.018267802894115448 
2019-04-26 19:29:12,829  The global step train is 1682
2019-04-26 19:29:12,957  The loss during training is  :: 0.021906277164816856 
2019-04-26 19:29:13,119  The global step train is 1683
2019-04-26 19:29:13,243  The loss during training is  :: 0.047194402664899826 
2019-04-26 19:29:13,405  The global step train is 1684
2019-04-26 19:29:13,539  The loss during training is  :: 0.014676465652883053 
2019-04-26 19:29:13,698  The global step train is 1685
2019-04-26 19:29:13,826  The loss during training is  :: 0.024349968880414963 
2019-04-26 19:29:13,989  The global step train is 1686
2019-04-26 19:29:14,118  The loss during training is  :: 0.045892197638750076 
2019-04-26 19:29:14,288  The global step train is 1687
2019-04-26 19:29:14,419  The loss during training is  :: 0.046024471521377563 
2019-04-26 19:29:14,583  The global step train is 1688
2019-04-26 19:29:14,710  The loss during training is  :: 0.018804794177412987 
2019-04-26 19:29:14,871  The global step train is 1689
2019-04-26 19:29:14,999  The loss during training is  :: 0.02421349473297596 
2019-04-26 19:29:15,158  The global step train is 1690
2019-04-26 19:29:15,284  The loss during training is  :: 0.04013541340827942 
2019-04-26 19:29:15,446  The global step train is 1691
2019-04-26 19:29:15,575  The loss during training is  :: 0.0572625994682312 
2019-04-26 19:29:15,736  The global step train is 1692
2019-04-26 19:29:15,867  The loss during training is  :: 0.04478292167186737 
2019-04-26 19:29:16,031  The global step train is 1693
2019-04-26 19:29:16,161  The loss during training is  :: 0.022286593914031982 
2019-04-26 19:29:16,328  The global step train is 1694
2019-04-26 19:29:16,458  The loss during training is  :: 0.04805152118206024 
2019-04-26 19:29:16,623  The global step train is 1695
2019-04-26 19:29:16,756  The loss during training is  :: 0.008621362037956715 
2019-04-26 19:29:16,920  The global step train is 1696
2019-04-26 19:29:17,053  The loss during training is  :: 0.018883781507611275 
2019-04-26 19:29:17,210  The global step train is 1697
2019-04-26 19:29:17,344  The loss during training is  :: 0.011801224201917648 
2019-04-26 19:29:17,504  The global step train is 1698
2019-04-26 19:29:17,630  The loss during training is  :: 0.02578914910554886 
2019-04-26 19:29:17,798  The global step train is 1699
2019-04-26 19:29:17,927  The loss during training is  :: 0.036015257239341736 
2019-04-26 19:29:18,093  The global step train is 1700
2019-04-26 19:29:18,225  The loss during training is  :: 0.020748723298311234 
2019-04-26 19:29:18,388  The global step train is 1701
2019-04-26 19:29:18,520  The loss during training is  :: 0.03444543108344078 
2019-04-26 19:29:18,684  The global step train is 1702
2019-04-26 19:29:18,816  The loss during training is  :: 0.035071324557065964 
2019-04-26 19:29:18,980  The global step train is 1703
2019-04-26 19:29:19,107  The loss during training is  :: 0.017766274511814117 
2019-04-26 19:29:19,263  The global step train is 1704
2019-04-26 19:29:19,386  The loss during training is  :: 0.05147683620452881 
2019-04-26 19:29:19,559  The global step train is 1705
2019-04-26 19:29:19,686  The loss during training is  :: 0.07156209647655487 
2019-04-26 19:29:19,846  The global step train is 1706
2019-04-26 19:29:19,979  The loss during training is  :: 0.01671978272497654 
2019-04-26 19:29:20,142  The global step train is 1707
2019-04-26 19:29:20,272  The loss during training is  :: 0.009852876886725426 
2019-04-26 19:29:20,438  The global step train is 1708
2019-04-26 19:29:20,567  The loss during training is  :: 0.015031334944069386 
2019-04-26 19:29:20,731  The global step train is 1709
2019-04-26 19:29:20,856  The loss during training is  :: 0.0843423530459404 
2019-04-26 19:29:21,024  The global step train is 1710
2019-04-26 19:29:21,154  The loss during training is  :: 0.034646689891815186 
2019-04-26 19:29:21,315  The global step train is 1711
2019-04-26 19:29:21,442  The loss during training is  :: 0.06274103373289108 
2019-04-26 19:29:21,602  The global step train is 1712
2019-04-26 19:29:21,735  The loss during training is  :: 0.07853804528713226 
2019-04-26 19:29:21,900  The global step train is 1713
2019-04-26 19:29:22,029  The loss during training is  :: 0.01855861395597458 
2019-04-26 19:29:22,196  The global step train is 1714
2019-04-26 19:29:22,325  The loss during training is  :: 0.07896577566862106 
2019-04-26 19:29:22,489  The global step train is 1715
2019-04-26 19:29:22,619  The loss during training is  :: 0.01701308973133564 
2019-04-26 19:29:22,783  The global step train is 1716
2019-04-26 19:29:22,913  The loss during training is  :: 0.012183030135929585 
2019-04-26 19:29:23,084  The global step train is 1717
2019-04-26 19:29:23,212  The loss during training is  :: 0.07174351811408997 
2019-04-26 19:29:23,373  The global step train is 1718
2019-04-26 19:29:23,505  The loss during training is  :: 0.04072994738817215 
2019-04-26 19:29:23,667  The global step train is 1719
2019-04-26 19:29:23,802  The loss during training is  :: 0.022337283939123154 
2019-04-26 19:29:23,964  The global step train is 1720
2019-04-26 19:29:24,094  The loss during training is  :: 0.012686531990766525 
2019-04-26 19:29:24,263  The global step train is 1721
2019-04-26 19:29:24,399  The loss during training is  :: 0.04307509958744049 
2019-04-26 19:29:24,559  The global step train is 1722
2019-04-26 19:29:24,687  The loss during training is  :: 0.031202398240566254 
2019-04-26 19:29:24,850  The global step train is 1723
2019-04-26 19:29:24,979  The loss during training is  :: 0.07757535576820374 
2019-04-26 19:29:25,134  The global step train is 1724
2019-04-26 19:29:25,265  The loss during training is  :: 0.06038396805524826 
2019-04-26 19:29:25,428  The global step train is 1725
2019-04-26 19:29:25,559  The loss during training is  :: 0.04234258830547333 
2019-04-26 19:29:25,717  The global step train is 1726
2019-04-26 19:29:25,844  The loss during training is  :: 0.011953490786254406 
2019-04-26 19:29:26,008  The global step train is 1727
2019-04-26 19:29:26,139  The loss during training is  :: 0.04014241695404053 
2019-04-26 19:29:26,301  The global step train is 1728
2019-04-26 19:29:26,435  The loss during training is  :: 0.02126968652009964 
2019-04-26 19:29:26,597  The global step train is 1729
2019-04-26 19:29:26,729  The loss during training is  :: 0.01717429794371128 
2019-04-26 19:29:26,895  The global step train is 1730
2019-04-26 19:29:27,023  The loss during training is  :: 0.011166347190737724 
2019-04-26 19:29:27,186  The global step train is 1731
2019-04-26 19:29:27,319  The loss during training is  :: 0.02710944227874279 
2019-04-26 19:29:27,486  The global step train is 1732
2019-04-26 19:29:27,611  The loss during training is  :: 0.06598369032144547 
2019-04-26 19:29:27,776  The global step train is 1733
2019-04-26 19:29:27,903  The loss during training is  :: 0.025087345391511917 
2019-04-26 19:29:28,063  The global step train is 1734
2019-04-26 19:29:28,188  The loss during training is  :: 0.045531000941991806 
2019-04-26 19:29:28,351  The global step train is 1735
2019-04-26 19:29:28,481  The loss during training is  :: 0.049916669726371765 
2019-04-26 19:29:28,643  The global step train is 1736
2019-04-26 19:29:28,775  The loss during training is  :: 0.029297608882188797 
2019-04-26 19:29:28,933  The global step train is 1737
2019-04-26 19:29:29,060  The loss during training is  :: 0.02157876081764698 
2019-04-26 19:29:29,224  The global step train is 1738
2019-04-26 19:29:29,352  The loss during training is  :: 0.03197404369711876 
2019-04-26 19:29:29,515  The global step train is 1739
2019-04-26 19:29:29,635  The loss during training is  :: 0.03071402572095394 
2019-04-26 19:29:29,797  The global step train is 1740
2019-04-26 19:29:29,921  The loss during training is  :: 0.06038249284029007 
2019-04-26 19:29:30,095  The global step train is 1741
2019-04-26 19:29:30,226  The loss during training is  :: 0.07217271625995636 
2019-04-26 19:29:30,391  The global step train is 1742
2019-04-26 19:29:30,522  The loss during training is  :: 0.03731967881321907 
2019-04-26 19:29:30,682  The global step train is 1743
2019-04-26 19:29:30,813  The loss during training is  :: 0.04580512270331383 
2019-04-26 19:29:30,978  The global step train is 1744
2019-04-26 19:29:31,103  The loss during training is  :: 0.03358406573534012 
2019-04-26 19:29:31,265  The global step train is 1745
2019-04-26 19:29:31,396  The loss during training is  :: 0.046561505645513535 
2019-04-26 19:29:31,567  The global step train is 1746
2019-04-26 19:29:31,694  The loss during training is  :: 0.06600279361009598 
2019-04-26 19:29:31,850  The global step train is 1747
2019-04-26 19:29:31,980  The loss during training is  :: 0.0430084764957428 
2019-04-26 19:29:32,140  The global step train is 1748
2019-04-26 19:29:32,267  The loss during training is  :: 0.043613251298666 
2019-04-26 19:29:32,422  The global step train is 1749
2019-04-26 19:29:32,552  The loss during training is  :: 0.05130043998360634 
2019-04-26 19:29:32,715  The global step train is 1750
2019-04-26 19:29:32,842  The loss during training is  :: 0.03433535248041153 
2019-04-26 19:29:33,005  The global step train is 1751
2019-04-26 19:29:33,138  The loss during training is  :: 0.030741462484002113 
2019-04-26 19:29:33,302  The global step train is 1752
2019-04-26 19:29:33,432  The loss during training is  :: 0.03884384408593178 
2019-04-26 19:29:33,594  The global step train is 1753
2019-04-26 19:29:33,722  The loss during training is  :: 0.018214868381619453 
2019-04-26 19:29:33,880  The global step train is 1754
2019-04-26 19:29:34,012  The loss during training is  :: 0.023397132754325867 
2019-04-26 19:29:34,179  The global step train is 1755
2019-04-26 19:29:34,305  The loss during training is  :: 0.035662129521369934 
2019-04-26 19:29:34,471  The global step train is 1756
2019-04-26 19:29:34,597  The loss during training is  :: 0.014371420256793499 
2019-04-26 19:29:34,761  The global step train is 1757
2019-04-26 19:29:34,894  The loss during training is  :: 0.058101851493120193 
2019-04-26 19:29:35,058  The global step train is 1758
2019-04-26 19:29:35,182  The loss during training is  :: 0.007471357937902212 
2019-04-26 19:29:35,345  The global step train is 1759
2019-04-26 19:29:35,471  The loss during training is  :: 0.01701316051185131 
2019-04-26 19:29:35,632  The global step train is 1760
2019-04-26 19:29:35,760  The loss during training is  :: 0.020239340141415596 
2019-04-26 19:29:35,925  The global step train is 1761
2019-04-26 19:29:36,054  The loss during training is  :: 0.0494350828230381 
2019-04-26 19:29:36,212  The global step train is 1762
2019-04-26 19:29:36,341  The loss during training is  :: 0.027239598333835602 
2019-04-26 19:29:36,505  The global step train is 1763
2019-04-26 19:29:36,631  The loss during training is  :: 0.06225995346903801 
2019-04-26 19:29:36,796  The global step train is 1764
2019-04-26 19:29:36,923  The loss during training is  :: 0.11434505134820938 
2019-04-26 19:29:37,102  The global step train is 1765
2019-04-26 19:29:37,228  The loss during training is  :: 0.07201879471540451 
2019-04-26 19:29:37,389  The global step train is 1766
2019-04-26 19:29:37,522  The loss during training is  :: 0.05806557461619377 
2019-04-26 19:29:37,691  The global step train is 1767
2019-04-26 19:29:37,818  The loss during training is  :: 0.10310734063386917 
2019-04-26 19:29:37,980  The global step train is 1768
2019-04-26 19:29:38,116  The loss during training is  :: 0.040124114602804184 
2019-04-26 19:29:38,280  The global step train is 1769
2019-04-26 19:29:38,405  The loss during training is  :: 0.034738436341285706 
2019-04-26 19:29:38,564  The global step train is 1770
2019-04-26 19:29:38,699  The loss during training is  :: 0.05889516696333885 
2019-04-26 19:29:38,854  The global step train is 1771
2019-04-26 19:29:38,975  The loss during training is  :: 0.04802803695201874 
2019-04-26 19:29:39,136  The global step train is 1772
2019-04-26 19:29:39,266  The loss during training is  :: 0.05676839128136635 
2019-04-26 19:29:39,423  The global step train is 1773
2019-04-26 19:29:39,549  The loss during training is  :: 0.016059046611189842 
2019-04-26 19:29:39,709  The global step train is 1774
2019-04-26 19:29:39,842  The loss during training is  :: 0.03960249572992325 
2019-04-26 19:29:40,000  The global step train is 1775
2019-04-26 19:29:40,131  The loss during training is  :: 0.017889076843857765 
2019-04-26 19:29:40,296  The global step train is 1776
2019-04-26 19:29:40,422  The loss during training is  :: 0.04853720963001251 
2019-04-26 19:29:40,585  The global step train is 1777
2019-04-26 19:29:40,712  The loss during training is  :: 0.019507868215441704 
2019-04-26 19:29:40,875  The global step train is 1778
2019-04-26 19:29:41,004  The loss during training is  :: 0.057782065123319626 
2019-04-26 19:29:41,165  The global step train is 1779
2019-04-26 19:29:41,299  The loss during training is  :: 0.038686603307724 
2019-04-26 19:29:41,467  The global step train is 1780
2019-04-26 19:29:41,594  The loss during training is  :: 0.035846758633852005 
2019-04-26 19:29:41,756  The global step train is 1781
2019-04-26 19:29:41,885  The loss during training is  :: 0.033023275434970856 
2019-04-26 19:29:42,048  The global step train is 1782
2019-04-26 19:29:42,175  The loss during training is  :: 0.03436044603586197 
2019-04-26 19:29:42,338  The global step train is 1783
2019-04-26 19:29:42,464  The loss during training is  :: 0.035550639033317566 
2019-04-26 19:29:42,627  The global step train is 1784
2019-04-26 19:29:42,756  The loss during training is  :: 0.03419037535786629 
2019-04-26 19:29:42,920  The global step train is 1785
2019-04-26 19:29:43,053  The loss during training is  :: 0.010722086764872074 
2019-04-26 19:29:43,215  The global step train is 1786
2019-04-26 19:29:43,344  The loss during training is  :: 0.05725159868597984 
2019-04-26 19:29:43,507  The global step train is 1787
2019-04-26 19:29:43,634  The loss during training is  :: 0.06653301417827606 
2019-04-26 19:29:43,797  The global step train is 1788
2019-04-26 19:29:43,922  The loss during training is  :: 0.06758955121040344 
2019-04-26 19:29:44,087  The global step train is 1789
2019-04-26 19:29:44,213  The loss during training is  :: 0.013191722333431244 
2019-04-26 19:29:44,376  The global step train is 1790
2019-04-26 19:29:44,508  The loss during training is  :: 0.027238085865974426 
2019-04-26 19:29:44,670  The global step train is 1791
2019-04-26 19:29:44,794  The loss during training is  :: 0.014757896773517132 
2019-04-26 19:29:44,956  The global step train is 1792
2019-04-26 19:29:44,958  Starting evaluation 
2019-04-26 19:29:45,098  The loss during eval_loss is  :: 0.06949705630540848
2019-04-26 19:29:45,100  The global step eval is 393
2019-04-26 19:29:45,225  The loss during eval_loss is  :: 0.035299744457006454
2019-04-26 19:29:45,227  The global step eval is 394
2019-04-26 19:29:45,343  The loss during eval_loss is  :: 0.02613350935280323
2019-04-26 19:29:45,345  The global step eval is 395
2019-04-26 19:29:45,466  The loss during eval_loss is  :: 0.024600856006145477
2019-04-26 19:29:45,467  The global step eval is 396
2019-04-26 19:29:45,571  The loss during eval_loss is  :: 0.057233601808547974
2019-04-26 19:29:45,573  The global step eval is 397
2019-04-26 19:29:45,691  The loss during eval_loss is  :: 0.07237622886896133
2019-04-26 19:29:45,693  The global step eval is 398
2019-04-26 19:29:45,811  The loss during eval_loss is  :: 0.0936264768242836
2019-04-26 19:29:45,813  The global step eval is 399
2019-04-26 19:29:45,935  The loss during eval_loss is  :: 0.008686447516083717
2019-04-26 19:29:45,938  The global step eval is 400
2019-04-26 19:29:46,047  The loss during eval_loss is  :: 0.10246504098176956
2019-04-26 19:29:46,049  The global step eval is 401
2019-04-26 19:29:46,152  The loss during eval_loss is  :: 0.028501946479082108
2019-04-26 19:29:46,154  The global step eval is 402
2019-04-26 19:29:46,258  The loss during eval_loss is  :: 0.08757466822862625
2019-04-26 19:29:46,260  The global step eval is 403
2019-04-26 19:29:46,375  The loss during eval_loss is  :: 0.03748205304145813
2019-04-26 19:29:46,377  The global step eval is 404
2019-04-26 19:29:46,487  The loss during eval_loss is  :: 0.028856858611106873
2019-04-26 19:29:46,488  The global step eval is 405
2019-04-26 19:29:46,595  The loss during eval_loss is  :: 0.06863979995250702
2019-04-26 19:29:46,597  The global step eval is 406
2019-04-26 19:29:46,709  The loss during eval_loss is  :: 0.05125631019473076
2019-04-26 19:29:46,711  The global step eval is 407
2019-04-26 19:29:46,825  The loss during eval_loss is  :: 0.06892986595630646
2019-04-26 19:29:46,827  The global step eval is 408
2019-04-26 19:29:46,935  The loss during eval_loss is  :: 0.0630761981010437
2019-04-26 19:29:46,937  The global step eval is 409
2019-04-26 19:29:47,055  The loss during eval_loss is  :: 0.16110444068908691
2019-04-26 19:29:47,057  The global step eval is 410
2019-04-26 19:29:47,170  The loss during eval_loss is  :: 0.034720540046691895
2019-04-26 19:29:47,172  The global step eval is 411
2019-04-26 19:29:47,279  The loss during eval_loss is  :: 0.08682098984718323
2019-04-26 19:29:47,281  The global step eval is 412
2019-04-26 19:29:47,389  The loss during eval_loss is  :: 0.10474973917007446
2019-04-26 19:29:47,391  The global step eval is 413
2019-04-26 19:29:47,499  The loss during eval_loss is  :: 0.048824239522218704
2019-04-26 19:29:47,500  The global step eval is 414
2019-04-26 19:29:47,608  The loss during eval_loss is  :: 0.04179096594452858
2019-04-26 19:29:47,610  The global step eval is 415
2019-04-26 19:29:47,715  The loss during eval_loss is  :: 0.0341947115957737
2019-04-26 19:29:47,717  The global step eval is 416
2019-04-26 19:29:47,841  The loss during eval_loss is  :: 0.055293839424848557
2019-04-26 19:29:47,843  The global step eval is 417
2019-04-26 19:29:47,952  The loss during eval_loss is  :: 0.017808087170124054
2019-04-26 19:29:47,954  The global step eval is 418
2019-04-26 19:29:48,061  The loss during eval_loss is  :: 0.04795575514435768
2019-04-26 19:29:48,063  The global step eval is 419
2019-04-26 19:29:48,179  The loss during eval_loss is  :: 0.03865045681595802
2019-04-26 19:29:48,181  The global step eval is 420
2019-04-26 19:29:48,292  The loss during eval_loss is  :: 0.05833860859274864
2019-04-26 19:29:48,294  The global step eval is 421
2019-04-26 19:29:48,403  The loss during eval_loss is  :: 0.030822452157735825
2019-04-26 19:29:48,405  The global step eval is 422
2019-04-26 19:29:48,513  The loss during eval_loss is  :: 0.05987675487995148
2019-04-26 19:29:48,515  The global step eval is 423
2019-04-26 19:29:48,626  The loss during eval_loss is  :: 0.053011927753686905
2019-04-26 19:29:48,627  The global step eval is 424
2019-04-26 19:29:48,745  The loss during eval_loss is  :: 0.07139594852924347
2019-04-26 19:29:48,747  The global step eval is 425
2019-04-26 19:29:48,852  The loss during eval_loss is  :: 0.11603350192308426
2019-04-26 19:29:48,853  The global step eval is 426
2019-04-26 19:29:48,952  The loss during eval_loss is  :: 0.07750291377305984
2019-04-26 19:29:48,954  The global step eval is 427
2019-04-26 19:29:49,058  The loss during eval_loss is  :: 0.11460665613412857
2019-04-26 19:29:49,060  The global step eval is 428
2019-04-26 19:29:49,162  The loss during eval_loss is  :: 0.06633821129798889
2019-04-26 19:29:49,164  The global step eval is 429
2019-04-26 19:29:49,283  The loss during eval_loss is  :: 0.03180001303553581
2019-04-26 19:29:49,285  The global step eval is 430
2019-04-26 19:29:49,402  The loss during eval_loss is  :: 0.020067362114787102
2019-04-26 19:29:50,186  The global step eval is 431
2019-04-26 19:29:50,282  The loss during eval_loss is  :: 0.03334272280335426
2019-04-26 19:29:50,284  The global step eval is 432
2019-04-26 19:29:50,389  The loss during eval_loss is  :: 0.09755946695804596
2019-04-26 19:29:50,390  The global step eval is 433
2019-04-26 19:29:50,499  The loss during eval_loss is  :: 0.05637645721435547
2019-04-26 19:29:50,501  The global step eval is 434
2019-04-26 19:29:50,612  The loss during eval_loss is  :: 0.10843345522880554
2019-04-26 19:29:50,614  The global step eval is 435
2019-04-26 19:29:50,738  The loss during eval_loss is  :: 0.06118537858128548
2019-04-26 19:29:50,740  The global step eval is 436
2019-04-26 19:29:50,837  The loss during eval_loss is  :: 0.08691950887441635
2019-04-26 19:29:50,838  The global step eval is 437
2019-04-26 19:29:50,943  The loss during eval_loss is  :: 0.05042693391442299
2019-04-26 19:29:50,945  The global step eval is 438
2019-04-26 19:29:51,057  The loss during eval_loss is  :: 0.13801752030849457
2019-04-26 19:29:51,058  The global step eval is 439
2019-04-26 19:29:51,164  The loss during eval_loss is  :: 0.08451846987009048
2019-04-26 19:29:51,166  The global step eval is 440
2019-04-26 19:29:51,268  The loss during eval_loss is  :: 0.03417421504855156
2019-04-26 19:29:51,270  The global step eval is 441
2019-04-26 19:29:51,367  The loss during eval_loss is  :: 0.09101855009794235
2019-04-26 19:29:51,368  The global step eval is 442
2019-04-26 19:29:51,471  The loss during eval_loss is  :: 0.11138486117124557
2019-04-26 19:29:51,473  The global step eval is 443
2019-04-26 19:29:51,585  The loss during eval_loss is  :: 0.051192667335271835
2019-04-26 19:29:51,586  The global step eval is 444
2019-04-26 19:29:51,685  The loss during eval_loss is  :: 0.04398569092154503
2019-04-26 19:29:51,686  The global step eval is 445
2019-04-26 19:29:51,784  The loss during eval_loss is  :: 0.02744595892727375
2019-04-26 19:29:51,786  The global step eval is 446
2019-04-26 19:29:51,896  The loss during eval_loss is  :: 0.04508288949728012
2019-04-26 19:29:51,898  The global step eval is 447
2019-04-26 19:29:52,022  The loss during eval_loss is  :: 0.06222149357199669
2019-04-26 19:29:52,024  The global step eval is 448
2019-04-26 19:29:52,033  Saved checkpoint: ./trained_model\step_7.pth.tar
2019-04-26 19:29:52,034  Removed checkpoint: ./trained_model\step_3.pth.tar
2019-04-26 19:29:52,128  The loss during training is  :: 0.008753248490393162 
2019-04-26 19:29:52,278  The global step train is 1793
2019-04-26 19:29:52,390  The loss during training is  :: 0.04664378613233566 
2019-04-26 19:29:52,546  The global step train is 1794
2019-04-26 19:29:52,664  The loss during training is  :: 0.07010535895824432 
2019-04-26 19:29:52,814  The global step train is 1795
2019-04-26 19:29:52,927  The loss during training is  :: 0.03305116668343544 
2019-04-26 19:29:53,084  The global step train is 1796
2019-04-26 19:29:53,207  The loss during training is  :: 0.03183659538626671 
2019-04-26 19:29:53,362  The global step train is 1797
2019-04-26 19:29:53,494  The loss during training is  :: 0.027108512818813324 
2019-04-26 19:29:53,652  The global step train is 1798
2019-04-26 19:29:53,785  The loss during training is  :: 0.011724996380507946 
2019-04-26 19:29:53,946  The global step train is 1799
2019-04-26 19:29:54,078  The loss during training is  :: 0.021984631195664406 
2019-04-26 19:29:54,250  The global step train is 1800
2019-04-26 19:29:54,386  The loss during training is  :: 0.05232229456305504 
2019-04-26 19:29:54,560  The global step train is 1801
2019-04-26 19:29:54,691  The loss during training is  :: 0.041435860097408295 
2019-04-26 19:29:54,853  The global step train is 1802
2019-04-26 19:29:54,987  The loss during training is  :: 0.0439675897359848 
2019-04-26 19:29:55,144  The global step train is 1803
2019-04-26 19:29:55,274  The loss during training is  :: 0.03343162313103676 
2019-04-26 19:29:55,434  The global step train is 1804
2019-04-26 19:29:55,566  The loss during training is  :: 0.01704748533666134 
2019-04-26 19:29:55,728  The global step train is 1805
2019-04-26 19:29:55,854  The loss during training is  :: 0.021636225283145905 
2019-04-26 19:29:56,015  The global step train is 1806
2019-04-26 19:29:56,148  The loss during training is  :: 0.009074735455214977 
2019-04-26 19:29:56,315  The global step train is 1807
2019-04-26 19:29:56,444  The loss during training is  :: 0.04498474299907684 
2019-04-26 19:29:56,602  The global step train is 1808
2019-04-26 19:29:56,736  The loss during training is  :: 0.012593485414981842 
2019-04-26 19:29:56,896  The global step train is 1809
2019-04-26 19:29:57,029  The loss during training is  :: 0.02726929634809494 
2019-04-26 19:29:57,197  The global step train is 1810
2019-04-26 19:29:57,326  The loss during training is  :: 0.031978458166122437 
2019-04-26 19:29:57,488  The global step train is 1811
2019-04-26 19:29:57,618  The loss during training is  :: 0.01607755944132805 
2019-04-26 19:29:57,781  The global step train is 1812
2019-04-26 19:29:57,912  The loss during training is  :: 0.01805807463824749 
2019-04-26 19:29:58,077  The global step train is 1813
2019-04-26 19:29:58,206  The loss during training is  :: 0.019948136061429977 
2019-04-26 19:29:58,363  The global step train is 1814
2019-04-26 19:29:58,491  The loss during training is  :: 0.04265979304909706 
2019-04-26 19:29:58,652  The global step train is 1815
2019-04-26 19:29:58,780  The loss during training is  :: 0.06500627100467682 
2019-04-26 19:29:58,944  The global step train is 1816
2019-04-26 19:29:59,073  The loss during training is  :: 0.012717962265014648 
2019-04-26 19:29:59,234  The global step train is 1817
2019-04-26 19:29:59,364  The loss during training is  :: 0.02445300668478012 
2019-04-26 19:29:59,523  The global step train is 1818
2019-04-26 19:29:59,651  The loss during training is  :: 0.01681230217218399 
2019-04-26 19:29:59,813  The global step train is 1819
2019-04-26 19:29:59,940  The loss during training is  :: 0.017339130863547325 
2019-04-26 19:30:00,110  The global step train is 1820
2019-04-26 19:30:00,235  The loss during training is  :: 0.024188505485653877 
2019-04-26 19:30:00,397  The global step train is 1821
2019-04-26 19:30:00,531  The loss during training is  :: 0.03693562373518944 
2019-04-26 19:30:00,692  The global step train is 1822
2019-04-26 19:30:00,824  The loss during training is  :: 0.0705898255109787 
2019-04-26 19:30:00,985  The global step train is 1823
2019-04-26 19:30:01,120  The loss during training is  :: 0.11953882873058319 
2019-04-26 19:30:01,282  The global step train is 1824
2019-04-26 19:30:01,409  The loss during training is  :: 0.010974496603012085 
2019-04-26 19:30:01,569  The global step train is 1825
2019-04-26 19:30:01,706  The loss during training is  :: 0.06611926853656769 
2019-04-26 19:30:01,874  The global step train is 1826
2019-04-26 19:30:02,006  The loss during training is  :: 0.06876552850008011 
2019-04-26 19:30:02,170  The global step train is 1827
2019-04-26 19:30:02,302  The loss during training is  :: 0.01625150628387928 
2019-04-26 19:30:02,469  The global step train is 1828
2019-04-26 19:30:02,598  The loss during training is  :: 0.03115398809313774 
2019-04-26 19:30:02,762  The global step train is 1829
2019-04-26 19:30:02,891  The loss during training is  :: 0.030642658472061157 
2019-04-26 19:30:03,054  The global step train is 1830
2019-04-26 19:30:03,184  The loss during training is  :: 0.014179378747940063 
2019-04-26 19:30:03,345  The global step train is 1831
2019-04-26 19:30:03,475  The loss during training is  :: 0.03130698949098587 
2019-04-26 19:30:03,646  The global step train is 1832
2019-04-26 19:30:03,773  The loss during training is  :: 0.033829960972070694 
2019-04-26 19:30:03,931  The global step train is 1833
2019-04-26 19:30:04,061  The loss during training is  :: 0.0353253111243248 
2019-04-26 19:30:04,231  The global step train is 1834
2019-04-26 19:30:04,365  The loss during training is  :: 0.007138729095458984 
2019-04-26 19:30:04,530  The global step train is 1835
2019-04-26 19:30:04,659  The loss during training is  :: 0.05024753883481026 
2019-04-26 19:30:04,829  The global step train is 1836
2019-04-26 19:30:04,957  The loss during training is  :: 0.05505041033029556 
2019-04-26 19:30:05,120  The global step train is 1837
2019-04-26 19:30:05,245  The loss during training is  :: 0.026516549289226532 
2019-04-26 19:30:05,402  The global step train is 1838
2019-04-26 19:30:05,537  The loss during training is  :: 0.03819743171334267 
2019-04-26 19:30:05,697  The global step train is 1839
2019-04-26 19:30:05,826  The loss during training is  :: 0.02403431572020054 
2019-04-26 19:30:05,985  The global step train is 1840
2019-04-26 19:30:06,114  The loss during training is  :: 0.016800502315163612 
2019-04-26 19:30:06,275  The global step train is 1841
2019-04-26 19:30:06,405  The loss during training is  :: 0.029943354427814484 
2019-04-26 19:30:06,563  The global step train is 1842
2019-04-26 19:30:06,694  The loss during training is  :: 0.013279154896736145 
2019-04-26 19:30:06,855  The global step train is 1843
2019-04-26 19:30:06,982  The loss during training is  :: 0.009170894511044025 
2019-04-26 19:30:07,143  The global step train is 1844
2019-04-26 19:30:07,272  The loss during training is  :: 0.04694262146949768 
2019-04-26 19:30:07,434  The global step train is 1845
2019-04-26 19:30:07,566  The loss during training is  :: 0.02003375068306923 
2019-04-26 19:30:07,724  The global step train is 1846
2019-04-26 19:30:07,854  The loss during training is  :: 0.038806624710559845 
2019-04-26 19:30:08,015  The global step train is 1847
2019-04-26 19:30:08,147  The loss during training is  :: 0.024163106456398964 
2019-04-26 19:30:08,311  The global step train is 1848
2019-04-26 19:30:08,441  The loss during training is  :: 0.0353071466088295 
2019-04-26 19:30:08,606  The global step train is 1849
2019-04-26 19:30:08,735  The loss during training is  :: 0.031817298382520676 
2019-04-26 19:30:08,897  The global step train is 1850
2019-04-26 19:30:09,028  The loss during training is  :: 0.03985967859625816 
2019-04-26 19:30:09,186  The global step train is 1851
2019-04-26 19:30:09,317  The loss during training is  :: 0.040190190076828 
2019-04-26 19:30:09,481  The global step train is 1852
2019-04-26 19:30:09,611  The loss during training is  :: 0.028956623747944832 
2019-04-26 19:30:09,774  The global step train is 1853
2019-04-26 19:30:09,904  The loss during training is  :: 0.05267155170440674 
2019-04-26 19:30:10,083  The global step train is 1854
2019-04-26 19:30:10,216  The loss during training is  :: 0.0814296305179596 
2019-04-26 19:30:10,377  The global step train is 1855
2019-04-26 19:30:10,504  The loss during training is  :: 0.05471983551979065 
2019-04-26 19:30:10,663  The global step train is 1856
2019-04-26 19:30:10,795  The loss during training is  :: 0.013510891236364841 
2019-04-26 19:30:10,960  The global step train is 1857
2019-04-26 19:30:11,087  The loss during training is  :: 0.026577197015285492 
2019-04-26 19:30:11,248  The global step train is 1858
2019-04-26 19:30:11,375  The loss during training is  :: 0.008474775590002537 
2019-04-26 19:30:11,537  The global step train is 1859
2019-04-26 19:30:11,668  The loss during training is  :: 0.06017468124628067 
2019-04-26 19:30:11,831  The global step train is 1860
2019-04-26 19:30:11,960  The loss during training is  :: 0.024785086512565613 
2019-04-26 19:30:12,123  The global step train is 1861
2019-04-26 19:30:12,252  The loss during training is  :: 0.016246818006038666 
2019-04-26 19:30:12,428  The global step train is 1862
2019-04-26 19:30:12,559  The loss during training is  :: 0.030356543138623238 
2019-04-26 19:30:12,723  The global step train is 1863
2019-04-26 19:30:12,854  The loss during training is  :: 0.023502448573708534 
2019-04-26 19:30:13,009  The global step train is 1864
2019-04-26 19:30:13,141  The loss during training is  :: 0.012794704176485538 
2019-04-26 19:30:13,304  The global step train is 1865
2019-04-26 19:30:13,436  The loss during training is  :: 0.03206923231482506 
2019-04-26 19:30:13,594  The global step train is 1866
2019-04-26 19:30:13,722  The loss during training is  :: 0.04058781638741493 
2019-04-26 19:30:13,887  The global step train is 1867
2019-04-26 19:30:14,018  The loss during training is  :: 0.051316484808921814 
2019-04-26 19:30:14,182  The global step train is 1868
2019-04-26 19:30:14,315  The loss during training is  :: 0.023359009996056557 
2019-04-26 19:30:14,483  The global step train is 1869
2019-04-26 19:30:14,613  The loss during training is  :: 0.05043301731348038 
2019-04-26 19:30:14,776  The global step train is 1870
2019-04-26 19:30:14,909  The loss during training is  :: 0.0262192003428936 
2019-04-26 19:30:15,065  The global step train is 1871
2019-04-26 19:30:15,192  The loss during training is  :: 0.1149866133928299 
2019-04-26 19:30:15,355  The global step train is 1872
2019-04-26 19:30:15,480  The loss during training is  :: 0.033237870782613754 
2019-04-26 19:30:15,643  The global step train is 1873
2019-04-26 19:30:15,775  The loss during training is  :: 0.02482522651553154 
2019-04-26 19:30:15,938  The global step train is 1874
2019-04-26 19:30:16,064  The loss during training is  :: 0.016508309170603752 
2019-04-26 19:30:16,226  The global step train is 1875
2019-04-26 19:30:16,360  The loss during training is  :: 0.0729694664478302 
2019-04-26 19:30:16,521  The global step train is 1876
2019-04-26 19:30:16,652  The loss during training is  :: 0.014326759614050388 
2019-04-26 19:30:16,857  The global step train is 1877
2019-04-26 19:30:16,986  The loss during training is  :: 0.08367294818162918 
2019-04-26 19:30:17,153  The global step train is 1878
2019-04-26 19:30:17,285  The loss during training is  :: 0.018380222842097282 
2019-04-26 19:30:17,441  The global step train is 1879
2019-04-26 19:30:17,572  The loss during training is  :: 0.007930361665785313 
2019-04-26 19:30:17,735  The global step train is 1880
2019-04-26 19:30:17,866  The loss during training is  :: 0.03300391510128975 
2019-04-26 19:30:18,043  The global step train is 1881
2019-04-26 19:30:18,169  The loss during training is  :: 0.020259246230125427 
2019-04-26 19:30:18,329  The global step train is 1882
2019-04-26 19:30:18,459  The loss during training is  :: 0.07250553369522095 
2019-04-26 19:30:18,620  The global step train is 1883
2019-04-26 19:30:18,752  The loss during training is  :: 0.06484545022249222 
2019-04-26 19:30:18,912  The global step train is 1884
2019-04-26 19:30:19,041  The loss during training is  :: 0.030329277738928795 
2019-04-26 19:30:19,204  The global step train is 1885
2019-04-26 19:30:19,337  The loss during training is  :: 0.02616577222943306 
2019-04-26 19:30:19,503  The global step train is 1886
2019-04-26 19:30:19,631  The loss during training is  :: 0.06883389502763748 
2019-04-26 19:30:19,790  The global step train is 1887
2019-04-26 19:30:19,923  The loss during training is  :: 0.10653677582740784 
2019-04-26 19:30:20,085  The global step train is 1888
2019-04-26 19:30:20,216  The loss during training is  :: 0.021259671077132225 
2019-04-26 19:30:20,376  The global step train is 1889
2019-04-26 19:30:20,504  The loss during training is  :: 0.011078360490500927 
2019-04-26 19:30:20,670  The global step train is 1890
2019-04-26 19:30:20,800  The loss during training is  :: 0.033081166446208954 
2019-04-26 19:30:20,950  The global step train is 1891
2019-04-26 19:30:21,084  The loss during training is  :: 0.031449094414711 
2019-04-26 19:30:21,242  The global step train is 1892
2019-04-26 19:30:21,374  The loss during training is  :: 0.030137112364172935 
2019-04-26 19:30:21,534  The global step train is 1893
2019-04-26 19:30:21,667  The loss during training is  :: 0.015462472103536129 
2019-04-26 19:30:21,833  The global step train is 1894
2019-04-26 19:30:21,963  The loss during training is  :: 0.0114885363727808 
2019-04-26 19:30:22,126  The global step train is 1895
2019-04-26 19:30:22,254  The loss during training is  :: 0.031070826575160027 
2019-04-26 19:30:22,417  The global step train is 1896
2019-04-26 19:30:22,542  The loss during training is  :: 0.030048729851841927 
2019-04-26 19:30:22,710  The global step train is 1897
2019-04-26 19:30:22,835  The loss during training is  :: 0.04569334164261818 
2019-04-26 19:30:22,998  The global step train is 1898
2019-04-26 19:30:23,132  The loss during training is  :: 0.0382077619433403 
2019-04-26 19:30:23,295  The global step train is 1899
2019-04-26 19:30:23,427  The loss during training is  :: 0.03645242005586624 
2019-04-26 19:30:23,589  The global step train is 1900
2019-04-26 19:30:23,720  The loss during training is  :: 0.01499676052480936 
2019-04-26 19:30:23,888  The global step train is 1901
2019-04-26 19:30:24,014  The loss during training is  :: 0.020907212048768997 
2019-04-26 19:30:24,174  The global step train is 1902
2019-04-26 19:30:24,305  The loss during training is  :: 0.015412422828376293 
2019-04-26 19:30:24,470  The global step train is 1903
2019-04-26 19:30:24,605  The loss during training is  :: 0.027570025995373726 
2019-04-26 19:30:24,769  The global step train is 1904
2019-04-26 19:30:24,899  The loss during training is  :: 0.03045164979994297 
2019-04-26 19:30:25,065  The global step train is 1905
2019-04-26 19:30:25,204  The loss during training is  :: 0.05068592727184296 
2019-04-26 19:30:25,370  The global step train is 1906
2019-04-26 19:30:25,497  The loss during training is  :: 0.034651584923267365 
2019-04-26 19:30:25,659  The global step train is 1907
2019-04-26 19:30:25,790  The loss during training is  :: 0.013833532109856606 
2019-04-26 19:30:25,951  The global step train is 1908
2019-04-26 19:30:26,080  The loss during training is  :: 0.03546783700585365 
2019-04-26 19:30:26,241  The global step train is 1909
2019-04-26 19:30:26,371  The loss during training is  :: 0.02452666684985161 
2019-04-26 19:30:26,539  The global step train is 1910
2019-04-26 19:30:26,669  The loss during training is  :: 0.008768917992711067 
2019-04-26 19:30:26,828  The global step train is 1911
2019-04-26 19:30:26,954  The loss during training is  :: 0.04080052301287651 
2019-04-26 19:30:27,116  The global step train is 1912
2019-04-26 19:30:27,247  The loss during training is  :: 0.012739649042487144 
2019-04-26 19:30:27,407  The global step train is 1913
2019-04-26 19:30:27,537  The loss during training is  :: 0.062002453953027725 
2019-04-26 19:30:27,700  The global step train is 1914
2019-04-26 19:30:27,826  The loss during training is  :: 0.006493504624813795 
2019-04-26 19:30:27,988  The global step train is 1915
2019-04-26 19:30:28,122  The loss during training is  :: 0.041107870638370514 
2019-04-26 19:30:28,283  The global step train is 1916
2019-04-26 19:30:28,417  The loss during training is  :: 0.08384451270103455 
2019-04-26 19:30:28,581  The global step train is 1917
2019-04-26 19:30:28,714  The loss during training is  :: 0.018601205199956894 
2019-04-26 19:30:28,877  The global step train is 1918
2019-04-26 19:30:29,011  The loss during training is  :: 0.03771718963980675 
2019-04-26 19:30:29,177  The global step train is 1919
2019-04-26 19:30:29,311  The loss during training is  :: 0.06453672051429749 
2019-04-26 19:30:29,473  The global step train is 1920
2019-04-26 19:30:29,607  The loss during training is  :: 0.01868966780602932 
2019-04-26 19:30:29,770  The global step train is 1921
2019-04-26 19:30:29,900  The loss during training is  :: 0.047215018421411514 
2019-04-26 19:30:30,061  The global step train is 1922
2019-04-26 19:30:30,186  The loss during training is  :: 0.06923945248126984 
2019-04-26 19:30:30,348  The global step train is 1923
2019-04-26 19:30:30,470  The loss during training is  :: 0.061863530427217484 
2019-04-26 19:30:30,636  The global step train is 1924
2019-04-26 19:30:30,763  The loss during training is  :: 0.04044222831726074 
2019-04-26 19:30:30,921  The global step train is 1925
2019-04-26 19:30:31,056  The loss during training is  :: 0.05770162120461464 
2019-04-26 19:30:31,224  The global step train is 1926
2019-04-26 19:30:31,357  The loss during training is  :: 0.03848278522491455 
2019-04-26 19:30:31,524  The global step train is 1927
2019-04-26 19:30:31,649  The loss during training is  :: 0.02328440360724926 
2019-04-26 19:30:31,809  The global step train is 1928
2019-04-26 19:30:31,940  The loss during training is  :: 0.0275117177516222 
2019-04-26 19:30:32,105  The global step train is 1929
2019-04-26 19:30:32,236  The loss during training is  :: 0.02691122703254223 
2019-04-26 19:30:32,398  The global step train is 1930
2019-04-26 19:30:32,530  The loss during training is  :: 0.014608443714678288 
2019-04-26 19:30:32,689  The global step train is 1931
2019-04-26 19:30:32,818  The loss during training is  :: 0.051920220255851746 
2019-04-26 19:30:32,989  The global step train is 1932
2019-04-26 19:30:33,120  The loss during training is  :: 0.017603887245059013 
2019-04-26 19:30:33,285  The global step train is 1933
2019-04-26 19:30:33,419  The loss during training is  :: 0.027212129905819893 
2019-04-26 19:30:33,578  The global step train is 1934
2019-04-26 19:30:33,711  The loss during training is  :: 0.026093702763319016 
2019-04-26 19:30:33,872  The global step train is 1935
2019-04-26 19:30:34,002  The loss during training is  :: 0.04760468751192093 
2019-04-26 19:30:34,166  The global step train is 1936
2019-04-26 19:30:34,293  The loss during training is  :: 0.03319014981389046 
2019-04-26 19:30:34,456  The global step train is 1937
2019-04-26 19:30:34,582  The loss during training is  :: 0.09186270087957382 
2019-04-26 19:30:34,746  The global step train is 1938
2019-04-26 19:30:34,879  The loss during training is  :: 0.08854196220636368 
2019-04-26 19:30:35,055  The global step train is 1939
2019-04-26 19:30:35,201  The loss during training is  :: 0.027200356125831604 
2019-04-26 19:30:35,376  The global step train is 1940
2019-04-26 19:30:35,513  The loss during training is  :: 0.013051341287791729 
2019-04-26 19:30:35,673  The global step train is 1941
2019-04-26 19:30:35,807  The loss during training is  :: 0.03567273169755936 
2019-04-26 19:30:35,972  The global step train is 1942
2019-04-26 19:30:36,099  The loss during training is  :: 0.025986645370721817 
2019-04-26 19:30:36,267  The global step train is 1943
2019-04-26 19:30:36,397  The loss during training is  :: 0.03523203358054161 
2019-04-26 19:30:36,555  The global step train is 1944
2019-04-26 19:30:36,685  The loss during training is  :: 0.0735902190208435 
2019-04-26 19:30:36,846  The global step train is 1945
2019-04-26 19:30:36,975  The loss during training is  :: 0.012574599124491215 
2019-04-26 19:30:37,145  The global step train is 1946
2019-04-26 19:30:37,275  The loss during training is  :: 0.01743128150701523 
2019-04-26 19:30:37,440  The global step train is 1947
2019-04-26 19:30:37,567  The loss during training is  :: 0.039780233055353165 
2019-04-26 19:30:37,734  The global step train is 1948
2019-04-26 19:30:37,858  The loss during training is  :: 0.024462947621941566 
2019-04-26 19:30:38,021  The global step train is 1949
2019-04-26 19:30:38,155  The loss during training is  :: 0.05983546003699303 
2019-04-26 19:30:38,317  The global step train is 1950
2019-04-26 19:30:38,450  The loss during training is  :: 0.03699362277984619 
2019-04-26 19:30:38,612  The global step train is 1951
2019-04-26 19:30:38,742  The loss during training is  :: 0.08006896823644638 
2019-04-26 19:30:38,905  The global step train is 1952
2019-04-26 19:30:39,034  The loss during training is  :: 0.02514088898897171 
2019-04-26 19:30:39,196  The global step train is 1953
2019-04-26 19:30:39,330  The loss during training is  :: 0.022961918264627457 
2019-04-26 19:30:39,489  The global step train is 1954
2019-04-26 19:30:39,622  The loss during training is  :: 0.03636794909834862 
2019-04-26 19:30:39,784  The global step train is 1955
2019-04-26 19:30:39,914  The loss during training is  :: 0.04141680896282196 
2019-04-26 19:30:40,076  The global step train is 1956
2019-04-26 19:30:40,209  The loss during training is  :: 0.017759278416633606 
2019-04-26 19:30:40,371  The global step train is 1957
2019-04-26 19:30:40,503  The loss during training is  :: 0.04265948012471199 
2019-04-26 19:30:40,664  The global step train is 1958
2019-04-26 19:30:40,786  The loss during training is  :: 0.0466780811548233 
2019-04-26 19:30:40,951  The global step train is 1959
2019-04-26 19:30:41,079  The loss during training is  :: 0.04454301670193672 
2019-04-26 19:30:41,245  The global step train is 1960
2019-04-26 19:30:41,373  The loss during training is  :: 0.08469151705503464 
2019-04-26 19:30:41,536  The global step train is 1961
2019-04-26 19:30:41,663  The loss during training is  :: 0.019734583795070648 
2019-04-26 19:30:41,821  The global step train is 1962
2019-04-26 19:30:41,948  The loss during training is  :: 0.01924051344394684 
2019-04-26 19:30:42,110  The global step train is 1963
2019-04-26 19:30:42,242  The loss during training is  :: 0.015581795014441013 
2019-04-26 19:30:42,401  The global step train is 1964
2019-04-26 19:30:42,526  The loss during training is  :: 0.09060382843017578 
2019-04-26 19:30:42,695  The global step train is 1965
2019-04-26 19:30:42,828  The loss during training is  :: 0.07294214516878128 
2019-04-26 19:30:42,989  The global step train is 1966
2019-04-26 19:30:43,115  The loss during training is  :: 0.014698156155645847 
2019-04-26 19:30:43,276  The global step train is 1967
2019-04-26 19:30:43,408  The loss during training is  :: 0.12468823790550232 
2019-04-26 19:30:43,573  The global step train is 1968
2019-04-26 19:30:43,704  The loss during training is  :: 0.03329893574118614 
2019-04-26 19:30:43,863  The global step train is 1969
2019-04-26 19:30:43,993  The loss during training is  :: 0.008653233759105206 
2019-04-26 19:30:44,158  The global step train is 1970
2019-04-26 19:30:44,288  The loss during training is  :: 0.011538867838680744 
2019-04-26 19:30:44,448  The global step train is 1971
2019-04-26 19:30:44,575  The loss during training is  :: 0.03634735941886902 
2019-04-26 19:30:44,735  The global step train is 1972
2019-04-26 19:30:44,866  The loss during training is  :: 0.016481272876262665 
2019-04-26 19:30:45,048  The global step train is 1973
2019-04-26 19:30:45,177  The loss during training is  :: 0.015649382025003433 
2019-04-26 19:30:45,339  The global step train is 1974
2019-04-26 19:30:45,472  The loss during training is  :: 0.012767483480274677 
2019-04-26 19:30:45,642  The global step train is 1975
2019-04-26 19:30:45,767  The loss during training is  :: 0.028458992019295692 
2019-04-26 19:30:45,928  The global step train is 1976
2019-04-26 19:30:46,054  The loss during training is  :: 0.02836586907505989 
2019-04-26 19:30:46,215  The global step train is 1977
2019-04-26 19:30:46,341  The loss during training is  :: 0.034220971167087555 
2019-04-26 19:30:46,507  The global step train is 1978
2019-04-26 19:30:46,633  The loss during training is  :: 0.032986681908369064 
2019-04-26 19:30:46,794  The global step train is 1979
2019-04-26 19:30:46,924  The loss during training is  :: 0.0652996376156807 
2019-04-26 19:30:47,085  The global step train is 1980
2019-04-26 19:30:47,217  The loss during training is  :: 0.02377896010875702 
2019-04-26 19:30:47,380  The global step train is 1981
2019-04-26 19:30:47,506  The loss during training is  :: 0.02193945273756981 
2019-04-26 19:30:47,674  The global step train is 1982
2019-04-26 19:30:47,808  The loss during training is  :: 0.013388287276029587 
2019-04-26 19:30:47,970  The global step train is 1983
2019-04-26 19:30:48,097  The loss during training is  :: 0.01572059653699398 
2019-04-26 19:30:48,259  The global step train is 1984
2019-04-26 19:30:48,389  The loss during training is  :: 0.029825381934642792 
2019-04-26 19:30:48,553  The global step train is 1985
2019-04-26 19:30:48,681  The loss during training is  :: 0.024450134485960007 
2019-04-26 19:30:48,839  The global step train is 1986
2019-04-26 19:30:48,969  The loss during training is  :: 0.0215042345225811 
2019-04-26 19:30:49,129  The global step train is 1987
2019-04-26 19:30:49,255  The loss during training is  :: 0.010595785453915596 
2019-04-26 19:30:49,412  The global step train is 1988
2019-04-26 19:30:49,540  The loss during training is  :: 0.02722516469657421 
2019-04-26 19:30:49,704  The global step train is 1989
2019-04-26 19:30:49,832  The loss during training is  :: 0.013424981385469437 
2019-04-26 19:30:49,994  The global step train is 1990
2019-04-26 19:30:50,127  The loss during training is  :: 0.02356216497719288 
2019-04-26 19:30:50,287  The global step train is 1991
2019-04-26 19:30:50,420  The loss during training is  :: 0.020295849069952965 
2019-04-26 19:30:50,584  The global step train is 1992
2019-04-26 19:30:50,707  The loss during training is  :: 0.020394721999764442 
2019-04-26 19:30:50,867  The global step train is 1993
2019-04-26 19:30:50,998  The loss during training is  :: 0.026392046362161636 
2019-04-26 19:30:51,163  The global step train is 1994
2019-04-26 19:30:51,292  The loss during training is  :: 0.05213557928800583 
2019-04-26 19:30:51,453  The global step train is 1995
2019-04-26 19:30:51,584  The loss during training is  :: 0.01857019029557705 
2019-04-26 19:30:51,747  The global step train is 1996
2019-04-26 19:30:51,875  The loss during training is  :: 0.006222330499440432 
2019-04-26 19:30:52,041  The global step train is 1997
2019-04-26 19:30:52,165  The loss during training is  :: 0.018367154523730278 
2019-04-26 19:30:52,327  The global step train is 1998
2019-04-26 19:30:52,453  The loss during training is  :: 0.04481872171163559 
2019-04-26 19:30:52,618  The global step train is 1999
2019-04-26 19:30:52,747  The loss during training is  :: 0.020878251641988754 
2019-04-26 19:30:52,910  The global step train is 2000
2019-04-26 19:30:53,042  The loss during training is  :: 0.020146135240793228 
2019-04-26 19:30:53,212  The global step train is 2001
2019-04-26 19:30:53,341  The loss during training is  :: 0.09684321284294128 
2019-04-26 19:30:53,506  The global step train is 2002
2019-04-26 19:30:53,634  The loss during training is  :: 0.03240850940346718 
2019-04-26 19:30:53,791  The global step train is 2003
2019-04-26 19:30:53,923  The loss during training is  :: 0.041188281029462814 
2019-04-26 19:30:54,090  The global step train is 2004
2019-04-26 19:30:54,219  The loss during training is  :: 0.036228835582733154 
2019-04-26 19:30:54,384  The global step train is 2005
2019-04-26 19:30:54,508  The loss during training is  :: 0.07970455288887024 
2019-04-26 19:30:54,674  The global step train is 2006
2019-04-26 19:30:54,803  The loss during training is  :: 0.035935673862695694 
2019-04-26 19:30:54,960  The global step train is 2007
2019-04-26 19:30:55,090  The loss during training is  :: 0.024351701140403748 
2019-04-26 19:30:55,259  The global step train is 2008
2019-04-26 19:30:55,394  The loss during training is  :: 0.04305998980998993 
2019-04-26 19:30:55,553  The global step train is 2009
2019-04-26 19:30:55,684  The loss during training is  :: 0.02414078637957573 
2019-04-26 19:30:55,845  The global step train is 2010
2019-04-26 19:30:55,971  The loss during training is  :: 0.014611396938562393 
2019-04-26 19:30:56,143  The global step train is 2011
2019-04-26 19:30:56,272  The loss during training is  :: 0.029652243480086327 
2019-04-26 19:30:56,437  The global step train is 2012
2019-04-26 19:30:56,564  The loss during training is  :: 0.05367748439311981 
2019-04-26 19:30:56,718  The global step train is 2013
2019-04-26 19:30:56,846  The loss during training is  :: 0.06435279548168182 
2019-04-26 19:30:57,000  The global step train is 2014
2019-04-26 19:30:57,131  The loss during training is  :: 0.014399254694581032 
2019-04-26 19:30:57,291  The global step train is 2015
2019-04-26 19:30:57,419  The loss during training is  :: 0.03696488216519356 
2019-04-26 19:30:57,583  The global step train is 2016
2019-04-26 19:30:57,585  Starting evaluation 
2019-04-26 19:30:57,722  The loss during eval_loss is  :: 0.05587612837553024
2019-04-26 19:30:57,724  The global step eval is 449
2019-04-26 19:30:57,849  The loss during eval_loss is  :: 0.03908997029066086
2019-04-26 19:30:57,851  The global step eval is 450
2019-04-26 19:30:57,982  The loss during eval_loss is  :: 0.020455993711948395
2019-04-26 19:30:57,984  The global step eval is 451
2019-04-26 19:30:58,095  The loss during eval_loss is  :: 0.022623319178819656
2019-04-26 19:30:58,096  The global step eval is 452
2019-04-26 19:30:58,205  The loss during eval_loss is  :: 0.05329852178692818
2019-04-26 19:30:58,207  The global step eval is 453
2019-04-26 19:30:58,329  The loss during eval_loss is  :: 0.07605182379484177
2019-04-26 19:30:58,330  The global step eval is 454
2019-04-26 19:30:58,448  The loss during eval_loss is  :: 0.08097758889198303
2019-04-26 19:30:58,450  The global step eval is 455
2019-04-26 19:30:58,564  The loss during eval_loss is  :: 0.004531866870820522
2019-04-26 19:30:58,566  The global step eval is 456
2019-04-26 19:30:58,677  The loss during eval_loss is  :: 0.08015096187591553
2019-04-26 19:30:58,679  The global step eval is 457
2019-04-26 19:30:58,782  The loss during eval_loss is  :: 0.02263392135500908
2019-04-26 19:30:58,784  The global step eval is 458
2019-04-26 19:30:58,893  The loss during eval_loss is  :: 0.10047787427902222
2019-04-26 19:30:58,894  The global step eval is 459
2019-04-26 19:30:59,009  The loss during eval_loss is  :: 0.03601795807480812
2019-04-26 19:30:59,011  The global step eval is 460
2019-04-26 19:30:59,115  The loss during eval_loss is  :: 0.027112336829304695
2019-04-26 19:30:59,116  The global step eval is 461
2019-04-26 19:30:59,228  The loss during eval_loss is  :: 0.053378764539957047
2019-04-26 19:30:59,229  The global step eval is 462
2019-04-26 19:30:59,345  The loss during eval_loss is  :: 0.0384896844625473
2019-04-26 19:30:59,347  The global step eval is 463
2019-04-26 19:30:59,451  The loss during eval_loss is  :: 0.07707679271697998
2019-04-26 19:30:59,452  The global step eval is 464
2019-04-26 19:30:59,562  The loss during eval_loss is  :: 0.07386846840381622
2019-04-26 19:30:59,564  The global step eval is 465
2019-04-26 19:30:59,674  The loss during eval_loss is  :: 0.13633835315704346
2019-04-26 19:30:59,675  The global step eval is 466
2019-04-26 19:30:59,788  The loss during eval_loss is  :: 0.04160165786743164
2019-04-26 19:30:59,790  The global step eval is 467
2019-04-26 19:30:59,903  The loss during eval_loss is  :: 0.06753882765769958
2019-04-26 19:30:59,906  The global step eval is 468
2019-04-26 19:31:00,018  The loss during eval_loss is  :: 0.0816897600889206
2019-04-26 19:31:00,019  The global step eval is 469
2019-04-26 19:31:00,123  The loss during eval_loss is  :: 0.05489252880215645
2019-04-26 19:31:00,125  The global step eval is 470
2019-04-26 19:31:00,243  The loss during eval_loss is  :: 0.044118545949459076
2019-04-26 19:31:00,245  The global step eval is 471
2019-04-26 19:31:00,352  The loss during eval_loss is  :: 0.039174702018499374
2019-04-26 19:31:00,354  The global step eval is 472
2019-04-26 19:31:00,460  The loss during eval_loss is  :: 0.02589770406484604
2019-04-26 19:31:00,461  The global step eval is 473
2019-04-26 19:31:00,565  The loss during eval_loss is  :: 0.013344488106667995
2019-04-26 19:31:00,567  The global step eval is 474
2019-04-26 19:31:00,675  The loss during eval_loss is  :: 0.057861778885126114
2019-04-26 19:31:00,677  The global step eval is 475
2019-04-26 19:31:00,796  The loss during eval_loss is  :: 0.055156853049993515
2019-04-26 19:31:00,798  The global step eval is 476
2019-04-26 19:31:00,902  The loss during eval_loss is  :: 0.06102736294269562
2019-04-26 19:31:00,904  The global step eval is 477
2019-04-26 19:31:01,019  The loss during eval_loss is  :: 0.03055248223245144
2019-04-26 19:31:01,021  The global step eval is 478
2019-04-26 19:31:01,135  The loss during eval_loss is  :: 0.0338422916829586
2019-04-26 19:31:01,137  The global step eval is 479
2019-04-26 19:31:01,258  The loss during eval_loss is  :: 0.06819470971822739
2019-04-26 19:31:01,260  The global step eval is 480
2019-04-26 19:31:01,365  The loss during eval_loss is  :: 0.06273861229419708
2019-04-26 19:31:01,367  The global step eval is 481
2019-04-26 19:31:01,473  The loss during eval_loss is  :: 0.12926287949085236
2019-04-26 19:31:01,475  The global step eval is 482
2019-04-26 19:31:01,594  The loss during eval_loss is  :: 0.04615717753767967
2019-04-26 19:31:01,596  The global step eval is 483
2019-04-26 19:31:01,706  The loss during eval_loss is  :: 0.10628724098205566
2019-04-26 19:31:01,708  The global step eval is 484
2019-04-26 19:31:01,810  The loss during eval_loss is  :: 0.07821834087371826
2019-04-26 19:31:01,812  The global step eval is 485
2019-04-26 19:31:01,925  The loss during eval_loss is  :: 0.05681527405977249
2019-04-26 19:31:01,927  The global step eval is 486
2019-04-26 19:31:02,029  The loss during eval_loss is  :: 0.013295230455696583
2019-04-26 19:31:02,031  The global step eval is 487
2019-04-26 19:31:02,138  The loss during eval_loss is  :: 0.012194531969726086
2019-04-26 19:31:02,140  The global step eval is 488
2019-04-26 19:31:02,244  The loss during eval_loss is  :: 0.029929565265774727
2019-04-26 19:31:02,246  The global step eval is 489
2019-04-26 19:31:02,363  The loss during eval_loss is  :: 0.03704911097884178
2019-04-26 19:31:02,365  The global step eval is 490
2019-04-26 19:31:02,475  The loss during eval_loss is  :: 0.07203984260559082
2019-04-26 19:31:02,477  The global step eval is 491
2019-04-26 19:31:02,593  The loss during eval_loss is  :: 0.041147321462631226
2019-04-26 19:31:02,595  The global step eval is 492
2019-04-26 19:31:02,708  The loss during eval_loss is  :: 0.13212865591049194
2019-04-26 19:31:02,710  The global step eval is 493
2019-04-26 19:31:02,823  The loss during eval_loss is  :: 0.05863543972373009
2019-04-26 19:31:02,825  The global step eval is 494
2019-04-26 19:31:02,936  The loss during eval_loss is  :: 0.09992150962352753
2019-04-26 19:31:02,938  The global step eval is 495
2019-04-26 19:31:03,049  The loss during eval_loss is  :: 0.09341388195753098
2019-04-26 19:31:03,050  The global step eval is 496
2019-04-26 19:31:03,160  The loss during eval_loss is  :: 0.01569189317524433
2019-04-26 19:31:03,162  The global step eval is 497
2019-04-26 19:31:03,279  The loss during eval_loss is  :: 0.08485177904367447
2019-04-26 19:31:03,281  The global step eval is 498
2019-04-26 19:31:03,397  The loss during eval_loss is  :: 0.0884811282157898
2019-04-26 19:31:03,398  The global step eval is 499
2019-04-26 19:31:03,518  The loss during eval_loss is  :: 0.0359199233353138
2019-04-26 19:31:03,520  The global step eval is 500
2019-04-26 19:31:03,632  The loss during eval_loss is  :: 0.03459164500236511
2019-04-26 19:31:03,634  The global step eval is 501
2019-04-26 19:31:03,746  The loss during eval_loss is  :: 0.01564093865454197
2019-04-26 19:31:03,762  The global step eval is 502
2019-04-26 19:31:03,874  The loss during eval_loss is  :: 0.04988672584295273
2019-04-26 19:31:03,875  The global step eval is 503
2019-04-26 19:31:03,994  The loss during eval_loss is  :: 0.052460961043834686
2019-04-26 19:31:03,996  The global step eval is 504
2019-04-26 19:31:04,011  Saved checkpoint: ./trained_model\step_8.pth.tar
2019-04-26 19:31:04,012  Removed checkpoint: ./trained_model\step_4.pth.tar
2019-04-26 19:31:04,122  The loss during training is  :: 0.019608741626143456 
2019-04-26 19:31:04,280  The global step train is 2017
2019-04-26 19:31:04,411  The loss during training is  :: 0.034657590091228485 
2019-04-26 19:31:04,573  The global step train is 2018
2019-04-26 19:31:04,705  The loss during training is  :: 0.024106984958052635 
2019-04-26 19:31:04,868  The global step train is 2019
2019-04-26 19:31:05,001  The loss during training is  :: 0.015977144241333008 
2019-04-26 19:31:05,168  The global step train is 2020
2019-04-26 19:31:05,301  The loss during training is  :: 0.03513162210583687 
2019-04-26 19:31:05,463  The global step train is 2021
2019-04-26 19:31:05,587  The loss during training is  :: 0.032379746437072754 
2019-04-26 19:31:05,750  The global step train is 2022
2019-04-26 19:31:05,881  The loss during training is  :: 0.039279088377952576 
2019-04-26 19:31:06,045  The global step train is 2023
2019-04-26 19:31:06,173  The loss during training is  :: 0.02690049447119236 
2019-04-26 19:31:06,336  The global step train is 2024
2019-04-26 19:31:06,469  The loss during training is  :: 0.025246746838092804 
2019-04-26 19:31:06,635  The global step train is 2025
2019-04-26 19:31:06,763  The loss during training is  :: 0.010799513198435307 
2019-04-26 19:31:06,923  The global step train is 2026
2019-04-26 19:31:07,047  The loss during training is  :: 0.05342361330986023 
2019-04-26 19:31:07,226  The global step train is 2027
2019-04-26 19:31:07,357  The loss during training is  :: 0.012946103699505329 
2019-04-26 19:31:07,521  The global step train is 2028
2019-04-26 19:31:07,646  The loss during training is  :: 0.03662697225809097 
2019-04-26 19:31:07,809  The global step train is 2029
2019-04-26 19:31:07,943  The loss during training is  :: 0.007515557575970888 
2019-04-26 19:31:08,104  The global step train is 2030
2019-04-26 19:31:08,237  The loss during training is  :: 0.041972629725933075 
2019-04-26 19:31:08,402  The global step train is 2031
2019-04-26 19:31:08,533  The loss during training is  :: 0.02872180938720703 
2019-04-26 19:31:08,696  The global step train is 2032
2019-04-26 19:31:08,831  The loss during training is  :: 0.03723720833659172 
2019-04-26 19:31:08,989  The global step train is 2033
2019-04-26 19:31:09,120  The loss during training is  :: 0.034074243158102036 
2019-04-26 19:31:09,283  The global step train is 2034
2019-04-26 19:31:09,414  The loss during training is  :: 0.045573387295007706 
2019-04-26 19:31:09,579  The global step train is 2035
2019-04-26 19:31:09,711  The loss during training is  :: 0.01506513636559248 
2019-04-26 19:31:09,877  The global step train is 2036
2019-04-26 19:31:10,007  The loss during training is  :: 0.061279259622097015 
2019-04-26 19:31:10,167  The global step train is 2037
2019-04-26 19:31:10,296  The loss during training is  :: 0.0803278312087059 
2019-04-26 19:31:10,459  The global step train is 2038
2019-04-26 19:31:10,588  The loss during training is  :: 0.018095629289746284 
2019-04-26 19:31:10,753  The global step train is 2039
2019-04-26 19:31:10,881  The loss during training is  :: 0.02179710753262043 
2019-04-26 19:31:11,044  The global step train is 2040
2019-04-26 19:31:11,169  The loss during training is  :: 0.020119909197092056 
2019-04-26 19:31:11,338  The global step train is 2041
2019-04-26 19:31:11,465  The loss during training is  :: 0.038527924567461014 
2019-04-26 19:31:11,628  The global step train is 2042
2019-04-26 19:31:11,759  The loss during training is  :: 0.14919468760490417 
2019-04-26 19:31:11,925  The global step train is 2043
2019-04-26 19:31:12,058  The loss during training is  :: 0.04153215140104294 
2019-04-26 19:31:12,220  The global step train is 2044
2019-04-26 19:31:12,350  The loss during training is  :: 0.040267568081617355 
2019-04-26 19:31:12,514  The global step train is 2045
2019-04-26 19:31:12,644  The loss during training is  :: 0.010984792374074459 
2019-04-26 19:31:12,808  The global step train is 2046
2019-04-26 19:31:12,937  The loss during training is  :: 0.060757115483284 
2019-04-26 19:31:13,102  The global step train is 2047
2019-04-26 19:31:13,232  The loss during training is  :: 0.03130517154932022 
2019-04-26 19:31:13,391  The global step train is 2048
2019-04-26 19:31:13,521  The loss during training is  :: 0.013917979784309864 
2019-04-26 19:31:13,684  The global step train is 2049
2019-04-26 19:31:13,816  The loss during training is  :: 0.02978438325226307 
2019-04-26 19:31:13,980  The global step train is 2050
2019-04-26 19:31:14,114  The loss during training is  :: 0.04977857321500778 
2019-04-26 19:31:14,282  The global step train is 2051
2019-04-26 19:31:14,410  The loss during training is  :: 0.07479646801948547 
2019-04-26 19:31:14,573  The global step train is 2052
2019-04-26 19:31:14,697  The loss during training is  :: 0.024545764550566673 
2019-04-26 19:31:14,859  The global step train is 2053
2019-04-26 19:31:14,990  The loss during training is  :: 0.011898699216544628 
2019-04-26 19:31:15,153  The global step train is 2054
2019-04-26 19:31:15,284  The loss during training is  :: 0.02244590036571026 
2019-04-26 19:31:15,452  The global step train is 2055
2019-04-26 19:31:15,584  The loss during training is  :: 0.015912918373942375 
2019-04-26 19:31:15,745  The global step train is 2056
2019-04-26 19:31:15,875  The loss during training is  :: 0.02464977651834488 
2019-04-26 19:31:16,037  The global step train is 2057
2019-04-26 19:31:16,169  The loss during training is  :: 0.07634679973125458 
2019-04-26 19:31:16,330  The global step train is 2058
2019-04-26 19:31:16,457  The loss during training is  :: 0.019628314301371574 
2019-04-26 19:31:16,625  The global step train is 2059
2019-04-26 19:31:16,759  The loss during training is  :: 0.045579422265291214 
2019-04-26 19:31:16,921  The global step train is 2060
2019-04-26 19:31:17,048  The loss during training is  :: 0.009218978695571423 
2019-04-26 19:31:17,215  The global step train is 2061
2019-04-26 19:31:17,346  The loss during training is  :: 0.010149043053388596 
2019-04-26 19:31:17,510  The global step train is 2062
2019-04-26 19:31:17,642  The loss during training is  :: 0.01005943026393652 
2019-04-26 19:31:17,804  The global step train is 2063
2019-04-26 19:31:17,934  The loss during training is  :: 0.017220349982380867 
2019-04-26 19:31:18,096  The global step train is 2064
2019-04-26 19:31:18,223  The loss during training is  :: 0.01989271119236946 
2019-04-26 19:31:18,384  The global step train is 2065
2019-04-26 19:31:18,510  The loss during training is  :: 0.032665129750967026 
2019-04-26 19:31:18,675  The global step train is 2066
2019-04-26 19:31:18,806  The loss during training is  :: 0.033475566655397415 
2019-04-26 19:31:18,971  The global step train is 2067
2019-04-26 19:31:19,108  The loss during training is  :: 0.05193673074245453 
2019-04-26 19:31:19,275  The global step train is 2068
2019-04-26 19:31:19,403  The loss during training is  :: 0.015086469240486622 
2019-04-26 19:31:19,563  The global step train is 2069
2019-04-26 19:31:19,694  The loss during training is  :: 0.023232923820614815 
2019-04-26 19:31:19,857  The global step train is 2070
2019-04-26 19:31:19,984  The loss during training is  :: 0.05078418552875519 
2019-04-26 19:31:20,145  The global step train is 2071
2019-04-26 19:31:20,272  The loss during training is  :: 0.035926543176174164 
2019-04-26 19:31:20,443  The global step train is 2072
2019-04-26 19:31:20,569  The loss during training is  :: 0.018786994740366936 
2019-04-26 19:31:20,728  The global step train is 2073
2019-04-26 19:31:20,858  The loss during training is  :: 0.029662933200597763 
2019-04-26 19:31:21,012  The global step train is 2074
2019-04-26 19:31:21,142  The loss during training is  :: 0.03941987827420235 
2019-04-26 19:31:21,304  The global step train is 2075
2019-04-26 19:31:21,436  The loss during training is  :: 0.0064363256096839905 
2019-04-26 19:31:21,599  The global step train is 2076
2019-04-26 19:31:21,733  The loss during training is  :: 0.07414554804563522 
2019-04-26 19:31:21,898  The global step train is 2077
2019-04-26 19:31:22,026  The loss during training is  :: 0.014369744807481766 
2019-04-26 19:31:22,186  The global step train is 2078
2019-04-26 19:31:22,315  The loss during training is  :: 0.052830133587121964 
2019-04-26 19:31:22,479  The global step train is 2079
2019-04-26 19:31:22,605  The loss during training is  :: 0.02995120920240879 
2019-04-26 19:31:22,764  The global step train is 2080
2019-04-26 19:31:22,893  The loss during training is  :: 0.02870730124413967 
2019-04-26 19:31:23,059  The global step train is 2081
2019-04-26 19:31:23,183  The loss during training is  :: 0.006678539793938398 
2019-04-26 19:31:23,346  The global step train is 2082
2019-04-26 19:31:23,477  The loss during training is  :: 0.018633482977747917 
2019-04-26 19:31:23,634  The global step train is 2083
2019-04-26 19:31:23,764  The loss during training is  :: 0.031191429123282433 
2019-04-26 19:31:23,927  The global step train is 2084
2019-04-26 19:31:24,057  The loss during training is  :: 0.019329939037561417 
2019-04-26 19:31:24,226  The global step train is 2085
2019-04-26 19:31:24,360  The loss during training is  :: 0.014831374399363995 
2019-04-26 19:31:24,533  The global step train is 2086
2019-04-26 19:31:24,665  The loss during training is  :: 0.04728556424379349 
2019-04-26 19:31:24,827  The global step train is 2087
2019-04-26 19:31:24,960  The loss during training is  :: 0.043217260390520096 
2019-04-26 19:31:25,121  The global step train is 2088
2019-04-26 19:31:25,261  The loss during training is  :: 0.04151425138115883 
2019-04-26 19:31:25,453  The global step train is 2089
2019-04-26 19:31:25,580  The loss during training is  :: 0.028643744066357613 
2019-04-26 19:31:25,745  The global step train is 2090
2019-04-26 19:31:25,875  The loss during training is  :: 0.029950469732284546 
2019-04-26 19:31:26,036  The global step train is 2091
2019-04-26 19:31:26,159  The loss during training is  :: 0.03488088771700859 
2019-04-26 19:31:26,323  The global step train is 2092
2019-04-26 19:31:26,443  The loss during training is  :: 0.020349740982055664 
2019-04-26 19:31:26,604  The global step train is 2093
2019-04-26 19:31:26,736  The loss during training is  :: 0.07468770444393158 
2019-04-26 19:31:26,898  The global step train is 2094
2019-04-26 19:31:27,027  The loss during training is  :: 0.02009272575378418 
2019-04-26 19:31:27,189  The global step train is 2095
2019-04-26 19:31:27,316  The loss during training is  :: 0.019481830298900604 
2019-04-26 19:31:27,485  The global step train is 2096
2019-04-26 19:31:27,614  The loss during training is  :: 0.02065679244697094 
2019-04-26 19:31:27,781  The global step train is 2097
2019-04-26 19:31:27,909  The loss during training is  :: 0.014131412841379642 
2019-04-26 19:31:28,073  The global step train is 2098
2019-04-26 19:31:28,204  The loss during training is  :: 0.019962670281529427 
2019-04-26 19:31:28,363  The global step train is 2099
2019-04-26 19:31:28,494  The loss during training is  :: 0.03937937691807747 
2019-04-26 19:31:28,660  The global step train is 2100
2019-04-26 19:31:28,792  The loss during training is  :: 0.027235297486186028 
2019-04-26 19:31:28,950  The global step train is 2101
2019-04-26 19:31:29,080  The loss during training is  :: 0.046103451400995255 
2019-04-26 19:31:29,242  The global step train is 2102
2019-04-26 19:31:29,375  The loss during training is  :: 0.020843645557761192 
2019-04-26 19:31:29,535  The global step train is 2103
2019-04-26 19:31:29,663  The loss during training is  :: 0.0112692229449749 
2019-04-26 19:31:29,827  The global step train is 2104
2019-04-26 19:31:29,953  The loss during training is  :: 0.008593282662332058 
2019-04-26 19:31:30,118  The global step train is 2105
2019-04-26 19:31:30,247  The loss during training is  :: 0.03222121670842171 
2019-04-26 19:31:30,408  The global step train is 2106
2019-04-26 19:31:30,540  The loss during training is  :: 0.029515784233808517 
2019-04-26 19:31:30,702  The global step train is 2107
2019-04-26 19:31:30,829  The loss during training is  :: 0.020406370982527733 
2019-04-26 19:31:30,985  The global step train is 2108
2019-04-26 19:31:31,121  The loss during training is  :: 0.01839870773255825 
2019-04-26 19:31:31,283  The global step train is 2109
2019-04-26 19:31:31,414  The loss during training is  :: 0.04980597645044327 
2019-04-26 19:31:31,576  The global step train is 2110
2019-04-26 19:31:31,707  The loss during training is  :: 0.011235536076128483 
2019-04-26 19:31:31,866  The global step train is 2111
2019-04-26 19:31:31,994  The loss during training is  :: 0.0040043797343969345 
2019-04-26 19:31:32,152  The global step train is 2112
2019-04-26 19:31:32,280  The loss during training is  :: 0.04071909561753273 
2019-04-26 19:31:32,442  The global step train is 2113
2019-04-26 19:31:32,574  The loss during training is  :: 0.08350375294685364 
2019-04-26 19:31:32,734  The global step train is 2114
2019-04-26 19:31:32,864  The loss during training is  :: 0.02481628768146038 
2019-04-26 19:31:33,024  The global step train is 2115
2019-04-26 19:31:33,151  The loss during training is  :: 0.015414305031299591 
2019-04-26 19:31:33,314  The global step train is 2116
2019-04-26 19:31:33,446  The loss during training is  :: 0.01934143155813217 
2019-04-26 19:31:33,608  The global step train is 2117
2019-04-26 19:31:33,735  The loss during training is  :: 0.08021017909049988 
2019-04-26 19:31:33,899  The global step train is 2118
2019-04-26 19:31:34,028  The loss during training is  :: 0.06277360022068024 
2019-04-26 19:31:34,189  The global step train is 2119
2019-04-26 19:31:34,323  The loss during training is  :: 0.01527218148112297 
2019-04-26 19:31:34,486  The global step train is 2120
2019-04-26 19:31:34,619  The loss during training is  :: 0.012724396772682667 
2019-04-26 19:31:34,772  The global step train is 2121
2019-04-26 19:31:34,898  The loss during training is  :: 0.08491246402263641 
2019-04-26 19:31:35,061  The global step train is 2122
2019-04-26 19:31:35,190  The loss during training is  :: 0.025545943528413773 
2019-04-26 19:31:35,353  The global step train is 2123
2019-04-26 19:31:35,483  The loss during training is  :: 0.04050245136022568 
2019-04-26 19:31:35,645  The global step train is 2124
2019-04-26 19:31:35,775  The loss during training is  :: 0.03175733610987663 
2019-04-26 19:31:35,936  The global step train is 2125
2019-04-26 19:31:36,065  The loss during training is  :: 0.017302053049206734 
2019-04-26 19:31:36,228  The global step train is 2126
2019-04-26 19:31:36,359  The loss during training is  :: 0.02807852067053318 
2019-04-26 19:31:36,514  The global step train is 2127
2019-04-26 19:31:36,644  The loss during training is  :: 0.016199832782149315 
2019-04-26 19:31:36,800  The global step train is 2128
2019-04-26 19:31:36,932  The loss during training is  :: 0.03337840735912323 
2019-04-26 19:31:37,095  The global step train is 2129
2019-04-26 19:31:37,226  The loss during training is  :: 0.022271299734711647 
2019-04-26 19:31:37,386  The global step train is 2130
2019-04-26 19:31:37,513  The loss during training is  :: 0.037404097616672516 
2019-04-26 19:31:37,675  The global step train is 2131
2019-04-26 19:31:37,809  The loss during training is  :: 0.03711552545428276 
2019-04-26 19:31:37,969  The global step train is 2132
2019-04-26 19:31:38,104  The loss during training is  :: 0.03584185987710953 
2019-04-26 19:31:38,264  The global step train is 2133
2019-04-26 19:31:38,393  The loss during training is  :: 0.026265161111950874 
2019-04-26 19:31:38,559  The global step train is 2134
2019-04-26 19:31:38,692  The loss during training is  :: 0.08870041370391846 
2019-04-26 19:31:38,850  The global step train is 2135
2019-04-26 19:31:38,985  The loss during training is  :: 0.03330783545970917 
2019-04-26 19:31:39,149  The global step train is 2136
2019-04-26 19:31:39,278  The loss during training is  :: 0.03144734352827072 
2019-04-26 19:31:39,439  The global step train is 2137
2019-04-26 19:31:39,564  The loss during training is  :: 0.05886007845401764 
2019-04-26 19:31:39,723  The global step train is 2138
2019-04-26 19:31:39,854  The loss during training is  :: 0.013815171085298061 
2019-04-26 19:31:40,016  The global step train is 2139
2019-04-26 19:31:40,147  The loss during training is  :: 0.018919045105576515 
2019-04-26 19:31:40,320  The global step train is 2140
2019-04-26 19:31:40,451  The loss during training is  :: 0.023091094568371773 
2019-04-26 19:31:40,617  The global step train is 2141
2019-04-26 19:31:40,747  The loss during training is  :: 0.014466384425759315 
2019-04-26 19:31:40,911  The global step train is 2142
2019-04-26 19:31:41,042  The loss during training is  :: 0.07645730674266815 
2019-04-26 19:31:41,202  The global step train is 2143
2019-04-26 19:31:41,366  The loss during training is  :: 0.025809787213802338 
2019-04-26 19:31:41,541  The global step train is 2144
2019-04-26 19:31:41,692  The loss during training is  :: 0.03548602759838104 
2019-04-26 19:31:41,863  The global step train is 2145
2019-04-26 19:31:42,002  The loss during training is  :: 0.00447329506278038 
2019-04-26 19:31:42,175  The global step train is 2146
2019-04-26 19:31:42,314  The loss during training is  :: 0.02323298528790474 
2019-04-26 19:31:42,472  The global step train is 2147
2019-04-26 19:31:42,605  The loss during training is  :: 0.059723127633333206 
2019-04-26 19:31:42,773  The global step train is 2148
2019-04-26 19:31:42,900  The loss during training is  :: 0.015651658177375793 
2019-04-26 19:31:43,063  The global step train is 2149
2019-04-26 19:31:43,199  The loss during training is  :: 0.020283441990613937 
2019-04-26 19:31:43,361  The global step train is 2150
2019-04-26 19:31:43,489  The loss during training is  :: 0.058465100824832916 
2019-04-26 19:31:43,647  The global step train is 2151
2019-04-26 19:31:43,774  The loss during training is  :: 0.011334666982293129 
2019-04-26 19:31:43,939  The global step train is 2152
2019-04-26 19:31:44,069  The loss during training is  :: 0.03801557421684265 
2019-04-26 19:31:44,231  The global step train is 2153
2019-04-26 19:31:44,362  The loss during training is  :: 0.00721310917288065 
2019-04-26 19:31:44,525  The global step train is 2154
2019-04-26 19:31:44,658  The loss during training is  :: 0.01708017662167549 
2019-04-26 19:31:44,823  The global step train is 2155
2019-04-26 19:31:44,950  The loss during training is  :: 0.03772609308362007 
2019-04-26 19:31:45,118  The global step train is 2156
2019-04-26 19:31:45,245  The loss during training is  :: 0.015531495213508606 
2019-04-26 19:31:45,408  The global step train is 2157
2019-04-26 19:31:45,540  The loss during training is  :: 0.00732682878151536 
2019-04-26 19:31:45,705  The global step train is 2158
2019-04-26 19:31:45,835  The loss during training is  :: 0.04197387024760246 
2019-04-26 19:31:46,002  The global step train is 2159
2019-04-26 19:31:46,136  The loss during training is  :: 0.026624634861946106 
2019-04-26 19:31:46,299  The global step train is 2160
2019-04-26 19:31:46,433  The loss during training is  :: 0.006761541590094566 
2019-04-26 19:31:46,601  The global step train is 2161
2019-04-26 19:31:46,734  The loss during training is  :: 0.029357334598898888 
2019-04-26 19:31:46,898  The global step train is 2162
2019-04-26 19:31:47,028  The loss during training is  :: 0.033827487379312515 
2019-04-26 19:31:47,191  The global step train is 2163
2019-04-26 19:31:47,322  The loss during training is  :: 0.020310765132308006 
2019-04-26 19:31:47,485  The global step train is 2164
2019-04-26 19:31:47,618  The loss during training is  :: 0.03810783848166466 
2019-04-26 19:31:47,782  The global step train is 2165
2019-04-26 19:31:47,909  The loss during training is  :: 0.024252567440271378 
2019-04-26 19:31:48,073  The global step train is 2166
2019-04-26 19:31:48,205  The loss during training is  :: 0.03257846087217331 
2019-04-26 19:31:48,370  The global step train is 2167
2019-04-26 19:31:48,495  The loss during training is  :: 0.03186940401792526 
2019-04-26 19:31:48,659  The global step train is 2168
2019-04-26 19:31:48,784  The loss during training is  :: 0.008921814151108265 
2019-04-26 19:31:48,943  The global step train is 2169
2019-04-26 19:31:49,067  The loss during training is  :: 0.012855462729930878 
2019-04-26 19:31:49,233  The global step train is 2170
2019-04-26 19:31:49,368  The loss during training is  :: 0.030584627762436867 
2019-04-26 19:31:49,535  The global step train is 2171
2019-04-26 19:31:49,670  The loss during training is  :: 0.029385926201939583 
2019-04-26 19:31:49,831  The global step train is 2172
2019-04-26 19:31:49,957  The loss during training is  :: 0.017324106767773628 
2019-04-26 19:31:50,120  The global step train is 2173
2019-04-26 19:31:50,248  The loss during training is  :: 0.0131969740614295 
2019-04-26 19:31:50,426  The global step train is 2174
2019-04-26 19:31:50,567  The loss during training is  :: 0.02663794904947281 
2019-04-26 19:31:50,734  The global step train is 2175
2019-04-26 19:31:50,863  The loss during training is  :: 0.05528083071112633 
2019-04-26 19:31:51,028  The global step train is 2176
2019-04-26 19:31:51,162  The loss during training is  :: 0.007860743440687656 
2019-04-26 19:31:51,336  The global step train is 2177
2019-04-26 19:31:51,465  The loss during training is  :: 0.0416996031999588 
2019-04-26 19:31:51,628  The global step train is 2178
2019-04-26 19:31:51,756  The loss during training is  :: 0.033301543444395065 
2019-04-26 19:31:51,923  The global step train is 2179
2019-04-26 19:31:52,054  The loss during training is  :: 0.01447249110788107 
2019-04-26 19:31:52,223  The global step train is 2180
2019-04-26 19:31:52,351  The loss during training is  :: 0.03572725132107735 
2019-04-26 19:31:52,510  The global step train is 2181
2019-04-26 19:31:52,636  The loss during training is  :: 0.03095644898712635 
2019-04-26 19:31:52,804  The global step train is 2182
2019-04-26 19:31:52,937  The loss during training is  :: 0.011921202763915062 
2019-04-26 19:31:53,099  The global step train is 2183
2019-04-26 19:31:53,229  The loss during training is  :: 0.019050201401114464 
2019-04-26 19:31:53,396  The global step train is 2184
2019-04-26 19:31:53,527  The loss during training is  :: 0.023563552647829056 
2019-04-26 19:31:53,693  The global step train is 2185
2019-04-26 19:31:53,823  The loss during training is  :: 0.038675643503665924 
2019-04-26 19:31:53,986  The global step train is 2186
2019-04-26 19:31:54,119  The loss during training is  :: 0.013692639768123627 
2019-04-26 19:31:54,282  The global step train is 2187
2019-04-26 19:31:54,412  The loss during training is  :: 0.011627871543169022 
2019-04-26 19:31:54,579  The global step train is 2188
2019-04-26 19:31:54,714  The loss during training is  :: 0.007162227761000395 
2019-04-26 19:31:54,878  The global step train is 2189
2019-04-26 19:31:55,012  The loss during training is  :: 0.03177569434046745 
2019-04-26 19:31:55,185  The global step train is 2190
2019-04-26 19:31:55,319  The loss during training is  :: 0.004862216301262379 
2019-04-26 19:31:55,483  The global step train is 2191
2019-04-26 19:31:55,613  The loss during training is  :: 0.03713530674576759 
2019-04-26 19:31:55,775  The global step train is 2192
2019-04-26 19:31:55,899  The loss during training is  :: 0.032569143921136856 
2019-04-26 19:31:56,065  The global step train is 2193
2019-04-26 19:31:56,195  The loss during training is  :: 0.03406774252653122 
2019-04-26 19:31:56,363  The global step train is 2194
2019-04-26 19:31:56,495  The loss during training is  :: 0.006629146169871092 
2019-04-26 19:31:56,655  The global step train is 2195
2019-04-26 19:31:56,787  The loss during training is  :: 0.01511760987341404 
2019-04-26 19:31:56,954  The global step train is 2196
2019-04-26 19:31:57,083  The loss during training is  :: 0.02579530142247677 
2019-04-26 19:31:57,246  The global step train is 2197
2019-04-26 19:31:57,378  The loss during training is  :: 0.060145944356918335 
2019-04-26 19:31:57,536  The global step train is 2198
2019-04-26 19:31:57,674  The loss during training is  :: 0.029887694865465164 
2019-04-26 19:31:57,837  The global step train is 2199
2019-04-26 19:31:57,978  The loss during training is  :: 0.0389937162399292 
2019-04-26 19:31:58,153  The global step train is 2200
2019-04-26 19:31:58,288  The loss during training is  :: 0.027820736169815063 
2019-04-26 19:31:58,454  The global step train is 2201
2019-04-26 19:31:58,582  The loss during training is  :: 0.022915471345186234 
2019-04-26 19:31:58,748  The global step train is 2202
2019-04-26 19:31:58,882  The loss during training is  :: 0.03940178081393242 
2019-04-26 19:31:59,043  The global step train is 2203
2019-04-26 19:31:59,176  The loss during training is  :: 0.004659140948206186 
2019-04-26 19:31:59,341  The global step train is 2204
2019-04-26 19:31:59,473  The loss during training is  :: 0.01043134368956089 
2019-04-26 19:31:59,638  The global step train is 2205
2019-04-26 19:31:59,771  The loss during training is  :: 0.016345558688044548 
2019-04-26 19:31:59,935  The global step train is 2206
2019-04-26 19:32:00,063  The loss during training is  :: 0.03616621345281601 
2019-04-26 19:32:00,229  The global step train is 2207
2019-04-26 19:32:00,363  The loss during training is  :: 0.0196316409856081 
2019-04-26 19:32:00,523  The global step train is 2208
2019-04-26 19:32:00,654  The loss during training is  :: 0.04002193734049797 
2019-04-26 19:32:00,817  The global step train is 2209
2019-04-26 19:32:00,951  The loss during training is  :: 0.017810208722949028 
2019-04-26 19:32:01,129  The global step train is 2210
2019-04-26 19:32:01,260  The loss during training is  :: 0.05069030821323395 
2019-04-26 19:32:01,427  The global step train is 2211
2019-04-26 19:32:01,554  The loss during training is  :: 0.02881680428981781 
2019-04-26 19:32:01,715  The global step train is 2212
2019-04-26 19:32:01,843  The loss during training is  :: 0.01453819777816534 
2019-04-26 19:32:02,008  The global step train is 2213
2019-04-26 19:32:02,137  The loss during training is  :: 0.013426701538264751 
2019-04-26 19:32:02,301  The global step train is 2214
2019-04-26 19:32:02,439  The loss during training is  :: 0.006681547034531832 
2019-04-26 19:32:02,612  The global step train is 2215
2019-04-26 19:32:02,752  The loss during training is  :: 0.0204881951212883 
2019-04-26 19:32:02,933  The global step train is 2216
2019-04-26 19:32:03,071  The loss during training is  :: 0.011755657382309437 
2019-04-26 19:32:03,250  The global step train is 2217
2019-04-26 19:32:03,391  The loss during training is  :: 0.054519880563020706 
2019-04-26 19:32:03,565  The global step train is 2218
2019-04-26 19:32:03,701  The loss during training is  :: 0.005865958519279957 
2019-04-26 19:32:03,873  The global step train is 2219
2019-04-26 19:32:04,013  The loss during training is  :: 0.015252135694026947 
2019-04-26 19:32:04,189  The global step train is 2220
2019-04-26 19:32:04,339  The loss during training is  :: 0.0228810366243124 
2019-04-26 19:32:04,514  The global step train is 2221
2019-04-26 19:32:04,653  The loss during training is  :: 0.0603334940969944 
2019-04-26 19:32:04,822  The global step train is 2222
2019-04-26 19:32:04,948  The loss during training is  :: 0.08826956152915955 
2019-04-26 19:32:05,115  The global step train is 2223
2019-04-26 19:32:05,242  The loss during training is  :: 0.029362564906477928 
2019-04-26 19:32:05,403  The global step train is 2224
2019-04-26 19:32:05,536  The loss during training is  :: 0.04369004815816879 
2019-04-26 19:32:05,698  The global step train is 2225
2019-04-26 19:32:05,830  The loss during training is  :: 0.02145898900926113 
2019-04-26 19:32:05,993  The global step train is 2226
2019-04-26 19:32:06,126  The loss during training is  :: 0.014211317524313927 
2019-04-26 19:32:06,287  The global step train is 2227
2019-04-26 19:32:06,417  The loss during training is  :: 0.029264716431498528 
2019-04-26 19:32:06,581  The global step train is 2228
2019-04-26 19:32:06,715  The loss during training is  :: 0.03276374936103821 
2019-04-26 19:32:06,873  The global step train is 2229
2019-04-26 19:32:07,006  The loss during training is  :: 0.04460960999131203 
2019-04-26 19:32:07,170  The global step train is 2230
2019-04-26 19:32:07,298  The loss during training is  :: 0.03159572184085846 
2019-04-26 19:32:07,464  The global step train is 2231
2019-04-26 19:32:07,598  The loss during training is  :: 0.08814937621355057 
2019-04-26 19:32:07,795  The global step train is 2232
2019-04-26 19:32:07,933  The loss during training is  :: 0.02064506523311138 
2019-04-26 19:32:08,101  The global step train is 2233
2019-04-26 19:32:08,230  The loss during training is  :: 0.038999442011117935 
2019-04-26 19:32:08,396  The global step train is 2234
2019-04-26 19:32:08,528  The loss during training is  :: 0.009045175276696682 
2019-04-26 19:32:08,693  The global step train is 2235
2019-04-26 19:32:08,826  The loss during training is  :: 0.017885863780975342 
2019-04-26 19:32:08,994  The global step train is 2236
2019-04-26 19:32:09,125  The loss during training is  :: 0.03786580264568329 
2019-04-26 19:32:09,292  The global step train is 2237
2019-04-26 19:32:09,421  The loss during training is  :: 0.05037695914506912 
2019-04-26 19:32:09,587  The global step train is 2238
2019-04-26 19:32:09,715  The loss during training is  :: 0.02057928405702114 
2019-04-26 19:32:09,879  The global step train is 2239
2019-04-26 19:32:10,012  The loss during training is  :: 0.021537799388170242 
2019-04-26 19:32:10,173  The global step train is 2240
2019-04-26 19:32:10,176  Starting evaluation 
2019-04-26 19:32:10,313  The loss during eval_loss is  :: 0.07245125621557236
2019-04-26 19:32:10,315  The global step eval is 505
2019-04-26 19:32:10,437  The loss during eval_loss is  :: 0.04868273064494133
2019-04-26 19:32:10,439  The global step eval is 506
2019-04-26 19:32:10,549  The loss during eval_loss is  :: 0.015106544829905033
2019-04-26 19:32:10,550  The global step eval is 507
2019-04-26 19:32:10,660  The loss during eval_loss is  :: 0.024578100070357323
2019-04-26 19:32:10,662  The global step eval is 508
2019-04-26 19:32:10,787  The loss during eval_loss is  :: 0.05136481672525406
2019-04-26 19:32:10,789  The global step eval is 509
2019-04-26 19:32:10,898  The loss during eval_loss is  :: 0.09353147447109222
2019-04-26 19:32:10,900  The global step eval is 510
2019-04-26 19:32:11,021  The loss during eval_loss is  :: 0.095357745885849
2019-04-26 19:32:11,023  The global step eval is 511
2019-04-26 19:32:11,140  The loss during eval_loss is  :: 0.003981847781687975
2019-04-26 19:32:11,141  The global step eval is 512
2019-04-26 19:32:11,247  The loss during eval_loss is  :: 0.07020952552556992
2019-04-26 19:32:11,249  The global step eval is 513
2019-04-26 19:32:11,362  The loss during eval_loss is  :: 0.0442548505961895
2019-04-26 19:32:11,364  The global step eval is 514
2019-04-26 19:32:11,478  The loss during eval_loss is  :: 0.11453556269407272
2019-04-26 19:32:11,480  The global step eval is 515
2019-04-26 19:32:11,588  The loss during eval_loss is  :: 0.022786103188991547
2019-04-26 19:32:11,590  The global step eval is 516
2019-04-26 19:32:11,697  The loss during eval_loss is  :: 0.02528807707130909
2019-04-26 19:32:11,699  The global step eval is 517
2019-04-26 19:32:11,802  The loss during eval_loss is  :: 0.05565652996301651
2019-04-26 19:32:11,804  The global step eval is 518
2019-04-26 19:32:11,913  The loss during eval_loss is  :: 0.02712593413889408
2019-04-26 19:32:11,916  The global step eval is 519
2019-04-26 19:32:12,020  The loss during eval_loss is  :: 0.08998985588550568
2019-04-26 19:32:12,022  The global step eval is 520
2019-04-26 19:32:12,130  The loss during eval_loss is  :: 0.05092386156320572
2019-04-26 19:32:12,132  The global step eval is 521
2019-04-26 19:32:12,248  The loss during eval_loss is  :: 0.14664475619792938
2019-04-26 19:32:12,250  The global step eval is 522
2019-04-26 19:32:12,356  The loss during eval_loss is  :: 0.05065164715051651
2019-04-26 19:32:12,357  The global step eval is 523
2019-04-26 19:32:12,467  The loss during eval_loss is  :: 0.0409993901848793
2019-04-26 19:32:12,469  The global step eval is 524
2019-04-26 19:32:12,581  The loss during eval_loss is  :: 0.09293027967214584
2019-04-26 19:32:12,582  The global step eval is 525
2019-04-26 19:32:12,690  The loss during eval_loss is  :: 0.04427473247051239
2019-04-26 19:32:12,692  The global step eval is 526
2019-04-26 19:32:12,816  The loss during eval_loss is  :: 0.05228225886821747
2019-04-26 19:32:12,817  The global step eval is 527
2019-04-26 19:32:12,926  The loss during eval_loss is  :: 0.04945219308137894
2019-04-26 19:32:12,928  The global step eval is 528
2019-04-26 19:32:13,073  The loss during eval_loss is  :: 0.04395866021513939
2019-04-26 19:32:13,074  The global step eval is 529
2019-04-26 19:32:13,197  The loss during eval_loss is  :: 0.006558135151863098
2019-04-26 19:32:13,199  The global step eval is 530
2019-04-26 19:32:13,300  The loss during eval_loss is  :: 0.07272359728813171
2019-04-26 19:32:13,302  The global step eval is 531
2019-04-26 19:32:13,413  The loss during eval_loss is  :: 0.04446440935134888
2019-04-26 19:32:13,415  The global step eval is 532
2019-04-26 19:32:13,528  The loss during eval_loss is  :: 0.05419827625155449
2019-04-26 19:32:13,529  The global step eval is 533
2019-04-26 19:32:13,637  The loss during eval_loss is  :: 0.022585581988096237
2019-04-26 19:32:13,640  The global step eval is 534
2019-04-26 19:32:13,747  The loss during eval_loss is  :: 0.055283185094594955
2019-04-26 19:32:13,749  The global step eval is 535
2019-04-26 19:32:13,853  The loss during eval_loss is  :: 0.057035643607378006
2019-04-26 19:32:13,855  The global step eval is 536
2019-04-26 19:32:13,959  The loss during eval_loss is  :: 0.04964938759803772
2019-04-26 19:32:13,961  The global step eval is 537
2019-04-26 19:32:14,085  The loss during eval_loss is  :: 0.1212969496846199
2019-04-26 19:32:14,087  The global step eval is 538
2019-04-26 19:32:14,197  The loss during eval_loss is  :: 0.044219549745321274
2019-04-26 19:32:14,199  The global step eval is 539
2019-04-26 19:32:14,308  The loss during eval_loss is  :: 0.10812807828187943
2019-04-26 19:32:14,310  The global step eval is 540
2019-04-26 19:32:14,418  The loss during eval_loss is  :: 0.09759849309921265
2019-04-26 19:32:14,420  The global step eval is 541
2019-04-26 19:32:14,521  The loss during eval_loss is  :: 0.06636226922273636
2019-04-26 19:32:14,523  The global step eval is 542
2019-04-26 19:32:14,652  The loss during eval_loss is  :: 0.00841206219047308
2019-04-26 19:32:14,654  The global step eval is 543
2019-04-26 19:32:14,779  The loss during eval_loss is  :: 0.020476458594202995
2019-04-26 19:32:14,780  The global step eval is 544
2019-04-26 19:32:14,883  The loss during eval_loss is  :: 0.03198575973510742
2019-04-26 19:32:14,885  The global step eval is 545
2019-04-26 19:32:14,995  The loss during eval_loss is  :: 0.03613043949007988
2019-04-26 19:32:14,997  The global step eval is 546
2019-04-26 19:32:15,111  The loss during eval_loss is  :: 0.07621580362319946
2019-04-26 19:32:15,113  The global step eval is 547
2019-04-26 19:32:15,219  The loss during eval_loss is  :: 0.020011119544506073
2019-04-26 19:32:15,220  The global step eval is 548
2019-04-26 19:32:15,344  The loss during eval_loss is  :: 0.14260123670101166
2019-04-26 19:32:15,346  The global step eval is 549
2019-04-26 19:32:15,475  The loss during eval_loss is  :: 0.03881860896945
2019-04-26 19:32:15,477  The global step eval is 550
2019-04-26 19:32:15,581  The loss during eval_loss is  :: 0.07886247336864471
2019-04-26 19:32:15,582  The global step eval is 551
2019-04-26 19:32:15,688  The loss during eval_loss is  :: 0.10369895398616791
2019-04-26 19:32:15,690  The global step eval is 552
2019-04-26 19:32:15,805  The loss during eval_loss is  :: 0.016282370314002037
2019-04-26 19:32:15,806  The global step eval is 553
2019-04-26 19:32:15,908  The loss during eval_loss is  :: 0.09246900677680969
2019-04-26 19:32:15,910  The global step eval is 554
2019-04-26 19:32:16,012  The loss during eval_loss is  :: 0.08427615463733673
2019-04-26 19:32:16,014  The global step eval is 555
2019-04-26 19:32:16,116  The loss during eval_loss is  :: 0.028238197788596153
2019-04-26 19:32:16,118  The global step eval is 556
2019-04-26 19:32:16,238  The loss during eval_loss is  :: 0.0642978698015213
2019-04-26 19:32:16,240  The global step eval is 557
2019-04-26 19:32:16,345  The loss during eval_loss is  :: 0.02009912207722664
2019-04-26 19:32:16,347  The global step eval is 558
2019-04-26 19:32:16,452  The loss during eval_loss is  :: 0.034013018012046814
2019-04-26 19:32:16,454  The global step eval is 559
2019-04-26 19:32:16,557  The loss during eval_loss is  :: 0.05869610607624054
2019-04-26 19:32:16,559  The global step eval is 560
2019-04-26 19:32:16,570  Saved checkpoint: ./trained_model\step_9.pth.tar
2019-04-26 19:32:16,571  Removed checkpoint: ./trained_model\step_5.pth.tar
2019-04-26 19:32:16,676  The loss during training is  :: 0.06400755792856216 
2019-04-26 19:32:16,834  The global step train is 2241
2019-04-26 19:32:16,960  The loss during training is  :: 0.02435588277876377 
2019-04-26 19:32:17,130  The global step train is 2242
2019-04-26 19:32:17,261  The loss during training is  :: 0.00945997890084982 
2019-04-26 19:32:17,427  The global step train is 2243
2019-04-26 19:32:17,555  The loss during training is  :: 0.012692035175859928 
2019-04-26 19:32:17,717  The global step train is 2244
2019-04-26 19:32:17,850  The loss during training is  :: 0.044221822172403336 
2019-04-26 19:32:18,011  The global step train is 2245
2019-04-26 19:32:18,146  The loss during training is  :: 0.04580052196979523 
2019-04-26 19:32:18,310  The global step train is 2246
2019-04-26 19:32:18,437  The loss during training is  :: 0.01750897988677025 
2019-04-26 19:32:18,595  The global step train is 2247
2019-04-26 19:32:18,720  The loss during training is  :: 0.02787451446056366 
2019-04-26 19:32:18,886  The global step train is 2248
2019-04-26 19:32:19,013  The loss during training is  :: 0.027178993448615074 
2019-04-26 19:32:19,180  The global step train is 2249
2019-04-26 19:32:19,315  The loss during training is  :: 0.029016857966780663 
2019-04-26 19:32:19,479  The global step train is 2250
2019-04-26 19:32:19,608  The loss during training is  :: 0.03058670088648796 
2019-04-26 19:32:19,785  The global step train is 2251
2019-04-26 19:32:19,912  The loss during training is  :: 0.03432471305131912 
2019-04-26 19:32:20,076  The global step train is 2252
2019-04-26 19:32:20,205  The loss during training is  :: 0.04728477820754051 
2019-04-26 19:32:20,373  The global step train is 2253
2019-04-26 19:32:20,507  The loss during training is  :: 0.005064818076789379 
2019-04-26 19:32:20,669  The global step train is 2254
2019-04-26 19:32:20,802  The loss during training is  :: 0.02027287147939205 
2019-04-26 19:32:20,964  The global step train is 2255
2019-04-26 19:32:21,095  The loss during training is  :: 0.028731880709528923 
2019-04-26 19:32:21,262  The global step train is 2256
2019-04-26 19:32:21,393  The loss during training is  :: 0.006484937854111195 
2019-04-26 19:32:21,553  The global step train is 2257
2019-04-26 19:32:21,687  The loss during training is  :: 0.05569698289036751 
2019-04-26 19:32:21,860  The global step train is 2258
2019-04-26 19:32:21,998  The loss during training is  :: 0.041665222495794296 
2019-04-26 19:32:22,168  The global step train is 2259
2019-04-26 19:32:22,299  The loss during training is  :: 0.025372564792633057 
2019-04-26 19:32:22,467  The global step train is 2260
2019-04-26 19:32:22,602  The loss during training is  :: 0.03262973204255104 
2019-04-26 19:32:22,772  The global step train is 2261
2019-04-26 19:32:22,907  The loss during training is  :: 0.04187905788421631 
2019-04-26 19:32:23,079  The global step train is 2262
2019-04-26 19:32:23,222  The loss during training is  :: 0.0669998973608017 
2019-04-26 19:32:23,389  The global step train is 2263
2019-04-26 19:32:23,522  The loss during training is  :: 0.05237526074051857 
2019-04-26 19:32:23,691  The global step train is 2264
2019-04-26 19:32:23,826  The loss during training is  :: 0.007511288393288851 
2019-04-26 19:32:23,994  The global step train is 2265
2019-04-26 19:32:24,129  The loss during training is  :: 0.04522659257054329 
2019-04-26 19:32:24,303  The global step train is 2266
2019-04-26 19:32:24,445  The loss during training is  :: 0.04310688376426697 
2019-04-26 19:32:24,617  The global step train is 2267
2019-04-26 19:32:24,755  The loss during training is  :: 0.01884201355278492 
2019-04-26 19:32:24,929  The global step train is 2268
2019-04-26 19:32:25,066  The loss during training is  :: 0.03120304085314274 
2019-04-26 19:32:25,240  The global step train is 2269
2019-04-26 19:32:25,369  The loss during training is  :: 0.015084988437592983 
2019-04-26 19:32:25,529  The global step train is 2270
2019-04-26 19:32:25,665  The loss during training is  :: 0.031248673796653748 
2019-04-26 19:32:25,833  The global step train is 2271
2019-04-26 19:32:25,969  The loss during training is  :: 0.018632424995303154 
2019-04-26 19:32:26,132  The global step train is 2272
2019-04-26 19:32:26,279  The loss during training is  :: 0.0220699030905962 
2019-04-26 19:32:26,452  The global step train is 2273
2019-04-26 19:32:26,586  The loss during training is  :: 0.01598173752427101 
2019-04-26 19:32:26,754  The global step train is 2274
2019-04-26 19:32:26,889  The loss during training is  :: 0.007518126163631678 
2019-04-26 19:32:27,057  The global step train is 2275
2019-04-26 19:32:27,190  The loss during training is  :: 0.005606282502412796 
2019-04-26 19:32:27,361  The global step train is 2276
2019-04-26 19:32:27,495  The loss during training is  :: 0.04521295800805092 
2019-04-26 19:32:27,667  The global step train is 2277
2019-04-26 19:32:27,794  The loss during training is  :: 0.01229898165911436 
2019-04-26 19:32:27,959  The global step train is 2278
2019-04-26 19:32:28,085  The loss during training is  :: 0.02650502882897854 
2019-04-26 19:32:28,265  The global step train is 2279
2019-04-26 19:32:28,402  The loss during training is  :: 0.03382272645831108 
2019-04-26 19:32:28,570  The global step train is 2280
2019-04-26 19:32:28,709  The loss during training is  :: 0.006853278260678053 
2019-04-26 19:32:28,878  The global step train is 2281
2019-04-26 19:32:29,011  The loss during training is  :: 0.04766944795846939 
2019-04-26 19:32:29,179  The global step train is 2282
2019-04-26 19:32:29,319  The loss during training is  :: 0.010849736630916595 
2019-04-26 19:32:29,491  The global step train is 2283
2019-04-26 19:32:29,628  The loss during training is  :: 0.009278465993702412 
2019-04-26 19:32:29,805  The global step train is 2284
2019-04-26 19:32:29,940  The loss during training is  :: 0.006426858715713024 
2019-04-26 19:32:30,111  The global step train is 2285
2019-04-26 19:32:30,244  The loss during training is  :: 0.019236739724874496 
2019-04-26 19:32:30,420  The global step train is 2286
2019-04-26 19:32:30,555  The loss during training is  :: 0.1698756217956543 
2019-04-26 19:32:30,724  The global step train is 2287
2019-04-26 19:32:30,858  The loss during training is  :: 0.01615944877266884 
2019-04-26 19:32:31,031  The global step train is 2288
2019-04-26 19:32:31,165  The loss during training is  :: 0.028740955516695976 
2019-04-26 19:32:31,331  The global step train is 2289
2019-04-26 19:32:31,464  The loss during training is  :: 0.026907416060566902 
2019-04-26 19:32:31,635  The global step train is 2290
2019-04-26 19:32:31,767  The loss during training is  :: 0.026176931336522102 
2019-04-26 19:32:31,936  The global step train is 2291
2019-04-26 19:32:32,068  The loss during training is  :: 0.01706465147435665 
2019-04-26 19:32:32,238  The global step train is 2292
2019-04-26 19:32:32,372  The loss during training is  :: 0.014461730606853962 
2019-04-26 19:32:32,537  The global step train is 2293
2019-04-26 19:32:32,667  The loss during training is  :: 0.023036323487758636 
2019-04-26 19:32:32,829  The global step train is 2294
2019-04-26 19:32:32,956  The loss during training is  :: 0.029596611857414246 
2019-04-26 19:32:33,125  The global step train is 2295
2019-04-26 19:32:33,252  The loss during training is  :: 0.010227524675428867 
2019-04-26 19:32:33,425  The global step train is 2296
2019-04-26 19:32:33,557  The loss during training is  :: 0.02965114824473858 
2019-04-26 19:32:33,726  The global step train is 2297
2019-04-26 19:32:33,856  The loss during training is  :: 0.02121630311012268 
2019-04-26 19:32:34,016  The global step train is 2298
2019-04-26 19:32:34,148  The loss during training is  :: 0.010133905336260796 
2019-04-26 19:32:34,313  The global step train is 2299
2019-04-26 19:32:34,448  The loss during training is  :: 0.026258233934640884 
2019-04-26 19:32:34,613  The global step train is 2300
2019-04-26 19:32:34,742  The loss during training is  :: 0.053055159747600555 
2019-04-26 19:32:34,909  The global step train is 2301
2019-04-26 19:32:35,036  The loss during training is  :: 0.007694155443459749 
2019-04-26 19:32:35,199  The global step train is 2302
2019-04-26 19:32:35,323  The loss during training is  :: 0.04301817715167999 
2019-04-26 19:32:35,494  The global step train is 2303
2019-04-26 19:32:35,625  The loss during training is  :: 0.028102153912186623 
2019-04-26 19:32:35,786  The global step train is 2304
2019-04-26 19:32:35,914  The loss during training is  :: 0.010054048150777817 
2019-04-26 19:32:36,075  The global step train is 2305
2019-04-26 19:32:36,206  The loss during training is  :: 0.009002024307847023 
2019-04-26 19:32:36,367  The global step train is 2306
2019-04-26 19:32:36,500  The loss during training is  :: 0.016957689076662064 
2019-04-26 19:32:36,657  The global step train is 2307
2019-04-26 19:32:36,783  The loss during training is  :: 0.02966652624309063 
2019-04-26 19:32:36,944  The global step train is 2308
2019-04-26 19:32:37,071  The loss during training is  :: 0.01473261509090662 
2019-04-26 19:32:37,243  The global step train is 2309
2019-04-26 19:32:37,376  The loss during training is  :: 0.028707584366202354 
2019-04-26 19:32:37,544  The global step train is 2310
2019-04-26 19:32:37,674  The loss during training is  :: 0.014945713803172112 
2019-04-26 19:32:37,837  The global step train is 2311
2019-04-26 19:32:37,967  The loss during training is  :: 0.03288061544299126 
2019-04-26 19:32:38,128  The global step train is 2312
2019-04-26 19:32:38,254  The loss during training is  :: 0.04768047481775284 
2019-04-26 19:32:38,425  The global step train is 2313
2019-04-26 19:32:38,554  The loss during training is  :: 0.009223083034157753 
2019-04-26 19:32:38,716  The global step train is 2314
2019-04-26 19:32:38,848  The loss during training is  :: 0.03681261092424393 
2019-04-26 19:32:39,012  The global step train is 2315
2019-04-26 19:32:39,139  The loss during training is  :: 0.061822447925806046 
2019-04-26 19:32:39,298  The global step train is 2316
2019-04-26 19:32:39,438  The loss during training is  :: 0.010117584839463234 
2019-04-26 19:32:39,605  The global step train is 2317
2019-04-26 19:32:39,732  The loss during training is  :: 0.026234455406665802 
2019-04-26 19:32:39,899  The global step train is 2318
2019-04-26 19:32:40,029  The loss during training is  :: 0.054244447499513626 
2019-04-26 19:32:40,189  The global step train is 2319
2019-04-26 19:32:40,321  The loss during training is  :: 0.021261781454086304 
2019-04-26 19:32:40,484  The global step train is 2320
2019-04-26 19:32:40,617  The loss during training is  :: 0.04236723855137825 
2019-04-26 19:32:40,781  The global step train is 2321
2019-04-26 19:32:40,910  The loss during training is  :: 0.011262896470725536 
2019-04-26 19:32:41,091  The global step train is 2322
2019-04-26 19:32:41,219  The loss during training is  :: 0.022512998431921005 
2019-04-26 19:32:41,385  The global step train is 2323
2019-04-26 19:32:41,524  The loss during training is  :: 0.03950415551662445 
2019-04-26 19:32:41,687  The global step train is 2324
2019-04-26 19:32:41,818  The loss during training is  :: 0.03189554810523987 
2019-04-26 19:32:41,986  The global step train is 2325
2019-04-26 19:32:42,114  The loss during training is  :: 0.005804519634693861 
2019-04-26 19:32:42,279  The global step train is 2326
2019-04-26 19:32:42,412  The loss during training is  :: 0.026677625253796577 
2019-04-26 19:32:42,576  The global step train is 2327
2019-04-26 19:32:42,708  The loss during training is  :: 0.05999351665377617 
2019-04-26 19:32:42,871  The global step train is 2328
2019-04-26 19:32:42,999  The loss during training is  :: 0.023575039580464363 
2019-04-26 19:32:43,162  The global step train is 2329
2019-04-26 19:32:43,288  The loss during training is  :: 0.05479728803038597 
2019-04-26 19:32:43,448  The global step train is 2330
2019-04-26 19:32:43,580  The loss during training is  :: 0.012506389990448952 
2019-04-26 19:32:43,740  The global step train is 2331
2019-04-26 19:32:43,871  The loss during training is  :: 0.05514384061098099 
2019-04-26 19:32:44,032  The global step train is 2332
2019-04-26 19:32:44,163  The loss during training is  :: 0.01236207690089941 
2019-04-26 19:32:44,327  The global step train is 2333
2019-04-26 19:32:44,459  The loss during training is  :: 0.01398405060172081 
2019-04-26 19:32:44,630  The global step train is 2334
2019-04-26 19:32:44,764  The loss during training is  :: 0.07284006476402283 
2019-04-26 19:32:44,927  The global step train is 2335
2019-04-26 19:32:45,050  The loss during training is  :: 0.02575712464749813 
2019-04-26 19:32:45,227  The global step train is 2336
2019-04-26 19:32:45,354  The loss during training is  :: 0.029909886419773102 
2019-04-26 19:32:45,512  The global step train is 2337
2019-04-26 19:32:45,644  The loss during training is  :: 0.048382557928562164 
2019-04-26 19:32:45,804  The global step train is 2338
2019-04-26 19:32:45,935  The loss during training is  :: 0.010181557387113571 
2019-04-26 19:32:46,097  The global step train is 2339
2019-04-26 19:32:46,231  The loss during training is  :: 0.03552834689617157 
2019-04-26 19:32:46,393  The global step train is 2340
2019-04-26 19:32:46,523  The loss during training is  :: 0.01363446842879057 
2019-04-26 19:32:46,686  The global step train is 2341
2019-04-26 19:32:46,806  The loss during training is  :: 0.0584256686270237 
2019-04-26 19:32:46,967  The global step train is 2342
2019-04-26 19:32:47,098  The loss during training is  :: 0.04690028727054596 
2019-04-26 19:32:47,255  The global step train is 2343
2019-04-26 19:32:47,387  The loss during training is  :: 0.02053603157401085 
2019-04-26 19:32:47,547  The global step train is 2344
2019-04-26 19:32:47,679  The loss during training is  :: 0.015736499801278114 
2019-04-26 19:32:47,841  The global step train is 2345
2019-04-26 19:32:47,973  The loss during training is  :: 0.015757359564304352 
2019-04-26 19:32:48,136  The global step train is 2346
2019-04-26 19:32:48,270  The loss during training is  :: 0.030664049088954926 
2019-04-26 19:32:48,431  The global step train is 2347
2019-04-26 19:32:48,556  The loss during training is  :: 0.03241343051195145 
2019-04-26 19:32:48,724  The global step train is 2348
2019-04-26 19:32:48,851  The loss during training is  :: 0.008071746677160263 
2019-04-26 19:32:49,012  The global step train is 2349
2019-04-26 19:32:49,142  The loss during training is  :: 0.015634950250387192 
2019-04-26 19:32:49,309  The global step train is 2350
2019-04-26 19:32:49,440  The loss during training is  :: 0.021928153932094574 
2019-04-26 19:32:49,610  The global step train is 2351
2019-04-26 19:32:49,736  The loss during training is  :: 0.01300573069602251 
2019-04-26 19:32:49,898  The global step train is 2352
2019-04-26 19:32:50,024  The loss during training is  :: 0.040297236293554306 
2019-04-26 19:32:50,190  The global step train is 2353
2019-04-26 19:32:50,325  The loss during training is  :: 0.010335483588278294 
2019-04-26 19:32:50,485  The global step train is 2354
2019-04-26 19:32:50,624  The loss during training is  :: 0.03151261806488037 
2019-04-26 19:32:50,785  The global step train is 2355
2019-04-26 19:32:50,915  The loss during training is  :: 0.01484417263418436 
2019-04-26 19:32:51,085  The global step train is 2356
2019-04-26 19:32:51,212  The loss during training is  :: 0.03577378764748573 
2019-04-26 19:32:51,370  The global step train is 2357
2019-04-26 19:32:51,497  The loss during training is  :: 0.03135261312127113 
2019-04-26 19:32:51,655  The global step train is 2358
2019-04-26 19:32:51,785  The loss during training is  :: 0.01355733536183834 
2019-04-26 19:32:51,949  The global step train is 2359
2019-04-26 19:32:52,070  The loss during training is  :: 0.01989484764635563 
2019-04-26 19:32:52,236  The global step train is 2360
2019-04-26 19:32:52,366  The loss during training is  :: 0.007328634150326252 
2019-04-26 19:32:52,528  The global step train is 2361
2019-04-26 19:32:52,659  The loss during training is  :: 0.016372237354516983 
2019-04-26 19:32:52,816  The global step train is 2362
2019-04-26 19:32:52,945  The loss during training is  :: 0.02959405817091465 
2019-04-26 19:32:53,107  The global step train is 2363
2019-04-26 19:32:53,234  The loss during training is  :: 0.008235225453972816 
2019-04-26 19:32:53,391  The global step train is 2364
2019-04-26 19:32:53,523  The loss during training is  :: 0.06846296042203903 
2019-04-26 19:32:53,684  The global step train is 2365
2019-04-26 19:32:53,811  The loss during training is  :: 0.025285927578806877 
2019-04-26 19:32:53,972  The global step train is 2366
2019-04-26 19:32:54,100  The loss during training is  :: 0.005071576219052076 
2019-04-26 19:32:54,256  The global step train is 2367
2019-04-26 19:32:54,386  The loss during training is  :: 0.017545325681567192 
2019-04-26 19:32:54,553  The global step train is 2368
2019-04-26 19:32:54,685  The loss during training is  :: 0.011175832711160183 
2019-04-26 19:32:54,845  The global step train is 2369
2019-04-26 19:32:54,971  The loss during training is  :: 0.007476240862160921 
2019-04-26 19:32:55,144  The global step train is 2370
2019-04-26 19:32:55,273  The loss during training is  :: 0.039118774235248566 
2019-04-26 19:32:55,432  The global step train is 2371
2019-04-26 19:32:55,564  The loss during training is  :: 0.0075438846834003925 
2019-04-26 19:32:55,729  The global step train is 2372
2019-04-26 19:32:55,862  The loss during training is  :: 0.005844211671501398 
2019-04-26 19:32:56,030  The global step train is 2373
2019-04-26 19:32:56,157  The loss during training is  :: 0.015774525701999664 
2019-04-26 19:32:56,320  The global step train is 2374
2019-04-26 19:32:56,445  The loss during training is  :: 0.019061777740716934 
2019-04-26 19:32:56,607  The global step train is 2375
2019-04-26 19:32:56,740  The loss during training is  :: 0.008566334843635559 
2019-04-26 19:32:56,902  The global step train is 2376
2019-04-26 19:32:57,027  The loss during training is  :: 0.02770265005528927 
2019-04-26 19:32:57,197  The global step train is 2377
2019-04-26 19:32:57,332  The loss during training is  :: 0.02216629683971405 
2019-04-26 19:32:57,495  The global step train is 2378
2019-04-26 19:32:57,628  The loss during training is  :: 0.03974060341715813 
2019-04-26 19:32:57,797  The global step train is 2379
2019-04-26 19:32:57,930  The loss during training is  :: 0.031373534351587296 
2019-04-26 19:32:58,093  The global step train is 2380
2019-04-26 19:32:58,223  The loss during training is  :: 0.073554627597332 
2019-04-26 19:32:58,388  The global step train is 2381
2019-04-26 19:32:58,520  The loss during training is  :: 0.019605262205004692 
2019-04-26 19:32:58,684  The global step train is 2382
2019-04-26 19:32:58,814  The loss during training is  :: 0.012701050378382206 
2019-04-26 19:32:58,973  The global step train is 2383
2019-04-26 19:32:59,101  The loss during training is  :: 0.05325384438037872 
2019-04-26 19:32:59,266  The global step train is 2384
2019-04-26 19:32:59,388  The loss during training is  :: 0.015607007779181004 
2019-04-26 19:32:59,554  The global step train is 2385
2019-04-26 19:32:59,681  The loss during training is  :: 0.04886024072766304 
2019-04-26 19:32:59,842  The global step train is 2386
2019-04-26 19:32:59,974  The loss during training is  :: 0.02555597573518753 
2019-04-26 19:33:00,142  The global step train is 2387
2019-04-26 19:33:00,272  The loss during training is  :: 0.018317563459277153 
2019-04-26 19:33:00,437  The global step train is 2388
2019-04-26 19:33:00,565  The loss during training is  :: 0.011142559349536896 
2019-04-26 19:33:00,724  The global step train is 2389
2019-04-26 19:33:00,858  The loss during training is  :: 0.02695808745920658 
2019-04-26 19:33:01,023  The global step train is 2390
2019-04-26 19:33:01,150  The loss during training is  :: 0.015056880190968513 
2019-04-26 19:33:01,311  The global step train is 2391
2019-04-26 19:33:01,443  The loss during training is  :: 0.02127213217318058 
2019-04-26 19:33:01,618  The global step train is 2392
2019-04-26 19:33:01,743  The loss during training is  :: 0.004588257521390915 
2019-04-26 19:33:01,913  The global step train is 2393
2019-04-26 19:33:02,043  The loss during training is  :: 0.02076370269060135 
2019-04-26 19:33:02,208  The global step train is 2394
2019-04-26 19:33:02,341  The loss during training is  :: 0.06956283748149872 
2019-04-26 19:33:02,507  The global step train is 2395
2019-04-26 19:33:02,635  The loss during training is  :: 0.012446867302060127 
2019-04-26 19:33:02,803  The global step train is 2396
2019-04-26 19:33:02,930  The loss during training is  :: 0.009735641069710255 
2019-04-26 19:33:03,087  The global step train is 2397
2019-04-26 19:33:03,215  The loss during training is  :: 0.020495355129241943 
2019-04-26 19:33:03,380  The global step train is 2398
2019-04-26 19:33:03,500  The loss during training is  :: 0.046511247754096985 
2019-04-26 19:33:03,664  The global step train is 2399
2019-04-26 19:33:03,794  The loss during training is  :: 0.019517894834280014 
2019-04-26 19:33:03,958  The global step train is 2400
2019-04-26 19:33:04,087  The loss during training is  :: 0.012144632637500763 
2019-04-26 19:33:04,257  The global step train is 2401
2019-04-26 19:33:04,388  The loss during training is  :: 0.02639394998550415 
2019-04-26 19:33:04,552  The global step train is 2402
2019-04-26 19:33:04,683  The loss during training is  :: 0.03187904506921768 
2019-04-26 19:33:04,847  The global step train is 2403
2019-04-26 19:33:04,984  The loss during training is  :: 0.013959592208266258 
2019-04-26 19:33:05,145  The global step train is 2404
2019-04-26 19:33:05,280  The loss during training is  :: 0.019678965210914612 
2019-04-26 19:33:05,445  The global step train is 2405
2019-04-26 19:33:05,583  The loss during training is  :: 0.021966101601719856 
2019-04-26 19:33:05,768  The global step train is 2406
2019-04-26 19:33:05,915  The loss during training is  :: 0.027417169883847237 
2019-04-26 19:33:06,094  The global step train is 2407
2019-04-26 19:33:06,239  The loss during training is  :: 0.04044061526656151 
2019-04-26 19:33:06,424  The global step train is 2408
2019-04-26 19:33:06,567  The loss during training is  :: 0.0180622898042202 
2019-04-26 19:33:06,756  The global step train is 2409
2019-04-26 19:33:06,899  The loss during training is  :: 0.006080124992877245 
2019-04-26 19:33:07,091  The global step train is 2410
2019-04-26 19:33:07,232  The loss during training is  :: 0.016744321212172508 
2019-04-26 19:33:07,396  The global step train is 2411
2019-04-26 19:33:07,528  The loss during training is  :: 0.030891990289092064 
2019-04-26 19:33:07,693  The global step train is 2412
2019-04-26 19:33:07,824  The loss during training is  :: 0.025324204936623573 
2019-04-26 19:33:07,998  The global step train is 2413
2019-04-26 19:33:08,130  The loss during training is  :: 0.03188743069767952 
2019-04-26 19:33:08,295  The global step train is 2414
2019-04-26 19:33:08,426  The loss during training is  :: 0.00910810474306345 
2019-04-26 19:33:08,586  The global step train is 2415
2019-04-26 19:33:08,716  The loss during training is  :: 0.024516636505723 
2019-04-26 19:33:08,884  The global step train is 2416
2019-04-26 19:33:09,012  The loss during training is  :: 0.007976140826940536 
2019-04-26 19:33:09,175  The global step train is 2417
2019-04-26 19:33:09,305  The loss during training is  :: 0.02632269263267517 
2019-04-26 19:33:09,468  The global step train is 2418
2019-04-26 19:33:09,596  The loss during training is  :: 0.019500818103551865 
2019-04-26 19:33:09,757  The global step train is 2419
2019-04-26 19:33:09,887  The loss during training is  :: 0.03212423995137215 
2019-04-26 19:33:10,054  The global step train is 2420
2019-04-26 19:33:10,182  The loss during training is  :: 0.03232473507523537 
2019-04-26 19:33:10,343  The global step train is 2421
2019-04-26 19:33:10,470  The loss during training is  :: 0.020711218938231468 
2019-04-26 19:33:10,633  The global step train is 2422
2019-04-26 19:33:10,761  The loss during training is  :: 0.007443237118422985 
2019-04-26 19:33:10,931  The global step train is 2423
2019-04-26 19:33:11,055  The loss during training is  :: 0.0110862348228693 
2019-04-26 19:33:11,236  The global step train is 2424
2019-04-26 19:33:11,378  The loss during training is  :: 0.03647451847791672 
2019-04-26 19:33:11,559  The global step train is 2425
2019-04-26 19:33:11,699  The loss during training is  :: 0.01762240007519722 
2019-04-26 19:33:11,889  The global step train is 2426
2019-04-26 19:33:12,024  The loss during training is  :: 0.02570153959095478 
2019-04-26 19:33:12,187  The global step train is 2427
2019-04-26 19:33:12,312  The loss during training is  :: 0.008282960392534733 
2019-04-26 19:33:12,474  The global step train is 2428
2019-04-26 19:33:12,605  The loss during training is  :: 0.015526339411735535 
2019-04-26 19:33:12,769  The global step train is 2429
2019-04-26 19:33:12,902  The loss during training is  :: 0.026866737753152847 
2019-04-26 19:33:13,063  The global step train is 2430
2019-04-26 19:33:13,189  The loss during training is  :: 0.040374938398599625 
2019-04-26 19:33:13,350  The global step train is 2431
2019-04-26 19:33:13,479  The loss during training is  :: 0.02764212340116501 
2019-04-26 19:33:13,641  The global step train is 2432
2019-04-26 19:33:13,772  The loss during training is  :: 0.004543107468634844 
2019-04-26 19:33:13,932  The global step train is 2433
2019-04-26 19:33:14,061  The loss during training is  :: 0.013122052885591984 
2019-04-26 19:33:14,231  The global step train is 2434
2019-04-26 19:33:14,364  The loss during training is  :: 0.023556776344776154 
2019-04-26 19:33:14,526  The global step train is 2435
2019-04-26 19:33:14,657  The loss during training is  :: 0.015940742567181587 
2019-04-26 19:33:14,827  The global step train is 2436
2019-04-26 19:33:14,959  The loss during training is  :: 0.0207686685025692 
2019-04-26 19:33:15,125  The global step train is 2437
2019-04-26 19:33:15,255  The loss during training is  :: 0.04039471223950386 
2019-04-26 19:33:15,418  The global step train is 2438
2019-04-26 19:33:15,544  The loss during training is  :: 0.01398021075874567 
2019-04-26 19:33:15,711  The global step train is 2439
2019-04-26 19:33:15,840  The loss during training is  :: 0.031319260597229004 
2019-04-26 19:33:16,005  The global step train is 2440
2019-04-26 19:33:16,135  The loss during training is  :: 0.017035435885190964 
2019-04-26 19:33:16,298  The global step train is 2441
2019-04-26 19:33:16,427  The loss during training is  :: 0.036354515701532364 
2019-04-26 19:33:16,589  The global step train is 2442
2019-04-26 19:33:16,720  The loss during training is  :: 0.030460920184850693 
2019-04-26 19:33:16,886  The global step train is 2443
2019-04-26 19:33:17,022  The loss during training is  :: 0.028719047084450722 
2019-04-26 19:33:17,188  The global step train is 2444
2019-04-26 19:33:17,319  The loss during training is  :: 0.03567919135093689 
2019-04-26 19:33:17,484  The global step train is 2445
2019-04-26 19:33:17,613  The loss during training is  :: 0.0403616726398468 
2019-04-26 19:33:17,779  The global step train is 2446
2019-04-26 19:33:17,908  The loss during training is  :: 0.024048417806625366 
2019-04-26 19:33:18,072  The global step train is 2447
2019-04-26 19:33:18,207  The loss during training is  :: 0.013190005905926228 
2019-04-26 19:33:18,372  The global step train is 2448
2019-04-26 19:33:18,504  The loss during training is  :: 0.007278633303940296 
2019-04-26 19:33:18,668  The global step train is 2449
2019-04-26 19:33:18,793  The loss during training is  :: 0.09001144021749496 
2019-04-26 19:33:18,959  The global step train is 2450
2019-04-26 19:33:19,084  The loss during training is  :: 0.032508138567209244 
2019-04-26 19:33:19,247  The global step train is 2451
2019-04-26 19:33:19,374  The loss during training is  :: 0.047908373177051544 
2019-04-26 19:33:19,541  The global step train is 2452
2019-04-26 19:33:19,670  The loss during training is  :: 0.0056415400467813015 
2019-04-26 19:33:19,833  The global step train is 2453
2019-04-26 19:33:19,968  The loss during training is  :: 0.03153073787689209 
2019-04-26 19:33:20,138  The global step train is 2454
2019-04-26 19:33:20,272  The loss during training is  :: 0.008221756666898727 
2019-04-26 19:33:20,437  The global step train is 2455
2019-04-26 19:33:20,565  The loss during training is  :: 0.039890166372060776 
2019-04-26 19:33:20,732  The global step train is 2456
2019-04-26 19:33:20,857  The loss during training is  :: 0.1000911295413971 
2019-04-26 19:33:21,020  The global step train is 2457
2019-04-26 19:33:21,157  The loss during training is  :: 0.001813929877243936 
2019-04-26 19:33:21,329  The global step train is 2458
2019-04-26 19:33:21,461  The loss during training is  :: 0.010519014671444893 
2019-04-26 19:33:21,623  The global step train is 2459
2019-04-26 19:33:21,755  The loss during training is  :: 0.052780911326408386 
2019-04-26 19:33:21,917  The global step train is 2460
2019-04-26 19:33:22,048  The loss during training is  :: 0.019929831847548485 
2019-04-26 19:33:22,221  The global step train is 2461
2019-04-26 19:33:22,356  The loss during training is  :: 0.021720746532082558 
2019-04-26 19:33:22,517  The global step train is 2462
2019-04-26 19:33:22,649  The loss during training is  :: 0.008270924910902977 
2019-04-26 19:33:22,817  The global step train is 2463
2019-04-26 19:33:22,947  The loss during training is  :: 0.030600249767303467 
2019-04-26 19:33:23,118  The global step train is 2464
2019-04-26 19:33:23,120  Starting evaluation 
2019-04-26 19:33:23,261  The loss during eval_loss is  :: 0.05667385831475258
2019-04-26 19:33:23,264  The global step eval is 561
2019-04-26 19:33:23,384  The loss during eval_loss is  :: 0.03620826080441475
2019-04-26 19:33:23,386  The global step eval is 562
2019-04-26 19:33:23,504  The loss during eval_loss is  :: 0.01572500914335251
2019-04-26 19:33:23,506  The global step eval is 563
2019-04-26 19:33:23,629  The loss during eval_loss is  :: 0.018869673833251
2019-04-26 19:33:23,630  The global step eval is 564
2019-04-26 19:33:23,738  The loss during eval_loss is  :: 0.04688341170549393
2019-04-26 19:33:23,740  The global step eval is 565
2019-04-26 19:33:23,856  The loss during eval_loss is  :: 0.05598853528499603
2019-04-26 19:33:23,858  The global step eval is 566
2019-04-26 19:33:23,967  The loss during eval_loss is  :: 0.06891952455043793
2019-04-26 19:33:23,969  The global step eval is 567
2019-04-26 19:33:24,084  The loss during eval_loss is  :: 0.004559987224638462
2019-04-26 19:33:24,086  The global step eval is 568
2019-04-26 19:33:24,206  The loss during eval_loss is  :: 0.07552135735750198
2019-04-26 19:33:24,208  The global step eval is 569
2019-04-26 19:33:24,309  The loss during eval_loss is  :: 0.023977724835276604
2019-04-26 19:33:24,311  The global step eval is 570
2019-04-26 19:33:24,412  The loss during eval_loss is  :: 0.09867262840270996
2019-04-26 19:33:24,414  The global step eval is 571
2019-04-26 19:33:24,536  The loss during eval_loss is  :: 0.03576553612947464
2019-04-26 19:33:24,538  The global step eval is 572
2019-04-26 19:33:24,648  The loss during eval_loss is  :: 0.023923499509692192
2019-04-26 19:33:24,650  The global step eval is 573
2019-04-26 19:33:24,770  The loss during eval_loss is  :: 0.051119014620780945
2019-04-26 19:33:24,772  The global step eval is 574
2019-04-26 19:33:24,891  The loss during eval_loss is  :: 0.03807484731078148
2019-04-26 19:33:24,893  The global step eval is 575
2019-04-26 19:33:25,007  The loss during eval_loss is  :: 0.10165943950414658
2019-04-26 19:33:25,009  The global step eval is 576
2019-04-26 19:33:25,116  The loss during eval_loss is  :: 0.11507881432771683
2019-04-26 19:33:25,118  The global step eval is 577
2019-04-26 19:33:25,230  The loss during eval_loss is  :: 0.11144930869340897
2019-04-26 19:33:25,232  The global step eval is 578
2019-04-26 19:33:25,355  The loss during eval_loss is  :: 0.02749617025256157
2019-04-26 19:33:25,357  The global step eval is 579
2019-04-26 19:33:25,472  The loss during eval_loss is  :: 0.0493023507297039
2019-04-26 19:33:25,474  The global step eval is 580
2019-04-26 19:33:25,583  The loss during eval_loss is  :: 0.059214673936367035
2019-04-26 19:33:25,585  The global step eval is 581
2019-04-26 19:33:25,694  The loss during eval_loss is  :: 0.08051244914531708
2019-04-26 19:33:25,695  The global step eval is 582
2019-04-26 19:33:25,798  The loss during eval_loss is  :: 0.03680402413010597
2019-04-26 19:33:25,799  The global step eval is 583
2019-04-26 19:33:25,912  The loss during eval_loss is  :: 0.044307950884103775
2019-04-26 19:33:25,914  The global step eval is 584
2019-04-26 19:33:26,026  The loss during eval_loss is  :: 0.02366291545331478
2019-04-26 19:33:26,028  The global step eval is 585
2019-04-26 19:33:26,145  The loss during eval_loss is  :: 0.0069988504983484745
2019-04-26 19:33:26,147  The global step eval is 586
2019-04-26 19:33:26,255  The loss during eval_loss is  :: 0.052406031638383865
2019-04-26 19:33:26,257  The global step eval is 587
2019-04-26 19:33:26,363  The loss during eval_loss is  :: 0.04277965798974037
2019-04-26 19:33:26,365  The global step eval is 588
2019-04-26 19:33:26,469  The loss during eval_loss is  :: 0.07500945776700974
2019-04-26 19:33:26,470  The global step eval is 589
2019-04-26 19:33:26,575  The loss during eval_loss is  :: 0.03670966997742653
2019-04-26 19:33:26,577  The global step eval is 590
2019-04-26 19:33:26,691  The loss during eval_loss is  :: 0.029170040041208267
2019-04-26 19:33:26,693  The global step eval is 591
2019-04-26 19:33:26,797  The loss during eval_loss is  :: 0.06959985196590424
2019-04-26 19:33:26,798  The global step eval is 592
2019-04-26 19:33:26,906  The loss during eval_loss is  :: 0.06429671496152878
2019-04-26 19:33:26,908  The global step eval is 593
2019-04-26 19:33:27,020  The loss during eval_loss is  :: 0.11084134131669998
2019-04-26 19:33:27,022  The global step eval is 594
2019-04-26 19:33:27,140  The loss during eval_loss is  :: 0.026465559378266335
2019-04-26 19:33:27,142  The global step eval is 595
2019-04-26 19:33:27,259  The loss during eval_loss is  :: 0.11069722473621368
2019-04-26 19:33:27,261  The global step eval is 596
2019-04-26 19:33:27,376  The loss during eval_loss is  :: 0.05711710453033447
2019-04-26 19:33:27,378  The global step eval is 597
2019-04-26 19:33:27,511  The loss during eval_loss is  :: 0.06101014465093613
2019-04-26 19:33:27,513  The global step eval is 598
2019-04-26 19:33:27,614  The loss during eval_loss is  :: 0.022370414808392525
2019-04-26 19:33:27,616  The global step eval is 599
2019-04-26 19:33:27,718  The loss during eval_loss is  :: 0.010338465683162212
2019-04-26 19:33:27,720  The global step eval is 600
2019-04-26 19:33:27,835  The loss during eval_loss is  :: 0.022273240610957146
2019-04-26 19:33:27,837  The global step eval is 601
2019-04-26 19:33:27,945  The loss during eval_loss is  :: 0.03092178888618946
2019-04-26 19:33:27,947  The global step eval is 602
2019-04-26 19:33:28,055  The loss during eval_loss is  :: 0.06590256094932556
2019-04-26 19:33:28,057  The global step eval is 603
2019-04-26 19:33:28,174  The loss during eval_loss is  :: 0.04162855073809624
2019-04-26 19:33:28,177  The global step eval is 604
2019-04-26 19:33:28,294  The loss during eval_loss is  :: 0.1436583399772644
2019-04-26 19:33:28,296  The global step eval is 605
2019-04-26 19:33:28,408  The loss during eval_loss is  :: 0.04500981420278549
2019-04-26 19:33:28,410  The global step eval is 606
2019-04-26 19:33:28,517  The loss during eval_loss is  :: 0.09335952997207642
2019-04-26 19:33:28,519  The global step eval is 607
2019-04-26 19:33:28,635  The loss during eval_loss is  :: 0.08293471485376358
2019-04-26 19:33:28,637  The global step eval is 608
2019-04-26 19:33:28,747  The loss during eval_loss is  :: 0.017731113359332085
2019-04-26 19:33:28,748  The global step eval is 609
2019-04-26 19:33:28,852  The loss during eval_loss is  :: 0.0628742054104805
2019-04-26 19:33:28,854  The global step eval is 610
2019-04-26 19:33:28,967  The loss during eval_loss is  :: 0.07287131994962692
2019-04-26 19:33:28,969  The global step eval is 611
2019-04-26 19:33:29,089  The loss during eval_loss is  :: 0.03621535003185272
2019-04-26 19:33:29,090  The global step eval is 612
2019-04-26 19:33:29,201  The loss during eval_loss is  :: 0.02798190526664257
2019-04-26 19:33:29,203  The global step eval is 613
2019-04-26 19:33:29,312  The loss during eval_loss is  :: 0.01260211318731308
2019-04-26 19:33:29,313  The global step eval is 614
2019-04-26 19:33:29,421  The loss during eval_loss is  :: 0.05623784288764
2019-04-26 19:33:29,423  The global step eval is 615
2019-04-26 19:33:29,536  The loss during eval_loss is  :: 0.04453675448894501
2019-04-26 19:33:29,538  The global step eval is 616
2019-04-26 19:33:29,562  Saved checkpoint: ./trained_model\step_10.pth.tar
2019-04-26 19:33:29,564  Removed checkpoint: ./trained_model\step_10.pth.tar
2019-04-26 19:33:29,663  The loss during training is  :: 0.010778694413602352 
2019-04-26 19:33:29,821  The global step train is 2465
2019-04-26 19:33:29,952  The loss during training is  :: 0.016327856108546257 
2019-04-26 19:33:30,133  The global step train is 2466
2019-04-26 19:33:30,270  The loss during training is  :: 0.005410239100456238 
2019-04-26 19:33:30,433  The global step train is 2467
2019-04-26 19:33:30,566  The loss during training is  :: 0.028208404779434204 
2019-04-26 19:33:30,731  The global step train is 2468
2019-04-26 19:33:30,862  The loss during training is  :: 0.03438190743327141 
2019-04-26 19:33:31,029  The global step train is 2469
2019-04-26 19:33:31,159  The loss during training is  :: 0.0117116067558527 
2019-04-26 19:33:31,326  The global step train is 2470
2019-04-26 19:33:31,455  The loss during training is  :: 0.006829633843153715 
2019-04-26 19:33:31,614  The global step train is 2471
2019-04-26 19:33:31,742  The loss during training is  :: 0.008800357580184937 
2019-04-26 19:33:31,908  The global step train is 2472
2019-04-26 19:33:32,033  The loss during training is  :: 0.012574717402458191 
2019-04-26 19:33:32,197  The global step train is 2473
2019-04-26 19:33:32,335  The loss during training is  :: 0.020340263843536377 
2019-04-26 19:33:32,500  The global step train is 2474
2019-04-26 19:33:32,632  The loss during training is  :: 0.02594321221113205 
2019-04-26 19:33:32,798  The global step train is 2475
2019-04-26 19:33:32,925  The loss during training is  :: 0.015408837236464024 
2019-04-26 19:33:33,089  The global step train is 2476
2019-04-26 19:33:33,222  The loss during training is  :: 0.005649229511618614 
2019-04-26 19:33:33,384  The global step train is 2477
2019-04-26 19:33:33,518  The loss during training is  :: 0.008281691931188107 
2019-04-26 19:33:33,682  The global step train is 2478
2019-04-26 19:33:33,814  The loss during training is  :: 0.025766858831048012 
2019-04-26 19:33:33,976  The global step train is 2479
2019-04-26 19:33:34,105  The loss during training is  :: 0.15405093133449554 
2019-04-26 19:33:34,273  The global step train is 2480
2019-04-26 19:33:34,410  The loss during training is  :: 0.011319824494421482 
2019-04-26 19:33:34,576  The global step train is 2481
2019-04-26 19:33:34,707  The loss during training is  :: 0.00995565764605999 
2019-04-26 19:33:34,873  The global step train is 2482
2019-04-26 19:33:35,005  The loss during training is  :: 0.01820736564695835 
2019-04-26 19:33:35,171  The global step train is 2483
2019-04-26 19:33:35,300  The loss during training is  :: 0.008441537618637085 
2019-04-26 19:33:35,464  The global step train is 2484
2019-04-26 19:33:35,593  The loss during training is  :: 0.02735758200287819 
2019-04-26 19:33:35,755  The global step train is 2485
2019-04-26 19:33:35,883  The loss during training is  :: 0.007597634103149176 
2019-04-26 19:33:36,047  The global step train is 2486
2019-04-26 19:33:36,173  The loss during training is  :: 0.016921456903219223 
2019-04-26 19:33:36,336  The global step train is 2487
2019-04-26 19:33:36,460  The loss during training is  :: 0.015462452545762062 
2019-04-26 19:33:36,620  The global step train is 2488
2019-04-26 19:33:36,742  The loss during training is  :: 0.028929049149155617 
2019-04-26 19:33:36,901  The global step train is 2489
2019-04-26 19:33:37,036  The loss during training is  :: 0.009382756426930428 
2019-04-26 19:33:37,203  The global step train is 2490
2019-04-26 19:33:37,343  The loss during training is  :: 0.006152083165943623 
2019-04-26 19:33:37,507  The global step train is 2491
2019-04-26 19:33:37,640  The loss during training is  :: 0.013719571754336357 
2019-04-26 19:33:37,801  The global step train is 2492
2019-04-26 19:33:37,934  The loss during training is  :: 0.0073083145543932915 
2019-04-26 19:33:38,098  The global step train is 2493
2019-04-26 19:33:38,229  The loss during training is  :: 0.011885722167789936 
2019-04-26 19:33:38,390  The global step train is 2494
2019-04-26 19:33:38,520  The loss during training is  :: 0.00919576920568943 
2019-04-26 19:33:38,682  The global step train is 2495
2019-04-26 19:33:38,809  The loss during training is  :: 0.030064335092902184 
2019-04-26 19:33:38,972  The global step train is 2496
2019-04-26 19:33:39,095  The loss during training is  :: 0.010512241162359715 
2019-04-26 19:33:39,256  The global step train is 2497
2019-04-26 19:33:39,378  The loss during training is  :: 0.018718525767326355 
2019-04-26 19:33:39,538  The global step train is 2498
2019-04-26 19:33:39,671  The loss during training is  :: 0.0042857457883656025 
2019-04-26 19:33:39,833  The global step train is 2499
2019-04-26 19:33:39,952  The loss during training is  :: 0.017568236216902733 
2019-04-26 19:33:40,113  The global step train is 2500
2019-04-26 19:33:40,249  The loss during training is  :: 0.016709845513105392 
2019-04-26 19:33:40,425  The global step train is 2501
2019-04-26 19:33:40,557  The loss during training is  :: 0.021679537370800972 
2019-04-26 19:33:40,719  The global step train is 2502
2019-04-26 19:33:40,854  The loss during training is  :: 0.013641525991261005 
2019-04-26 19:33:41,012  The global step train is 2503
2019-04-26 19:33:41,155  The loss during training is  :: 0.019639378413558006 
2019-04-26 19:33:41,336  The global step train is 2504
2019-04-26 19:33:41,478  The loss during training is  :: 0.028675667941570282 
2019-04-26 19:33:41,646  The global step train is 2505
2019-04-26 19:33:41,779  The loss during training is  :: 0.023867197334766388 
2019-04-26 19:33:41,939  The global step train is 2506
2019-04-26 19:33:42,068  The loss during training is  :: 0.005817518103867769 
2019-04-26 19:33:42,230  The global step train is 2507
2019-04-26 19:33:42,361  The loss during training is  :: 0.022458773106336594 
2019-04-26 19:33:42,521  The global step train is 2508
2019-04-26 19:33:42,650  The loss during training is  :: 0.025014257058501244 
2019-04-26 19:33:42,813  The global step train is 2509
2019-04-26 19:33:42,939  The loss during training is  :: 0.009735136292874813 
2019-04-26 19:33:43,105  The global step train is 2510
2019-04-26 19:33:43,228  The loss during training is  :: 0.009282862767577171 
2019-04-26 19:33:43,392  The global step train is 2511
2019-04-26 19:33:43,520  The loss during training is  :: 0.01810678467154503 
2019-04-26 19:33:43,681  The global step train is 2512
2019-04-26 19:33:43,810  The loss during training is  :: 0.04347553849220276 
2019-04-26 19:33:43,976  The global step train is 2513
2019-04-26 19:33:44,106  The loss during training is  :: 0.016640285030007362 
2019-04-26 19:33:44,268  The global step train is 2514
2019-04-26 19:33:44,402  The loss during training is  :: 0.013036876916885376 
2019-04-26 19:33:44,565  The global step train is 2515
2019-04-26 19:33:44,697  The loss during training is  :: 0.020604807883501053 
2019-04-26 19:33:44,857  The global step train is 2516
2019-04-26 19:33:44,986  The loss during training is  :: 0.02424681931734085 
2019-04-26 19:33:45,151  The global step train is 2517
2019-04-26 19:33:45,280  The loss during training is  :: 0.04646619036793709 
2019-04-26 19:33:45,442  The global step train is 2518
2019-04-26 19:33:45,574  The loss during training is  :: 0.020657332614064217 
2019-04-26 19:33:45,738  The global step train is 2519
2019-04-26 19:33:45,872  The loss during training is  :: 0.03345998376607895 
2019-04-26 19:33:46,035  The global step train is 2520
2019-04-26 19:33:46,163  The loss during training is  :: 0.009794950485229492 
2019-04-26 19:33:46,328  The global step train is 2521
2019-04-26 19:33:46,454  The loss during training is  :: 0.011697349138557911 
2019-04-26 19:33:46,627  The global step train is 2522
2019-04-26 19:33:46,757  The loss during training is  :: 0.017806358635425568 
2019-04-26 19:33:46,922  The global step train is 2523
2019-04-26 19:33:47,047  The loss during training is  :: 0.007483959197998047 
2019-04-26 19:33:47,205  The global step train is 2524
2019-04-26 19:33:47,333  The loss during training is  :: 0.017493143677711487 
2019-04-26 19:33:47,493  The global step train is 2525
2019-04-26 19:33:47,632  The loss during training is  :: 0.017605507746338844 
2019-04-26 19:33:47,797  The global step train is 2526
2019-04-26 19:33:47,925  The loss during training is  :: 0.01095641776919365 
2019-04-26 19:33:48,087  The global step train is 2527
2019-04-26 19:33:48,219  The loss during training is  :: 0.0146082304418087 
2019-04-26 19:33:48,378  The global step train is 2528
2019-04-26 19:33:48,513  The loss during training is  :: 0.01736137643456459 
2019-04-26 19:33:48,675  The global step train is 2529
2019-04-26 19:33:48,810  The loss during training is  :: 0.017695071175694466 
2019-04-26 19:33:48,969  The global step train is 2530
2019-04-26 19:33:49,102  The loss during training is  :: 0.004368921741843224 
2019-04-26 19:33:49,265  The global step train is 2531
2019-04-26 19:33:49,397  The loss during training is  :: 0.004731359425932169 
2019-04-26 19:33:49,563  The global step train is 2532
2019-04-26 19:33:49,693  The loss during training is  :: 0.008073256351053715 
2019-04-26 19:33:49,854  The global step train is 2533
2019-04-26 19:33:49,986  The loss during training is  :: 0.025295352563261986 
2019-04-26 19:33:50,150  The global step train is 2534
2019-04-26 19:33:50,283  The loss during training is  :: 0.015284826047718525 
2019-04-26 19:33:50,449  The global step train is 2535
2019-04-26 19:33:50,587  The loss during training is  :: 0.024139869958162308 
2019-04-26 19:33:50,754  The global step train is 2536
2019-04-26 19:33:50,886  The loss during training is  :: 0.027977483347058296 
2019-04-26 19:33:51,052  The global step train is 2537
2019-04-26 19:33:51,180  The loss during training is  :: 0.003193330718204379 
2019-04-26 19:33:51,340  The global step train is 2538
2019-04-26 19:33:51,471  The loss during training is  :: 0.06485621631145477 
2019-04-26 19:33:51,645  The global step train is 2539
2019-04-26 19:33:51,775  The loss during training is  :: 0.012165890075266361 
2019-04-26 19:33:51,938  The global step train is 2540
2019-04-26 19:33:52,074  The loss during training is  :: 0.011217288672924042 
2019-04-26 19:33:52,239  The global step train is 2541
2019-04-26 19:33:52,368  The loss during training is  :: 0.03674129396677017 
2019-04-26 19:33:52,527  The global step train is 2542
2019-04-26 19:33:52,660  The loss during training is  :: 0.007490447256714106 
2019-04-26 19:33:52,826  The global step train is 2543
2019-04-26 19:33:52,961  The loss during training is  :: 0.016741551458835602 
2019-04-26 19:33:53,115  The global step train is 2544
2019-04-26 19:33:53,246  The loss during training is  :: 0.008960663340985775 
2019-04-26 19:33:53,403  The global step train is 2545
2019-04-26 19:33:53,534  The loss during training is  :: 0.0058990539982914925 
2019-04-26 19:33:53,695  The global step train is 2546
2019-04-26 19:33:53,828  The loss during training is  :: 0.04467163607478142 
2019-04-26 19:33:53,986  The global step train is 2547
2019-04-26 19:33:54,116  The loss during training is  :: 0.008628915064036846 
2019-04-26 19:33:54,274  The global step train is 2548
2019-04-26 19:33:54,404  The loss during training is  :: 0.04090317338705063 
2019-04-26 19:33:54,569  The global step train is 2549
2019-04-26 19:33:54,703  The loss during training is  :: 0.05835029482841492 
2019-04-26 19:33:54,861  The global step train is 2550
2019-04-26 19:33:54,991  The loss during training is  :: 0.015955911949276924 
2019-04-26 19:33:55,159  The global step train is 2551
2019-04-26 19:33:55,287  The loss during training is  :: 0.0059786573983728886 
2019-04-26 19:33:55,449  The global step train is 2552
2019-04-26 19:33:55,580  The loss during training is  :: 0.01477734837681055 
2019-04-26 19:33:55,743  The global step train is 2553
2019-04-26 19:33:55,877  The loss during training is  :: 0.05086660385131836 
2019-04-26 19:33:56,039  The global step train is 2554
2019-04-26 19:33:56,172  The loss during training is  :: 0.01871909201145172 
2019-04-26 19:33:56,331  The global step train is 2555
2019-04-26 19:33:56,462  The loss during training is  :: 0.06291565299034119 
2019-04-26 19:33:56,626  The global step train is 2556
2019-04-26 19:33:56,758  The loss during training is  :: 0.01781492307782173 
2019-04-26 19:33:56,919  The global step train is 2557
2019-04-26 19:33:57,051  The loss during training is  :: 0.017763592302799225 
2019-04-26 19:33:57,234  The global step train is 2558
2019-04-26 19:33:57,372  The loss during training is  :: 0.059384796768426895 
2019-04-26 19:33:57,541  The global step train is 2559
2019-04-26 19:33:57,674  The loss during training is  :: 0.010791781358420849 
2019-04-26 19:33:57,839  The global step train is 2560
2019-04-26 19:33:57,971  The loss during training is  :: 0.01338417362421751 
2019-04-26 19:33:58,141  The global step train is 2561
2019-04-26 19:33:58,305  The loss during training is  :: 0.014404570683836937 
2019-04-26 19:33:58,480  The global step train is 2562
2019-04-26 19:33:58,612  The loss during training is  :: 0.02980768121778965 
2019-04-26 19:33:58,773  The global step train is 2563
2019-04-26 19:33:58,904  The loss during training is  :: 0.08274703472852707 
2019-04-26 19:33:59,065  The global step train is 2564
2019-04-26 19:33:59,190  The loss during training is  :: 0.020828494802117348 
2019-04-26 19:33:59,354  The global step train is 2565
2019-04-26 19:33:59,480  The loss during training is  :: 0.023279089480638504 
2019-04-26 19:33:59,639  The global step train is 2566
2019-04-26 19:33:59,776  The loss during training is  :: 0.024271944537758827 
2019-04-26 19:33:59,941  The global step train is 2567
2019-04-26 19:34:00,076  The loss during training is  :: 0.06639010459184647 
2019-04-26 19:34:00,241  The global step train is 2568
2019-04-26 19:34:00,368  The loss during training is  :: 0.007535308133810759 
2019-04-26 19:34:00,527  The global step train is 2569
2019-04-26 19:34:00,660  The loss during training is  :: 0.04516836628317833 
2019-04-26 19:34:00,820  The global step train is 2570
2019-04-26 19:34:00,949  The loss during training is  :: 0.014835052192211151 
2019-04-26 19:34:01,110  The global step train is 2571
2019-04-26 19:34:01,241  The loss during training is  :: 0.04577529430389404 
2019-04-26 19:34:01,408  The global step train is 2572
2019-04-26 19:34:01,536  The loss during training is  :: 0.025133326649665833 
2019-04-26 19:34:01,698  The global step train is 2573
2019-04-26 19:34:01,826  The loss during training is  :: 0.03693525493144989 
2019-04-26 19:34:01,985  The global step train is 2574
2019-04-26 19:34:02,112  The loss during training is  :: 0.0569225437939167 
2019-04-26 19:34:02,281  The global step train is 2575
2019-04-26 19:34:02,412  The loss during training is  :: 0.039395321160554886 
2019-04-26 19:34:02,582  The global step train is 2576
2019-04-26 19:34:02,708  The loss during training is  :: 0.017294295132160187 
2019-04-26 19:34:02,884  The global step train is 2577
2019-04-26 19:34:03,012  The loss during training is  :: 0.013418843038380146 
2019-04-26 19:34:03,177  The global step train is 2578
2019-04-26 19:34:03,312  The loss during training is  :: 0.008985265158116817 
2019-04-26 19:34:03,472  The global step train is 2579
2019-04-26 19:34:03,605  The loss during training is  :: 0.01486724242568016 
2019-04-26 19:34:03,766  The global step train is 2580
2019-04-26 19:34:03,897  The loss during training is  :: 0.01965143531560898 
2019-04-26 19:34:04,069  The global step train is 2581
2019-04-26 19:34:04,207  The loss during training is  :: 0.01760903373360634 
2019-04-26 19:34:04,377  The global step train is 2582
2019-04-26 19:34:04,502  The loss during training is  :: 0.01648152992129326 
2019-04-26 19:34:04,663  The global step train is 2583
2019-04-26 19:34:04,799  The loss during training is  :: 0.008391128852963448 
2019-04-26 19:34:04,966  The global step train is 2584
2019-04-26 19:34:05,102  The loss during training is  :: 0.01755448430776596 
2019-04-26 19:34:05,264  The global step train is 2585
2019-04-26 19:34:05,395  The loss during training is  :: 0.011188154108822346 
2019-04-26 19:34:05,563  The global step train is 2586
2019-04-26 19:34:05,696  The loss during training is  :: 0.002179260365664959 
2019-04-26 19:34:05,863  The global step train is 2587
2019-04-26 19:34:05,997  The loss during training is  :: 0.012668177485466003 
2019-04-26 19:34:06,162  The global step train is 2588
2019-04-26 19:34:06,295  The loss during training is  :: 0.01005642581731081 
2019-04-26 19:34:06,455  The global step train is 2589
2019-04-26 19:34:06,584  The loss during training is  :: 0.021607259288430214 
2019-04-26 19:34:06,745  The global step train is 2590
2019-04-26 19:34:06,877  The loss during training is  :: 0.009767192415893078 
2019-04-26 19:34:07,041  The global step train is 2591
2019-04-26 19:34:07,173  The loss during training is  :: 0.024333540350198746 
2019-04-26 19:34:07,328  The global step train is 2592
2019-04-26 19:34:07,460  The loss during training is  :: 0.010906998068094254 
2019-04-26 19:34:07,624  The global step train is 2593
2019-04-26 19:34:07,751  The loss during training is  :: 0.10512641817331314 
2019-04-26 19:34:07,918  The global step train is 2594
2019-04-26 19:34:08,051  The loss during training is  :: 0.022836897522211075 
2019-04-26 19:34:08,223  The global step train is 2595
2019-04-26 19:34:08,355  The loss during training is  :: 0.011659597046673298 
2019-04-26 19:34:08,519  The global step train is 2596
2019-04-26 19:34:08,648  The loss during training is  :: 0.009607909247279167 
2019-04-26 19:34:08,814  The global step train is 2597
2019-04-26 19:34:08,937  The loss during training is  :: 0.012934455648064613 
2019-04-26 19:34:09,095  The global step train is 2598
2019-04-26 19:34:09,228  The loss during training is  :: 0.016453878954052925 
2019-04-26 19:34:09,389  The global step train is 2599
2019-04-26 19:34:09,517  The loss during training is  :: 0.05070040747523308 
2019-04-26 19:34:09,682  The global step train is 2600
2019-04-26 19:34:09,814  The loss during training is  :: 0.031409405171871185 
2019-04-26 19:34:09,981  The global step train is 2601
2019-04-26 19:34:10,113  The loss during training is  :: 0.01812893897294998 
2019-04-26 19:34:10,280  The global step train is 2602
2019-04-26 19:34:10,414  The loss during training is  :: 0.021663866937160492 
2019-04-26 19:34:10,573  The global step train is 2603
2019-04-26 19:34:10,706  The loss during training is  :: 0.028730208054184914 
2019-04-26 19:34:10,878  The global step train is 2604
2019-04-26 19:34:11,007  The loss during training is  :: 0.011952953413128853 
2019-04-26 19:34:11,170  The global step train is 2605
2019-04-26 19:34:11,296  The loss during training is  :: 0.005884052719920874 
2019-04-26 19:34:11,460  The global step train is 2606
2019-04-26 19:34:11,593  The loss during training is  :: 0.01084962859749794 
2019-04-26 19:34:11,751  The global step train is 2607
2019-04-26 19:34:11,880  The loss during training is  :: 0.018046407029032707 
2019-04-26 19:34:12,045  The global step train is 2608
2019-04-26 19:34:12,172  The loss during training is  :: 0.026301288977265358 
2019-04-26 19:34:12,335  The global step train is 2609
2019-04-26 19:34:12,462  The loss during training is  :: 0.0669146403670311 
2019-04-26 19:34:12,628  The global step train is 2610
2019-04-26 19:34:12,760  The loss during training is  :: 0.09079547971487045 
2019-04-26 19:34:12,923  The global step train is 2611
2019-04-26 19:34:13,050  The loss during training is  :: 0.04182559624314308 
2019-04-26 19:34:13,215  The global step train is 2612
2019-04-26 19:34:13,348  The loss during training is  :: 0.013439365662634373 
2019-04-26 19:34:13,525  The global step train is 2613
2019-04-26 19:34:13,656  The loss during training is  :: 0.004990345798432827 
2019-04-26 19:34:13,812  The global step train is 2614
2019-04-26 19:34:13,944  The loss during training is  :: 0.019763533025979996 
2019-04-26 19:34:14,114  The global step train is 2615
2019-04-26 19:34:14,236  The loss during training is  :: 0.03921515867114067 
2019-04-26 19:34:14,401  The global step train is 2616
2019-04-26 19:34:14,530  The loss during training is  :: 0.008077592588961124 
2019-04-26 19:34:14,688  The global step train is 2617
2019-04-26 19:34:14,815  The loss during training is  :: 0.034675560891628265 
2019-04-26 19:34:14,977  The global step train is 2618
2019-04-26 19:34:15,114  The loss during training is  :: 0.07876888662576675 
2019-04-26 19:34:15,279  The global step train is 2619
2019-04-26 19:34:15,412  The loss during training is  :: 0.021631119772791862 
2019-04-26 19:34:15,575  The global step train is 2620
2019-04-26 19:34:15,700  The loss during training is  :: 0.007195644546300173 
2019-04-26 19:34:15,862  The global step train is 2621
2019-04-26 19:34:15,992  The loss during training is  :: 0.03728090226650238 
2019-04-26 19:34:16,160  The global step train is 2622
2019-04-26 19:34:16,301  The loss during training is  :: 0.021489746868610382 
2019-04-26 19:34:16,467  The global step train is 2623
2019-04-26 19:34:16,597  The loss during training is  :: 0.026196952909231186 
2019-04-26 19:34:16,770  The global step train is 2624
2019-04-26 19:34:16,897  The loss during training is  :: 0.02132320962846279 
2019-04-26 19:34:17,060  The global step train is 2625
2019-04-26 19:34:17,191  The loss during training is  :: 0.04750165343284607 
2019-04-26 19:34:17,351  The global step train is 2626
2019-04-26 19:34:17,479  The loss during training is  :: 0.027866210788488388 
2019-04-26 19:34:17,643  The global step train is 2627
2019-04-26 19:34:17,776  The loss during training is  :: 0.02636723220348358 
2019-04-26 19:34:17,934  The global step train is 2628
2019-04-26 19:34:18,062  The loss during training is  :: 0.041492950171232224 
2019-04-26 19:34:18,228  The global step train is 2629
2019-04-26 19:34:18,354  The loss during training is  :: 0.0026198450941592455 
2019-04-26 19:34:18,516  The global step train is 2630
2019-04-26 19:34:18,646  The loss during training is  :: 0.036724742501974106 
2019-04-26 19:34:18,817  The global step train is 2631
2019-04-26 19:34:18,952  The loss during training is  :: 0.027240514755249023 
2019-04-26 19:34:19,128  The global step train is 2632
2019-04-26 19:34:19,260  The loss during training is  :: 0.06627798825502396 
2019-04-26 19:34:19,420  The global step train is 2633
2019-04-26 19:34:19,549  The loss during training is  :: 0.08012662827968597 
2019-04-26 19:34:19,714  The global step train is 2634
2019-04-26 19:34:19,842  The loss during training is  :: 0.026136407628655434 
2019-04-26 19:34:20,013  The global step train is 2635
2019-04-26 19:34:20,147  The loss during training is  :: 0.03151093050837517 
2019-04-26 19:34:20,310  The global step train is 2636
2019-04-26 19:34:20,440  The loss during training is  :: 0.058340344578027725 
2019-04-26 19:34:20,597  The global step train is 2637
2019-04-26 19:34:20,725  The loss during training is  :: 0.012815958820283413 
2019-04-26 19:34:20,885  The global step train is 2638
2019-04-26 19:34:21,017  The loss during training is  :: 0.020460696890950203 
2019-04-26 19:34:21,184  The global step train is 2639
2019-04-26 19:34:21,311  The loss during training is  :: 0.012336679734289646 
2019-04-26 19:34:21,473  The global step train is 2640
2019-04-26 19:34:21,603  The loss during training is  :: 0.006346750073134899 
2019-04-26 19:34:21,765  The global step train is 2641
2019-04-26 19:34:21,895  The loss during training is  :: 0.08514592796564102 
2019-04-26 19:34:22,061  The global step train is 2642
2019-04-26 19:34:22,189  The loss during training is  :: 0.02593773603439331 
2019-04-26 19:34:22,355  The global step train is 2643
2019-04-26 19:34:22,482  The loss during training is  :: 0.013355760835111141 
2019-04-26 19:34:22,641  The global step train is 2644
2019-04-26 19:34:22,773  The loss during training is  :: 0.03763800486922264 
2019-04-26 19:34:22,935  The global step train is 2645
2019-04-26 19:34:23,060  The loss during training is  :: 0.003988857381045818 
2019-04-26 19:34:23,222  The global step train is 2646
2019-04-26 19:34:23,352  The loss during training is  :: 0.02284897491335869 
2019-04-26 19:34:23,512  The global step train is 2647
2019-04-26 19:34:23,636  The loss during training is  :: 0.00904836691915989 
2019-04-26 19:34:23,794  The global step train is 2648
2019-04-26 19:34:23,922  The loss during training is  :: 0.023003173992037773 
2019-04-26 19:34:24,086  The global step train is 2649
2019-04-26 19:34:24,216  The loss during training is  :: 0.020863771438598633 
2019-04-26 19:34:24,381  The global step train is 2650
2019-04-26 19:34:24,513  The loss during training is  :: 0.007711909711360931 
2019-04-26 19:34:24,670  The global step train is 2651
2019-04-26 19:34:24,802  The loss during training is  :: 0.017681512981653214 
2019-04-26 19:34:24,965  The global step train is 2652
2019-04-26 19:34:25,095  The loss during training is  :: 0.05356096848845482 
2019-04-26 19:34:25,265  The global step train is 2653
2019-04-26 19:34:25,392  The loss during training is  :: 0.03224175050854683 
2019-04-26 19:34:25,555  The global step train is 2654
2019-04-26 19:34:25,685  The loss during training is  :: 0.04550512880086899 
2019-04-26 19:34:25,851  The global step train is 2655
2019-04-26 19:34:25,984  The loss during training is  :: 0.028117768466472626 
2019-04-26 19:34:26,149  The global step train is 2656
2019-04-26 19:34:26,278  The loss during training is  :: 0.012960989959537983 
2019-04-26 19:34:26,446  The global step train is 2657
2019-04-26 19:34:26,573  The loss during training is  :: 0.05193038284778595 
2019-04-26 19:34:26,739  The global step train is 2658
2019-04-26 19:34:26,863  The loss during training is  :: 0.029050219804048538 
2019-04-26 19:34:27,034  The global step train is 2659
2019-04-26 19:34:27,164  The loss during training is  :: 0.0014510981272906065 
2019-04-26 19:34:27,326  The global step train is 2660
2019-04-26 19:34:27,459  The loss during training is  :: 0.044083401560783386 
2019-04-26 19:34:27,623  The global step train is 2661
2019-04-26 19:34:27,752  The loss during training is  :: 0.004467833787202835 
2019-04-26 19:34:27,923  The global step train is 2662
2019-04-26 19:34:28,056  The loss during training is  :: 0.00925519596785307 
2019-04-26 19:34:28,233  The global step train is 2663
2019-04-26 19:34:28,373  The loss during training is  :: 0.016933733597397804 
2019-04-26 19:34:28,541  The global step train is 2664
2019-04-26 19:34:28,671  The loss during training is  :: 0.020012252032756805 
2019-04-26 19:34:28,834  The global step train is 2665
2019-04-26 19:34:28,965  The loss during training is  :: 0.051282331347465515 
2019-04-26 19:34:29,121  The global step train is 2666
2019-04-26 19:34:29,248  The loss during training is  :: 0.019552571699023247 
2019-04-26 19:34:29,411  The global step train is 2667
2019-04-26 19:34:29,543  The loss during training is  :: 0.01156210619956255 
2019-04-26 19:34:29,701  The global step train is 2668
2019-04-26 19:34:29,832  The loss during training is  :: 0.011443433351814747 
2019-04-26 19:34:29,997  The global step train is 2669
2019-04-26 19:34:30,120  The loss during training is  :: 0.02424544095993042 
2019-04-26 19:34:30,280  The global step train is 2670
2019-04-26 19:34:30,412  The loss during training is  :: 0.03405467048287392 
2019-04-26 19:34:30,576  The global step train is 2671
2019-04-26 19:34:30,708  The loss during training is  :: 0.03791077435016632 
2019-04-26 19:34:30,872  The global step train is 2672
2019-04-26 19:34:31,002  The loss during training is  :: 0.022675469517707825 
2019-04-26 19:34:31,164  The global step train is 2673
2019-04-26 19:34:31,291  The loss during training is  :: 0.06528625637292862 
2019-04-26 19:34:31,452  The global step train is 2674
2019-04-26 19:34:31,579  The loss during training is  :: 0.01529921218752861 
2019-04-26 19:34:31,745  The global step train is 2675
2019-04-26 19:34:31,872  The loss during training is  :: 0.014385986141860485 
2019-04-26 19:34:32,035  The global step train is 2676
2019-04-26 19:34:32,168  The loss during training is  :: 0.01108846627175808 
2019-04-26 19:34:32,326  The global step train is 2677
2019-04-26 19:34:32,452  The loss during training is  :: 0.05505359545350075 
2019-04-26 19:34:32,614  The global step train is 2678
2019-04-26 19:34:32,743  The loss during training is  :: 0.016874827444553375 
2019-04-26 19:34:32,907  The global step train is 2679
2019-04-26 19:34:33,036  The loss during training is  :: 0.08052889257669449 
2019-04-26 19:34:33,199  The global step train is 2680
2019-04-26 19:34:33,329  The loss during training is  :: 0.08801015466451645 
2019-04-26 19:34:33,493  The global step train is 2681
2019-04-26 19:34:33,622  The loss during training is  :: 0.0325356051325798 
2019-04-26 19:34:33,785  The global step train is 2682
2019-04-26 19:34:33,913  The loss during training is  :: 0.010188865475356579 
2019-04-26 19:34:34,073  The global step train is 2683
2019-04-26 19:34:34,208  The loss during training is  :: 0.007693897932767868 
2019-04-26 19:34:34,367  The global step train is 2684
2019-04-26 19:34:34,494  The loss during training is  :: 0.05531004071235657 
2019-04-26 19:34:34,661  The global step train is 2685
2019-04-26 19:34:34,788  The loss during training is  :: 0.009583952836692333 
2019-04-26 19:34:34,951  The global step train is 2686
2019-04-26 19:34:35,080  The loss during training is  :: 0.03256291523575783 
2019-04-26 19:34:35,239  The global step train is 2687
2019-04-26 19:34:35,368  The loss during training is  :: 0.04131166636943817 
2019-04-26 19:34:35,532  The global step train is 2688
2019-04-26 19:34:35,534  Starting evaluation 
2019-04-26 19:34:35,672  The loss during eval_loss is  :: 0.05068384110927582
2019-04-26 19:34:35,674  The global step eval is 617
2019-04-26 19:34:35,802  The loss during eval_loss is  :: 0.03733948618173599
2019-04-26 19:34:35,804  The global step eval is 618
2019-04-26 19:34:35,921  The loss during eval_loss is  :: 0.012804294936358929
2019-04-26 19:34:35,922  The global step eval is 619
2019-04-26 19:34:36,025  The loss during eval_loss is  :: 0.035434089601039886
2019-04-26 19:34:36,027  The global step eval is 620
2019-04-26 19:34:36,148  The loss during eval_loss is  :: 0.057206928730010986
2019-04-26 19:34:36,149  The global step eval is 621
2019-04-26 19:34:36,253  The loss during eval_loss is  :: 0.07792505621910095
2019-04-26 19:34:36,255  The global step eval is 622
2019-04-26 19:34:36,378  The loss during eval_loss is  :: 0.09884101152420044
2019-04-26 19:34:36,380  The global step eval is 623
2019-04-26 19:34:36,489  The loss during eval_loss is  :: 0.0016869481187313795
2019-04-26 19:34:36,491  The global step eval is 624
2019-04-26 19:34:36,605  The loss during eval_loss is  :: 0.06015755981206894
2019-04-26 19:34:36,607  The global step eval is 625
2019-04-26 19:34:36,723  The loss during eval_loss is  :: 0.014938080683350563
2019-04-26 19:34:36,725  The global step eval is 626
2019-04-26 19:34:36,832  The loss during eval_loss is  :: 0.11284998804330826
2019-04-26 19:34:36,833  The global step eval is 627
2019-04-26 19:34:36,959  The loss during eval_loss is  :: 0.03632432594895363
2019-04-26 19:34:36,961  The global step eval is 628
2019-04-26 19:34:37,067  The loss during eval_loss is  :: 0.019297627732157707
2019-04-26 19:34:37,069  The global step eval is 629
2019-04-26 19:34:37,182  The loss during eval_loss is  :: 0.04538266733288765
2019-04-26 19:34:37,184  The global step eval is 630
2019-04-26 19:34:37,289  The loss during eval_loss is  :: 0.02477925270795822
2019-04-26 19:34:37,291  The global step eval is 631
2019-04-26 19:34:37,406  The loss during eval_loss is  :: 0.08567851036787033
2019-04-26 19:34:37,408  The global step eval is 632
2019-04-26 19:34:37,525  The loss during eval_loss is  :: 0.10027167201042175
2019-04-26 19:34:37,527  The global step eval is 633
2019-04-26 19:34:37,638  The loss during eval_loss is  :: 0.10926257073879242
2019-04-26 19:34:37,640  The global step eval is 634
2019-04-26 19:34:37,746  The loss during eval_loss is  :: 0.021715745329856873
2019-04-26 19:34:37,748  The global step eval is 635
2019-04-26 19:34:37,847  The loss during eval_loss is  :: 0.0404808484017849
2019-04-26 19:34:37,849  The global step eval is 636
2019-04-26 19:34:37,973  The loss during eval_loss is  :: 0.07983880490064621
2019-04-26 19:34:37,975  The global step eval is 637
2019-04-26 19:34:38,084  The loss during eval_loss is  :: 0.05984907224774361
2019-04-26 19:34:38,086  The global step eval is 638
2019-04-26 19:34:38,191  The loss during eval_loss is  :: 0.056405067443847656
2019-04-26 19:34:38,193  The global step eval is 639
2019-04-26 19:34:38,306  The loss during eval_loss is  :: 0.043189119547605515
2019-04-26 19:34:38,307  The global step eval is 640
2019-04-26 19:34:38,424  The loss during eval_loss is  :: 0.02414957620203495
2019-04-26 19:34:38,426  The global step eval is 641
2019-04-26 19:34:38,532  The loss during eval_loss is  :: 0.011949444189667702
2019-04-26 19:34:38,534  The global step eval is 642
2019-04-26 19:34:38,638  The loss during eval_loss is  :: 0.030636977404356003
2019-04-26 19:34:38,640  The global step eval is 643
2019-04-26 19:34:38,760  The loss during eval_loss is  :: 0.039345044642686844
2019-04-26 19:34:38,762  The global step eval is 644
2019-04-26 19:34:38,868  The loss during eval_loss is  :: 0.064667247235775
2019-04-26 19:34:38,870  The global step eval is 645
2019-04-26 19:34:38,982  The loss during eval_loss is  :: 0.019159384071826935
2019-04-26 19:34:38,983  The global step eval is 646
2019-04-26 19:34:39,091  The loss during eval_loss is  :: 0.03689376264810562
2019-04-26 19:34:39,092  The global step eval is 647
2019-04-26 19:34:39,215  The loss during eval_loss is  :: 0.0514712892472744
2019-04-26 19:34:39,217  The global step eval is 648
2019-04-26 19:34:39,330  The loss during eval_loss is  :: 0.05559803545475006
2019-04-26 19:34:39,332  The global step eval is 649
2019-04-26 19:34:39,439  The loss during eval_loss is  :: 0.11034010350704193
2019-04-26 19:34:39,441  The global step eval is 650
2019-04-26 19:34:39,549  The loss during eval_loss is  :: 0.025661716237664223
2019-04-26 19:34:39,551  The global step eval is 651
2019-04-26 19:34:39,656  The loss during eval_loss is  :: 0.09378645569086075
2019-04-26 19:34:39,658  The global step eval is 652
2019-04-26 19:34:39,773  The loss during eval_loss is  :: 0.06158389896154404
2019-04-26 19:34:39,775  The global step eval is 653
2019-04-26 19:34:39,887  The loss during eval_loss is  :: 0.05594662204384804
2019-04-26 19:34:39,889  The global step eval is 654
2019-04-26 19:34:40,000  The loss during eval_loss is  :: 0.005109122488647699
2019-04-26 19:34:40,002  The global step eval is 655
2019-04-26 19:34:40,117  The loss during eval_loss is  :: 0.016749979928135872
2019-04-26 19:34:40,119  The global step eval is 656
2019-04-26 19:34:40,227  The loss during eval_loss is  :: 0.02197832614183426
2019-04-26 19:34:40,228  The global step eval is 657
2019-04-26 19:34:40,341  The loss during eval_loss is  :: 0.021930446848273277
2019-04-26 19:34:40,342  The global step eval is 658
2019-04-26 19:34:40,453  The loss during eval_loss is  :: 0.07656003534793854
2019-04-26 19:34:40,455  The global step eval is 659
2019-04-26 19:34:40,575  The loss during eval_loss is  :: 0.03936391323804855
2019-04-26 19:34:40,577  The global step eval is 660
2019-04-26 19:34:40,688  The loss during eval_loss is  :: 0.13912935554981232
2019-04-26 19:34:40,689  The global step eval is 661
2019-04-26 19:34:40,794  The loss during eval_loss is  :: 0.04166857898235321
2019-04-26 19:34:40,796  The global step eval is 662
2019-04-26 19:34:40,910  The loss during eval_loss is  :: 0.09785116463899612
2019-04-26 19:34:40,912  The global step eval is 663
2019-04-26 19:34:41,022  The loss during eval_loss is  :: 0.09787620604038239
2019-04-26 19:34:41,023  The global step eval is 664
2019-04-26 19:34:41,134  The loss during eval_loss is  :: 0.016707325354218483
2019-04-26 19:34:41,136  The global step eval is 665
2019-04-26 19:34:41,251  The loss during eval_loss is  :: 0.08488023281097412
2019-04-26 19:34:41,253  The global step eval is 666
2019-04-26 19:34:41,369  The loss during eval_loss is  :: 0.07243427634239197
2019-04-26 19:34:41,371  The global step eval is 667
2019-04-26 19:34:41,477  The loss during eval_loss is  :: 0.03277306631207466
2019-04-26 19:34:41,480  The global step eval is 668
2019-04-26 19:34:41,586  The loss during eval_loss is  :: 0.02162228524684906
2019-04-26 19:34:41,587  The global step eval is 669
2019-04-26 19:34:41,705  The loss during eval_loss is  :: 0.011648397892713547
2019-04-26 19:34:41,707  The global step eval is 670
2019-04-26 19:34:41,807  The loss during eval_loss is  :: 0.03845848888158798
2019-04-26 19:34:41,808  The global step eval is 671
2019-04-26 19:34:41,918  The loss during eval_loss is  :: 0.048200298100709915
2019-04-26 19:34:41,920  The global step eval is 672
2019-04-26 19:34:41,934  Saved checkpoint: ./trained_model\step_11.pth.tar
2019-04-26 19:34:41,935  Removed checkpoint: ./trained_model\step_11.pth.tar
2019-04-26 19:34:42,043  The loss during training is  :: 0.009785553440451622 
2019-04-26 19:34:42,202  The global step train is 2689
2019-04-26 19:34:42,334  The loss during training is  :: 0.019670069217681885 
2019-04-26 19:34:42,496  The global step train is 2690
2019-04-26 19:34:42,623  The loss during training is  :: 0.005839916877448559 
2019-04-26 19:34:42,782  The global step train is 2691
2019-04-26 19:34:42,912  The loss during training is  :: 0.01894906908273697 
2019-04-26 19:34:43,075  The global step train is 2692
2019-04-26 19:34:43,209  The loss during training is  :: 0.019673557952046394 
2019-04-26 19:34:43,375  The global step train is 2693
2019-04-26 19:34:43,501  The loss during training is  :: 0.007974350824952126 
2019-04-26 19:34:43,664  The global step train is 2694
2019-04-26 19:34:43,796  The loss during training is  :: 0.022315461188554764 
2019-04-26 19:34:43,960  The global step train is 2695
2019-04-26 19:34:44,091  The loss during training is  :: 0.012407118454575539 
2019-04-26 19:34:44,252  The global step train is 2696
2019-04-26 19:34:44,382  The loss during training is  :: 0.008061246946454048 
2019-04-26 19:34:44,552  The global step train is 2697
2019-04-26 19:34:44,687  The loss during training is  :: 0.010789706371724606 
2019-04-26 19:34:44,848  The global step train is 2698
2019-04-26 19:34:44,980  The loss during training is  :: 0.017616109922528267 
2019-04-26 19:34:45,145  The global step train is 2699
2019-04-26 19:34:45,280  The loss during training is  :: 0.023029159754514694 
2019-04-26 19:34:45,441  The global step train is 2700
2019-04-26 19:34:45,576  The loss during training is  :: 0.011107644997537136 
2019-04-26 19:34:45,737  The global step train is 2701
2019-04-26 19:34:45,866  The loss during training is  :: 0.01692146062850952 
2019-04-26 19:34:46,035  The global step train is 2702
2019-04-26 19:34:46,169  The loss during training is  :: 0.007045939564704895 
2019-04-26 19:34:46,335  The global step train is 2703
2019-04-26 19:34:46,463  The loss during training is  :: 0.014578863978385925 
2019-04-26 19:34:46,627  The global step train is 2704
2019-04-26 19:34:46,760  The loss during training is  :: 0.027748120948672295 
2019-04-26 19:34:46,921  The global step train is 2705
2019-04-26 19:34:47,052  The loss during training is  :: 0.015698522329330444 
2019-04-26 19:34:47,213  The global step train is 2706
2019-04-26 19:34:47,338  The loss during training is  :: 0.020564435049891472 
2019-04-26 19:34:47,513  The global step train is 2707
2019-04-26 19:34:47,642  The loss during training is  :: 0.012262261472642422 
2019-04-26 19:34:47,802  The global step train is 2708
2019-04-26 19:34:47,928  The loss during training is  :: 0.006711301859468222 
2019-04-26 19:34:48,091  The global step train is 2709
2019-04-26 19:34:48,224  The loss during training is  :: 0.011108353734016418 
2019-04-26 19:34:48,388  The global step train is 2710
2019-04-26 19:34:48,517  The loss during training is  :: 0.008489694446325302 
2019-04-26 19:34:48,676  The global step train is 2711
2019-04-26 19:34:48,806  The loss during training is  :: 0.026272015646100044 
2019-04-26 19:34:48,968  The global step train is 2712
2019-04-26 19:34:49,098  The loss during training is  :: 0.0627962052822113 
2019-04-26 19:34:49,268  The global step train is 2713
2019-04-26 19:34:49,399  The loss during training is  :: 0.012476981617510319 
2019-04-26 19:34:49,561  The global step train is 2714
2019-04-26 19:34:49,694  The loss during training is  :: 0.02461841329932213 
2019-04-26 19:34:49,854  The global step train is 2715
2019-04-26 19:34:49,989  The loss during training is  :: 0.04364732280373573 
2019-04-26 19:34:50,152  The global step train is 2716
2019-04-26 19:34:50,287  The loss during training is  :: 0.022042149677872658 
2019-04-26 19:34:50,461  The global step train is 2717
2019-04-26 19:34:50,596  The loss during training is  :: 0.021554235368967056 
2019-04-26 19:34:50,760  The global step train is 2718
2019-04-26 19:34:50,892  The loss during training is  :: 0.012293383479118347 
2019-04-26 19:34:51,058  The global step train is 2719
2019-04-26 19:34:51,194  The loss during training is  :: 0.005972118582576513 
2019-04-26 19:34:51,355  The global step train is 2720
2019-04-26 19:34:51,481  The loss during training is  :: 0.04361283406615257 
2019-04-26 19:34:51,642  The global step train is 2721
2019-04-26 19:34:51,773  The loss during training is  :: 0.012919041328132153 
2019-04-26 19:34:51,933  The global step train is 2722
2019-04-26 19:34:52,074  The loss during training is  :: 0.026785356923937798 
2019-04-26 19:34:52,242  The global step train is 2723
2019-04-26 19:34:52,373  The loss during training is  :: 0.019007276743650436 
2019-04-26 19:34:52,538  The global step train is 2724
2019-04-26 19:34:52,669  The loss during training is  :: 0.012532790191471577 
2019-04-26 19:34:52,836  The global step train is 2725
2019-04-26 19:34:52,963  The loss during training is  :: 0.03808850422501564 
2019-04-26 19:34:53,127  The global step train is 2726
2019-04-26 19:34:53,256  The loss during training is  :: 0.006895545404404402 
2019-04-26 19:34:53,421  The global step train is 2727
2019-04-26 19:34:53,554  The loss during training is  :: 0.007460994645953178 
2019-04-26 19:34:53,713  The global step train is 2728
2019-04-26 19:34:53,840  The loss during training is  :: 0.01732044853270054 
2019-04-26 19:34:54,002  The global step train is 2729
2019-04-26 19:34:54,133  The loss during training is  :: 0.005020453128963709 
2019-04-26 19:34:54,294  The global step train is 2730
2019-04-26 19:34:54,422  The loss during training is  :: 0.0010386848589405417 
2019-04-26 19:34:54,584  The global step train is 2731
2019-04-26 19:34:54,716  The loss during training is  :: 0.016846291720867157 
2019-04-26 19:34:54,883  The global step train is 2732
2019-04-26 19:34:55,011  The loss during training is  :: 0.010182450525462627 
2019-04-26 19:34:55,182  The global step train is 2733
2019-04-26 19:34:55,320  The loss during training is  :: 0.05310454219579697 
2019-04-26 19:34:55,488  The global step train is 2734
2019-04-26 19:34:55,620  The loss during training is  :: 0.05587843433022499 
2019-04-26 19:34:55,784  The global step train is 2735
2019-04-26 19:34:55,916  The loss during training is  :: 0.0225988682359457 
2019-04-26 19:34:56,079  The global step train is 2736
2019-04-26 19:34:56,213  The loss during training is  :: 0.019956471398472786 
2019-04-26 19:34:56,375  The global step train is 2737
2019-04-26 19:34:56,505  The loss during training is  :: 0.014770510606467724 
2019-04-26 19:34:56,667  The global step train is 2738
2019-04-26 19:34:56,797  The loss during training is  :: 0.009564266540110111 
2019-04-26 19:34:56,959  The global step train is 2739
2019-04-26 19:34:57,092  The loss during training is  :: 0.04506450518965721 
2019-04-26 19:34:57,254  The global step train is 2740
2019-04-26 19:34:57,384  The loss during training is  :: 0.02415160834789276 
2019-04-26 19:34:57,546  The global step train is 2741
2019-04-26 19:34:57,678  The loss during training is  :: 0.04214194044470787 
2019-04-26 19:34:57,845  The global step train is 2742
2019-04-26 19:34:57,971  The loss during training is  :: 0.03018775023519993 
2019-04-26 19:34:58,134  The global step train is 2743
2019-04-26 19:34:58,274  The loss during training is  :: 0.007273743860423565 
2019-04-26 19:34:58,459  The global step train is 2744
2019-04-26 19:34:58,584  The loss during training is  :: 0.007936124689877033 
2019-04-26 19:34:58,751  The global step train is 2745
2019-04-26 19:34:58,883  The loss during training is  :: 0.01820233091711998 
2019-04-26 19:34:59,056  The global step train is 2746
2019-04-26 19:34:59,190  The loss during training is  :: 0.007908254861831665 
2019-04-26 19:34:59,357  The global step train is 2747
2019-04-26 19:34:59,490  The loss during training is  :: 0.019586753100156784 
2019-04-26 19:34:59,653  The global step train is 2748
2019-04-26 19:34:59,785  The loss during training is  :: 0.015753958374261856 
2019-04-26 19:34:59,944  The global step train is 2749
2019-04-26 19:35:00,081  The loss during training is  :: 0.0026550611946731806 
2019-04-26 19:35:00,259  The global step train is 2750
2019-04-26 19:35:00,385  The loss during training is  :: 0.02393638901412487 
2019-04-26 19:35:00,556  The global step train is 2751
2019-04-26 19:35:00,680  The loss during training is  :: 0.05003971606492996 
2019-04-26 19:35:00,846  The global step train is 2752
2019-04-26 19:35:00,976  The loss during training is  :: 0.03198728710412979 
2019-04-26 19:35:01,143  The global step train is 2753
2019-04-26 19:35:01,274  The loss during training is  :: 0.006217857822775841 
2019-04-26 19:35:01,433  The global step train is 2754
2019-04-26 19:35:01,563  The loss during training is  :: 0.011143369600176811 
2019-04-26 19:35:01,725  The global step train is 2755
2019-04-26 19:35:01,854  The loss during training is  :: 0.01522087398916483 
2019-04-26 19:35:02,019  The global step train is 2756
2019-04-26 19:35:02,153  The loss during training is  :: 0.010503683239221573 
2019-04-26 19:35:02,318  The global step train is 2757
2019-04-26 19:35:02,452  The loss during training is  :: 0.04983430355787277 
2019-04-26 19:35:02,616  The global step train is 2758
2019-04-26 19:35:02,743  The loss during training is  :: 0.03188340365886688 
2019-04-26 19:35:02,903  The global step train is 2759
2019-04-26 19:35:03,038  The loss during training is  :: 0.002249453915283084 
2019-04-26 19:35:03,204  The global step train is 2760
2019-04-26 19:35:03,335  The loss during training is  :: 0.014178253710269928 
2019-04-26 19:35:03,494  The global step train is 2761
2019-04-26 19:35:03,629  The loss during training is  :: 0.010786171071231365 
2019-04-26 19:35:03,787  The global step train is 2762
2019-04-26 19:35:03,920  The loss during training is  :: 0.002635793760418892 
2019-04-26 19:35:04,084  The global step train is 2763
2019-04-26 19:35:04,217  The loss during training is  :: 0.02027306891977787 
2019-04-26 19:35:04,384  The global step train is 2764
2019-04-26 19:35:04,514  The loss during training is  :: 0.02007039450109005 
2019-04-26 19:35:04,676  The global step train is 2765
2019-04-26 19:35:04,809  The loss during training is  :: 0.017893796786665916 
2019-04-26 19:35:04,975  The global step train is 2766
2019-04-26 19:35:05,102  The loss during training is  :: 0.026833366602659225 
2019-04-26 19:35:05,263  The global step train is 2767
2019-04-26 19:35:05,396  The loss during training is  :: 0.0063073476776480675 
2019-04-26 19:35:05,561  The global step train is 2768
2019-04-26 19:35:05,688  The loss during training is  :: 0.0209523793309927 
2019-04-26 19:35:05,851  The global step train is 2769
2019-04-26 19:35:05,982  The loss during training is  :: 0.011990861967206001 
2019-04-26 19:35:06,146  The global step train is 2770
2019-04-26 19:35:06,280  The loss during training is  :: 0.027251090854406357 
2019-04-26 19:35:06,438  The global step train is 2771
2019-04-26 19:35:06,568  The loss during training is  :: 0.020839912816882133 
2019-04-26 19:35:06,740  The global step train is 2772
2019-04-26 19:35:06,869  The loss during training is  :: 0.013364534825086594 
2019-04-26 19:35:07,032  The global step train is 2773
2019-04-26 19:35:07,162  The loss during training is  :: 0.021780377253890038 
2019-04-26 19:35:07,322  The global step train is 2774
2019-04-26 19:35:07,449  The loss during training is  :: 0.008608970791101456 
2019-04-26 19:35:07,611  The global step train is 2775
2019-04-26 19:35:07,739  The loss during training is  :: 0.013331145979464054 
2019-04-26 19:35:07,901  The global step train is 2776
2019-04-26 19:35:08,035  The loss during training is  :: 0.03064436838030815 
2019-04-26 19:35:08,207  The global step train is 2777
2019-04-26 19:35:08,338  The loss during training is  :: 0.013995157554745674 
2019-04-26 19:35:08,513  The global step train is 2778
2019-04-26 19:35:08,646  The loss during training is  :: 0.00829821266233921 
2019-04-26 19:35:08,812  The global step train is 2779
2019-04-26 19:35:08,946  The loss during training is  :: 0.008461052551865578 
2019-04-26 19:35:09,110  The global step train is 2780
2019-04-26 19:35:09,241  The loss during training is  :: 0.016019200906157494 
2019-04-26 19:35:09,403  The global step train is 2781
2019-04-26 19:35:09,532  The loss during training is  :: 0.03139512985944748 
2019-04-26 19:35:09,694  The global step train is 2782
2019-04-26 19:35:09,826  The loss during training is  :: 0.03258047625422478 
2019-04-26 19:35:09,992  The global step train is 2783
2019-04-26 19:35:10,126  The loss during training is  :: 0.024923546239733696 
2019-04-26 19:35:10,288  The global step train is 2784
2019-04-26 19:35:10,418  The loss during training is  :: 0.009927259758114815 
2019-04-26 19:35:10,583  The global step train is 2785
2019-04-26 19:35:10,717  The loss during training is  :: 0.02331319823861122 
2019-04-26 19:35:10,876  The global step train is 2786
2019-04-26 19:35:11,007  The loss during training is  :: 0.0176100917160511 
2019-04-26 19:35:11,168  The global step train is 2787
2019-04-26 19:35:11,299  The loss during training is  :: 0.014558105729520321 
2019-04-26 19:35:11,461  The global step train is 2788
2019-04-26 19:35:11,588  The loss during training is  :: 0.030273959040641785 
2019-04-26 19:35:11,753  The global step train is 2789
2019-04-26 19:35:11,879  The loss during training is  :: 0.011266505345702171 
2019-04-26 19:35:12,048  The global step train is 2790
2019-04-26 19:35:12,181  The loss during training is  :: 0.036857184022665024 
2019-04-26 19:35:12,344  The global step train is 2791
2019-04-26 19:35:12,473  The loss during training is  :: 0.016978062689304352 
2019-04-26 19:35:12,635  The global step train is 2792
2019-04-26 19:35:12,764  The loss during training is  :: 0.03602968156337738 
2019-04-26 19:35:12,924  The global step train is 2793
2019-04-26 19:35:13,051  The loss during training is  :: 0.012820237316191196 
2019-04-26 19:35:13,217  The global step train is 2794
2019-04-26 19:35:13,346  The loss during training is  :: 0.018328431993722916 
2019-04-26 19:35:13,515  The global step train is 2795
2019-04-26 19:35:13,645  The loss during training is  :: 0.020611489191651344 
2019-04-26 19:35:13,802  The global step train is 2796
2019-04-26 19:35:13,931  The loss during training is  :: 0.0049254861660301685 
2019-04-26 19:35:14,095  The global step train is 2797
2019-04-26 19:35:14,227  The loss during training is  :: 0.00627001142129302 
2019-04-26 19:35:14,390  The global step train is 2798
2019-04-26 19:35:14,521  The loss during training is  :: 0.0074044386856257915 
2019-04-26 19:35:14,692  The global step train is 2799
2019-04-26 19:35:14,825  The loss during training is  :: 0.014781706966459751 
2019-04-26 19:35:14,989  The global step train is 2800
2019-04-26 19:35:15,120  The loss during training is  :: 0.01681232452392578 
2019-04-26 19:35:15,282  The global step train is 2801
2019-04-26 19:35:15,417  The loss during training is  :: 0.013300835154950619 
2019-04-26 19:35:15,579  The global step train is 2802
2019-04-26 19:35:15,723  The loss during training is  :: 0.015044406056404114 
2019-04-26 19:35:15,900  The global step train is 2803
2019-04-26 19:35:16,051  The loss during training is  :: 0.018121300265192986 
2019-04-26 19:35:16,235  The global step train is 2804
2019-04-26 19:35:16,383  The loss during training is  :: 0.001453040400519967 
2019-04-26 19:35:16,559  The global step train is 2805
2019-04-26 19:35:16,710  The loss during training is  :: 0.005524082109332085 
2019-04-26 19:35:16,914  The global step train is 2806
2019-04-26 19:35:17,076  The loss during training is  :: 0.021211031824350357 
2019-04-26 19:35:17,256  The global step train is 2807
2019-04-26 19:35:17,406  The loss during training is  :: 0.00627277372404933 
2019-04-26 19:35:17,573  The global step train is 2808
2019-04-26 19:35:17,702  The loss during training is  :: 0.014474020339548588 
2019-04-26 19:35:17,869  The global step train is 2809
2019-04-26 19:35:18,002  The loss during training is  :: 0.010930023156106472 
2019-04-26 19:35:18,176  The global step train is 2810
2019-04-26 19:35:18,306  The loss during training is  :: 0.02207433618605137 
2019-04-26 19:35:18,474  The global step train is 2811
2019-04-26 19:35:18,612  The loss during training is  :: 0.005658397451043129 
2019-04-26 19:35:18,775  The global step train is 2812
2019-04-26 19:35:18,912  The loss during training is  :: 0.01473904587328434 
2019-04-26 19:35:19,088  The global step train is 2813
2019-04-26 19:35:19,229  The loss during training is  :: 0.04871341586112976 
2019-04-26 19:35:19,405  The global step train is 2814
2019-04-26 19:35:19,546  The loss during training is  :: 0.037414632737636566 
2019-04-26 19:35:19,712  The global step train is 2815
2019-04-26 19:35:19,886  The loss during training is  :: 0.011000770144164562 
2019-04-26 19:35:20,064  The global step train is 2816
2019-04-26 19:35:20,204  The loss during training is  :: 0.03945830836892128 
2019-04-26 19:35:20,376  The global step train is 2817
2019-04-26 19:35:20,517  The loss during training is  :: 0.02712234854698181 
2019-04-26 19:35:20,689  The global step train is 2818
2019-04-26 19:35:20,826  The loss during training is  :: 0.028973296284675598 
2019-04-26 19:35:20,992  The global step train is 2819
2019-04-26 19:35:21,123  The loss during training is  :: 0.04980049282312393 
2019-04-26 19:35:21,287  The global step train is 2820
2019-04-26 19:35:21,421  The loss during training is  :: 0.02289615385234356 
2019-04-26 19:35:21,583  The global step train is 2821
2019-04-26 19:35:21,715  The loss during training is  :: 0.00570698082447052 
2019-04-26 19:35:21,880  The global step train is 2822
2019-04-26 19:35:22,008  The loss during training is  :: 0.011865726672112942 
2019-04-26 19:35:22,174  The global step train is 2823
2019-04-26 19:35:22,304  The loss during training is  :: 0.007056655827909708 
2019-04-26 19:35:22,470  The global step train is 2824
2019-04-26 19:35:22,605  The loss during training is  :: 0.030118698254227638 
2019-04-26 19:35:22,776  The global step train is 2825
2019-04-26 19:35:22,918  The loss during training is  :: 0.015790071338415146 
2019-04-26 19:35:23,089  The global step train is 2826
2019-04-26 19:35:23,231  The loss during training is  :: 0.028020719066262245 
2019-04-26 19:35:23,409  The global step train is 2827
2019-04-26 19:35:23,550  The loss during training is  :: 0.006714722141623497 
2019-04-26 19:35:23,725  The global step train is 2828
2019-04-26 19:35:23,865  The loss during training is  :: 0.03972692787647247 
2019-04-26 19:35:24,036  The global step train is 2829
2019-04-26 19:35:24,173  The loss during training is  :: 0.02568461187183857 
2019-04-26 19:35:24,336  The global step train is 2830
2019-04-26 19:35:24,469  The loss during training is  :: 0.004042561631649733 
2019-04-26 19:35:24,630  The global step train is 2831
2019-04-26 19:35:24,762  The loss during training is  :: 0.027995677664875984 
2019-04-26 19:35:24,930  The global step train is 2832
2019-04-26 19:35:25,061  The loss during training is  :: 0.009504115208983421 
2019-04-26 19:35:25,224  The global step train is 2833
2019-04-26 19:35:25,360  The loss during training is  :: 0.033036284148693085 
2019-04-26 19:35:25,525  The global step train is 2834
2019-04-26 19:35:25,660  The loss during training is  :: 0.0715370625257492 
2019-04-26 19:35:25,824  The global step train is 2835
2019-04-26 19:35:25,958  The loss during training is  :: 0.015927337110042572 
2019-04-26 19:35:26,132  The global step train is 2836
2019-04-26 19:35:26,264  The loss during training is  :: 0.013885879889130592 
2019-04-26 19:35:26,425  The global step train is 2837
2019-04-26 19:35:26,561  The loss during training is  :: 0.007391172926872969 
2019-04-26 19:35:26,727  The global step train is 2838
2019-04-26 19:35:26,863  The loss during training is  :: 0.019743366166949272 
2019-04-26 19:35:27,023  The global step train is 2839
2019-04-26 19:35:27,155  The loss during training is  :: 0.018533432856202126 
2019-04-26 19:35:27,321  The global step train is 2840
2019-04-26 19:35:27,455  The loss during training is  :: 0.013302278704941273 
2019-04-26 19:35:27,622  The global step train is 2841
2019-04-26 19:35:27,756  The loss during training is  :: 0.05165316164493561 
2019-04-26 19:35:27,923  The global step train is 2842
2019-04-26 19:35:28,058  The loss during training is  :: 0.027084290981292725 
2019-04-26 19:35:28,260  The global step train is 2843
2019-04-26 19:35:28,411  The loss during training is  :: 0.045642755925655365 
2019-04-26 19:35:28,581  The global step train is 2844
2019-04-26 19:35:28,715  The loss during training is  :: 0.013489567674696445 
2019-04-26 19:35:28,875  The global step train is 2845
2019-04-26 19:35:29,010  The loss during training is  :: 0.02828803099691868 
2019-04-26 19:35:29,178  The global step train is 2846
2019-04-26 19:35:29,303  The loss during training is  :: 0.0361868254840374 
2019-04-26 19:35:29,468  The global step train is 2847
2019-04-26 19:35:29,595  The loss during training is  :: 0.02720307931303978 
2019-04-26 19:35:29,764  The global step train is 2848
2019-04-26 19:35:29,899  The loss during training is  :: 0.048744089901447296 
2019-04-26 19:35:30,069  The global step train is 2849
2019-04-26 19:35:30,199  The loss during training is  :: 0.01735166274011135 
2019-04-26 19:35:30,364  The global step train is 2850
2019-04-26 19:35:30,499  The loss during training is  :: 0.012126000598073006 
2019-04-26 19:35:30,657  The global step train is 2851
2019-04-26 19:35:30,789  The loss during training is  :: 0.008448461070656776 
2019-04-26 19:35:30,957  The global step train is 2852
2019-04-26 19:35:31,091  The loss during training is  :: 0.007087735924869776 
2019-04-26 19:35:31,257  The global step train is 2853
2019-04-26 19:35:31,391  The loss during training is  :: 0.020795904099941254 
2019-04-26 19:35:31,553  The global step train is 2854
2019-04-26 19:35:31,688  The loss during training is  :: 0.0093377148732543 
2019-04-26 19:35:31,848  The global step train is 2855
2019-04-26 19:35:31,979  The loss during training is  :: 0.015772990882396698 
2019-04-26 19:35:32,148  The global step train is 2856
2019-04-26 19:35:32,280  The loss during training is  :: 0.013745883479714394 
2019-04-26 19:35:32,443  The global step train is 2857
2019-04-26 19:35:32,580  The loss during training is  :: 0.04086865112185478 
2019-04-26 19:35:32,751  The global step train is 2858
2019-04-26 19:35:32,880  The loss during training is  :: 0.013404308818280697 
2019-04-26 19:35:33,049  The global step train is 2859
2019-04-26 19:35:33,177  The loss during training is  :: 0.006512199994176626 
2019-04-26 19:35:33,343  The global step train is 2860
2019-04-26 19:35:33,477  The loss during training is  :: 0.02196536399424076 
2019-04-26 19:35:33,645  The global step train is 2861
2019-04-26 19:35:33,777  The loss during training is  :: 0.02450796216726303 
2019-04-26 19:35:33,939  The global step train is 2862
2019-04-26 19:35:34,072  The loss during training is  :: 0.019626474007964134 
2019-04-26 19:35:34,243  The global step train is 2863
2019-04-26 19:35:34,372  The loss during training is  :: 0.017525408416986465 
2019-04-26 19:35:34,537  The global step train is 2864
2019-04-26 19:35:34,671  The loss during training is  :: 0.0157758928835392 
2019-04-26 19:35:34,835  The global step train is 2865
2019-04-26 19:35:34,964  The loss during training is  :: 0.006129957735538483 
2019-04-26 19:35:35,132  The global step train is 2866
2019-04-26 19:35:35,268  The loss during training is  :: 0.009895745664834976 
2019-04-26 19:35:35,446  The global step train is 2867
2019-04-26 19:35:35,580  The loss during training is  :: 0.006736233830451965 
2019-04-26 19:35:35,747  The global step train is 2868
2019-04-26 19:35:35,880  The loss during training is  :: 0.020019037649035454 
2019-04-26 19:35:36,044  The global step train is 2869
2019-04-26 19:35:36,178  The loss during training is  :: 0.010531933978199959 
2019-04-26 19:35:36,351  The global step train is 2870
2019-04-26 19:35:36,486  The loss during training is  :: 0.05151231959462166 
2019-04-26 19:35:36,646  The global step train is 2871
2019-04-26 19:35:36,781  The loss during training is  :: 0.028649235144257545 
2019-04-26 19:35:36,944  The global step train is 2872
2019-04-26 19:35:37,078  The loss during training is  :: 0.07469083368778229 
2019-04-26 19:35:37,248  The global step train is 2873
2019-04-26 19:35:37,378  The loss during training is  :: 0.01802745833992958 
2019-04-26 19:35:37,543  The global step train is 2874
2019-04-26 19:35:37,676  The loss during training is  :: 0.002236350439488888 
2019-04-26 19:35:37,845  The global step train is 2875
2019-04-26 19:35:37,981  The loss during training is  :: 0.019863298162817955 
2019-04-26 19:35:38,147  The global step train is 2876
2019-04-26 19:35:38,283  The loss during training is  :: 0.035703107714653015 
2019-04-26 19:35:38,456  The global step train is 2877
2019-04-26 19:35:38,590  The loss during training is  :: 0.00575252203270793 
2019-04-26 19:35:38,758  The global step train is 2878
2019-04-26 19:35:38,901  The loss during training is  :: 0.0032577926758676767 
2019-04-26 19:35:39,079  The global step train is 2879
2019-04-26 19:35:39,221  The loss during training is  :: 0.021723667159676552 
2019-04-26 19:35:39,393  The global step train is 2880
2019-04-26 19:35:39,531  The loss during training is  :: 0.0993647426366806 
2019-04-26 19:35:39,707  The global step train is 2881
2019-04-26 19:35:39,858  The loss during training is  :: 0.02450553886592388 
2019-04-26 19:35:40,042  The global step train is 2882
2019-04-26 19:35:40,192  The loss during training is  :: 0.006029059179127216 
2019-04-26 19:35:40,375  The global step train is 2883
2019-04-26 19:35:40,519  The loss during training is  :: 0.007584467064589262 
2019-04-26 19:35:40,686  The global step train is 2884
2019-04-26 19:35:40,820  The loss during training is  :: 0.008625071495771408 
2019-04-26 19:35:40,984  The global step train is 2885
2019-04-26 19:35:41,114  The loss during training is  :: 0.04707653075456619 
2019-04-26 19:35:41,281  The global step train is 2886
2019-04-26 19:35:41,417  The loss during training is  :: 0.01721157319843769 
2019-04-26 19:35:41,586  The global step train is 2887
2019-04-26 19:35:41,724  The loss during training is  :: 0.015376167371869087 
2019-04-26 19:35:41,889  The global step train is 2888
2019-04-26 19:35:42,020  The loss during training is  :: 0.02689962089061737 
2019-04-26 19:35:42,181  The global step train is 2889
2019-04-26 19:35:42,317  The loss during training is  :: 0.02752586081624031 
2019-04-26 19:35:42,482  The global step train is 2890
2019-04-26 19:35:42,609  The loss during training is  :: 0.019259966909885406 
2019-04-26 19:35:42,774  The global step train is 2891
2019-04-26 19:35:42,902  The loss during training is  :: 0.03822594881057739 
2019-04-26 19:35:43,060  The global step train is 2892
2019-04-26 19:35:43,194  The loss during training is  :: 0.03470509871840477 
2019-04-26 19:35:43,357  The global step train is 2893
2019-04-26 19:35:43,493  The loss during training is  :: 0.02016609162092209 
2019-04-26 19:35:43,664  The global step train is 2894
2019-04-26 19:35:43,810  The loss during training is  :: 0.06372750550508499 
2019-04-26 19:35:43,992  The global step train is 2895
2019-04-26 19:35:44,142  The loss during training is  :: 0.1747598648071289 
2019-04-26 19:35:44,327  The global step train is 2896
2019-04-26 19:35:44,475  The loss during training is  :: 0.009782730601727962 
2019-04-26 19:35:44,647  The global step train is 2897
2019-04-26 19:35:44,782  The loss during training is  :: 0.01154808048158884 
2019-04-26 19:35:44,943  The global step train is 2898
2019-04-26 19:35:45,076  The loss during training is  :: 0.010438397526741028 
2019-04-26 19:35:45,245  The global step train is 2899
2019-04-26 19:35:45,380  The loss during training is  :: 0.040540024638175964 
2019-04-26 19:35:45,542  The global step train is 2900
2019-04-26 19:35:45,673  The loss during training is  :: 0.028919648379087448 
2019-04-26 19:35:45,840  The global step train is 2901
2019-04-26 19:35:45,974  The loss during training is  :: 0.004847186617553234 
2019-04-26 19:35:46,140  The global step train is 2902
2019-04-26 19:35:46,277  The loss during training is  :: 0.03137510269880295 
2019-04-26 19:35:46,450  The global step train is 2903
2019-04-26 19:35:46,591  The loss during training is  :: 0.026027819141745567 
2019-04-26 19:35:46,770  The global step train is 2904
2019-04-26 19:35:46,917  The loss during training is  :: 0.00301926932297647 
2019-04-26 19:35:47,077  The global step train is 2905
2019-04-26 19:35:47,210  The loss during training is  :: 0.01876731589436531 
2019-04-26 19:35:47,371  The global step train is 2906
2019-04-26 19:35:47,506  The loss during training is  :: 0.03403801843523979 
2019-04-26 19:35:47,683  The global step train is 2907
2019-04-26 19:35:47,829  The loss during training is  :: 0.030137697234749794 
2019-04-26 19:35:48,004  The global step train is 2908
2019-04-26 19:35:48,147  The loss during training is  :: 0.024342142045497894 
2019-04-26 19:35:48,333  The global step train is 2909
2019-04-26 19:35:48,472  The loss during training is  :: 0.011233905330300331 
2019-04-26 19:35:48,647  The global step train is 2910
2019-04-26 19:35:48,780  The loss during training is  :: 0.01667793281376362 
2019-04-26 19:35:48,942  The global step train is 2911
2019-04-26 19:35:49,078  The loss during training is  :: 0.04414001479744911 
2019-04-26 19:35:49,240  The global step train is 2912
2019-04-26 19:35:49,243  Starting evaluation 
2019-04-26 19:35:49,385  The loss during eval_loss is  :: 0.054945189505815506
2019-04-26 19:35:49,387  The global step eval is 673
2019-04-26 19:35:49,516  The loss during eval_loss is  :: 0.03549951687455177
2019-04-26 19:35:49,517  The global step eval is 674
2019-04-26 19:35:49,627  The loss during eval_loss is  :: 0.026660000905394554
2019-04-26 19:35:49,629  The global step eval is 675
2019-04-26 19:35:49,740  The loss during eval_loss is  :: 0.014875955879688263
2019-04-26 19:35:49,742  The global step eval is 676
2019-04-26 19:35:49,858  The loss during eval_loss is  :: 0.051078420132398605
2019-04-26 19:35:49,860  The global step eval is 677
2019-04-26 19:35:49,976  The loss during eval_loss is  :: 0.05335088074207306
2019-04-26 19:35:49,978  The global step eval is 678
2019-04-26 19:35:50,081  The loss during eval_loss is  :: 0.10167708992958069
2019-04-26 19:35:50,083  The global step eval is 679
2019-04-26 19:35:50,204  The loss during eval_loss is  :: 0.007884063757956028
2019-04-26 19:35:50,206  The global step eval is 680
2019-04-26 19:35:50,331  The loss during eval_loss is  :: 0.07831940799951553
2019-04-26 19:35:50,333  The global step eval is 681
2019-04-26 19:35:50,447  The loss during eval_loss is  :: 0.03027934394776821
2019-04-26 19:35:50,449  The global step eval is 682
2019-04-26 19:35:50,562  The loss during eval_loss is  :: 0.07991290092468262
2019-04-26 19:35:50,563  The global step eval is 683
2019-04-26 19:35:50,679  The loss during eval_loss is  :: 0.043645553290843964
2019-04-26 19:35:50,681  The global step eval is 684
2019-04-26 19:35:50,793  The loss during eval_loss is  :: 0.028674162924289703
2019-04-26 19:35:50,795  The global step eval is 685
2019-04-26 19:35:50,906  The loss during eval_loss is  :: 0.05418037250638008
2019-04-26 19:35:50,908  The global step eval is 686
2019-04-26 19:35:51,023  The loss during eval_loss is  :: 0.036031562834978104
2019-04-26 19:35:51,025  The global step eval is 687
2019-04-26 19:35:51,137  The loss during eval_loss is  :: 0.06778684258460999
2019-04-26 19:35:51,139  The global step eval is 688
2019-04-26 19:35:51,249  The loss during eval_loss is  :: 0.0966721773147583
2019-04-26 19:35:51,251  The global step eval is 689
2019-04-26 19:35:51,368  The loss during eval_loss is  :: 0.15359924733638763
2019-04-26 19:35:51,370  The global step eval is 690
2019-04-26 19:35:51,472  The loss during eval_loss is  :: 0.05315296724438667
2019-04-26 19:35:51,474  The global step eval is 691
2019-04-26 19:35:51,591  The loss during eval_loss is  :: 0.06811440736055374
2019-04-26 19:35:51,594  The global step eval is 692
2019-04-26 19:35:51,705  The loss during eval_loss is  :: 0.09301598370075226
2019-04-26 19:35:51,707  The global step eval is 693
2019-04-26 19:35:51,814  The loss during eval_loss is  :: 0.09019625186920166
2019-04-26 19:35:51,816  The global step eval is 694
2019-04-26 19:35:51,922  The loss during eval_loss is  :: 0.0379011407494545
2019-04-26 19:35:51,924  The global step eval is 695
2019-04-26 19:35:52,029  The loss during eval_loss is  :: 0.016368480399250984
2019-04-26 19:35:52,031  The global step eval is 696
2019-04-26 19:35:52,138  The loss during eval_loss is  :: 0.03774367645382881
2019-04-26 19:35:52,140  The global step eval is 697
2019-04-26 19:35:52,259  The loss during eval_loss is  :: 0.01403403002768755
2019-04-26 19:35:52,261  The global step eval is 698
2019-04-26 19:35:52,365  The loss during eval_loss is  :: 0.02960743010044098
2019-04-26 19:35:52,366  The global step eval is 699
2019-04-26 19:35:52,483  The loss during eval_loss is  :: 0.050756268203258514
2019-04-26 19:35:52,486  The global step eval is 700
2019-04-26 19:35:52,595  The loss during eval_loss is  :: 0.06029434874653816
2019-04-26 19:35:52,597  The global step eval is 701
2019-04-26 19:35:52,701  The loss during eval_loss is  :: 0.051600731909275055
2019-04-26 19:35:52,703  The global step eval is 702
2019-04-26 19:35:52,819  The loss during eval_loss is  :: 0.02636425383388996
2019-04-26 19:35:52,821  The global step eval is 703
2019-04-26 19:35:52,934  The loss during eval_loss is  :: 0.06983714550733566
2019-04-26 19:35:52,936  The global step eval is 704
2019-04-26 19:35:53,056  The loss during eval_loss is  :: 0.06402802467346191
2019-04-26 19:35:53,058  The global step eval is 705
2019-04-26 19:35:53,171  The loss during eval_loss is  :: 0.09069301187992096
2019-04-26 19:35:53,173  The global step eval is 706
2019-04-26 19:35:53,287  The loss during eval_loss is  :: 0.03265733644366264
2019-04-26 19:35:53,289  The global step eval is 707
2019-04-26 19:35:53,404  The loss during eval_loss is  :: 0.13261695206165314
2019-04-26 19:35:53,406  The global step eval is 708
2019-04-26 19:35:53,507  The loss during eval_loss is  :: 0.0705217644572258
2019-04-26 19:35:53,508  The global step eval is 709
2019-04-26 19:35:53,623  The loss during eval_loss is  :: 0.05072597414255142
2019-04-26 19:35:53,625  The global step eval is 710
2019-04-26 19:35:53,735  The loss during eval_loss is  :: 0.009608812630176544
2019-04-26 19:35:53,737  The global step eval is 711
2019-04-26 19:35:53,847  The loss during eval_loss is  :: 0.01437216717749834
2019-04-26 19:35:53,849  The global step eval is 712
2019-04-26 19:35:53,952  The loss during eval_loss is  :: 0.03181125223636627
2019-04-26 19:35:53,954  The global step eval is 713
2019-04-26 19:35:54,079  The loss during eval_loss is  :: 0.03834160789847374
2019-04-26 19:35:54,081  The global step eval is 714
2019-04-26 19:35:54,200  The loss during eval_loss is  :: 0.08871684223413467
2019-04-26 19:35:54,202  The global step eval is 715
2019-04-26 19:35:54,328  The loss during eval_loss is  :: 0.026043366640806198
2019-04-26 19:35:54,330  The global step eval is 716
2019-04-26 19:35:54,445  The loss during eval_loss is  :: 0.08599240332841873
2019-04-26 19:35:54,447  The global step eval is 717
2019-04-26 19:35:54,551  The loss during eval_loss is  :: 0.07271604239940643
2019-04-26 19:35:54,553  The global step eval is 718
2019-04-26 19:35:54,666  The loss during eval_loss is  :: 0.15467198193073273
2019-04-26 19:35:54,668  The global step eval is 719
2019-04-26 19:35:54,784  The loss during eval_loss is  :: 0.08112122118473053
2019-04-26 19:35:54,786  The global step eval is 720
2019-04-26 19:35:54,890  The loss during eval_loss is  :: 0.010698375292122364
2019-04-26 19:35:54,891  The global step eval is 721
2019-04-26 19:35:55,013  The loss during eval_loss is  :: 0.07556167244911194
2019-04-26 19:35:55,014  The global step eval is 722
2019-04-26 19:35:55,131  The loss during eval_loss is  :: 0.06852436065673828
2019-04-26 19:35:55,132  The global step eval is 723
2019-04-26 19:35:55,245  The loss during eval_loss is  :: 0.032142020761966705
2019-04-26 19:35:55,248  The global step eval is 724
2019-04-26 19:35:55,373  The loss during eval_loss is  :: 0.027621567249298096
2019-04-26 19:35:55,375  The global step eval is 725
2019-04-26 19:35:55,500  The loss during eval_loss is  :: 0.018150735646486282
2019-04-26 19:35:55,502  The global step eval is 726
2019-04-26 19:35:55,633  The loss during eval_loss is  :: 0.022519607096910477
2019-04-26 19:35:55,635  The global step eval is 727
2019-04-26 19:35:55,745  The loss during eval_loss is  :: 0.051701031625270844
2019-04-26 19:35:55,747  The global step eval is 728
2019-04-26 19:35:55,757  Saved checkpoint: ./trained_model\step_12.pth.tar
2019-04-26 19:35:55,758  Removed checkpoint: ./trained_model\step_12.pth.tar
2019-04-26 19:35:55,869  The loss during training is  :: 0.012618986889719963 
2019-04-26 19:35:56,024  The global step train is 2913
2019-04-26 19:35:56,159  The loss during training is  :: 0.008989639580249786 
2019-04-26 19:35:56,319  The global step train is 2914
2019-04-26 19:35:56,451  The loss during training is  :: 0.012600809335708618 
2019-04-26 19:35:56,627  The global step train is 2915
2019-04-26 19:35:56,763  The loss during training is  :: 0.04434049502015114 
2019-04-26 19:35:56,933  The global step train is 2916
2019-04-26 19:35:57,069  The loss during training is  :: 0.008582458831369877 
2019-04-26 19:35:57,240  The global step train is 2917
2019-04-26 19:35:57,377  The loss during training is  :: 0.012889261357486248 
2019-04-26 19:35:57,551  The global step train is 2918
2019-04-26 19:35:57,691  The loss during training is  :: 0.01884695701301098 
2019-04-26 19:35:57,862  The global step train is 2919
2019-04-26 19:35:58,010  The loss during training is  :: 0.022634033113718033 
2019-04-26 19:35:58,217  The global step train is 2920
2019-04-26 19:35:58,389  The loss during training is  :: 0.032249268144369125 
2019-04-26 19:35:58,580  The global step train is 2921
2019-04-26 19:35:58,723  The loss during training is  :: 0.022600507363677025 
2019-04-26 19:35:58,903  The global step train is 2922
2019-04-26 19:35:59,039  The loss during training is  :: 0.01684175431728363 
2019-04-26 19:35:59,210  The global step train is 2923
2019-04-26 19:35:59,353  The loss during training is  :: 0.006770172156393528 
2019-04-26 19:35:59,538  The global step train is 2924
2019-04-26 19:35:59,687  The loss during training is  :: 0.010075263679027557 
2019-04-26 19:35:59,866  The global step train is 2925
2019-04-26 19:36:00,011  The loss during training is  :: 0.0094083147123456 
2019-04-26 19:36:00,185  The global step train is 2926
2019-04-26 19:36:00,322  The loss during training is  :: 0.0068659973330795765 
2019-04-26 19:36:00,490  The global step train is 2927
2019-04-26 19:36:00,621  The loss during training is  :: 0.013156226836144924 
2019-04-26 19:36:00,786  The global step train is 2928
2019-04-26 19:36:00,924  The loss during training is  :: 0.020156094804406166 
2019-04-26 19:36:01,086  The global step train is 2929
2019-04-26 19:36:01,233  The loss during training is  :: 0.011724446900188923 
2019-04-26 19:36:01,403  The global step train is 2930
2019-04-26 19:36:01,544  The loss during training is  :: 0.005544961430132389 
2019-04-26 19:36:01,710  The global step train is 2931
2019-04-26 19:36:01,847  The loss during training is  :: 0.03188038989901543 
2019-04-26 19:36:02,014  The global step train is 2932
2019-04-26 19:36:02,150  The loss during training is  :: 0.008472181856632233 
2019-04-26 19:36:02,318  The global step train is 2933
2019-04-26 19:36:02,456  The loss during training is  :: 0.022834278643131256 
2019-04-26 19:36:02,626  The global step train is 2934
2019-04-26 19:36:02,763  The loss during training is  :: 0.019034801051020622 
2019-04-26 19:36:02,931  The global step train is 2935
2019-04-26 19:36:03,068  The loss during training is  :: 0.010565630160272121 
2019-04-26 19:36:03,239  The global step train is 2936
2019-04-26 19:36:03,376  The loss during training is  :: 0.003390741301700473 
2019-04-26 19:36:03,545  The global step train is 2937
2019-04-26 19:36:03,678  The loss during training is  :: 0.011860732920467854 
2019-04-26 19:36:03,846  The global step train is 2938
2019-04-26 19:36:03,979  The loss during training is  :: 0.010191514156758785 
2019-04-26 19:36:04,145  The global step train is 2939
2019-04-26 19:36:04,287  The loss during training is  :: 0.01042075827717781 
2019-04-26 19:36:04,452  The global step train is 2940
2019-04-26 19:36:04,583  The loss during training is  :: 0.01621464639902115 
2019-04-26 19:36:04,748  The global step train is 2941
2019-04-26 19:36:04,888  The loss during training is  :: 0.012325918301939964 
2019-04-26 19:36:05,050  The global step train is 2942
2019-04-26 19:36:05,184  The loss during training is  :: 0.006305221002548933 
2019-04-26 19:36:05,349  The global step train is 2943
2019-04-26 19:36:05,479  The loss during training is  :: 0.009042670018970966 
2019-04-26 19:36:05,646  The global step train is 2944
2019-04-26 19:36:05,776  The loss during training is  :: 0.018595267087221146 
2019-04-26 19:36:05,943  The global step train is 2945
2019-04-26 19:36:06,071  The loss during training is  :: 0.011178983375430107 
2019-04-26 19:36:06,236  The global step train is 2946
2019-04-26 19:36:06,371  The loss during training is  :: 0.013222052715718746 
2019-04-26 19:36:06,533  The global step train is 2947
2019-04-26 19:36:06,667  The loss during training is  :: 0.010357582941651344 
2019-04-26 19:36:06,830  The global step train is 2948
2019-04-26 19:36:06,955  The loss during training is  :: 0.004235121421515942 
2019-04-26 19:36:07,117  The global step train is 2949
2019-04-26 19:36:07,246  The loss during training is  :: 0.013761940412223339 
2019-04-26 19:36:07,410  The global step train is 2950
2019-04-26 19:36:07,543  The loss during training is  :: 0.01120858546346426 
2019-04-26 19:36:07,711  The global step train is 2951
2019-04-26 19:36:07,841  The loss during training is  :: 0.007785953115671873 
2019-04-26 19:36:08,007  The global step train is 2952
2019-04-26 19:36:08,141  The loss during training is  :: 0.01382444053888321 
2019-04-26 19:36:08,304  The global step train is 2953
2019-04-26 19:36:08,435  The loss during training is  :: 0.006198504939675331 
2019-04-26 19:36:08,597  The global step train is 2954
2019-04-26 19:36:08,734  The loss during training is  :: 0.0368066243827343 
2019-04-26 19:36:08,898  The global step train is 2955
2019-04-26 19:36:09,030  The loss during training is  :: 0.01868402399122715 
2019-04-26 19:36:09,197  The global step train is 2956
2019-04-26 19:36:09,332  The loss during training is  :: 0.012865514494478703 
2019-04-26 19:36:09,495  The global step train is 2957
2019-04-26 19:36:09,626  The loss during training is  :: 0.006134834140539169 
2019-04-26 19:36:09,804  The global step train is 2958
2019-04-26 19:36:09,942  The loss during training is  :: 0.030127061530947685 
2019-04-26 19:36:10,112  The global step train is 2959
2019-04-26 19:36:10,251  The loss during training is  :: 0.050213828682899475 
2019-04-26 19:36:10,414  The global step train is 2960
2019-04-26 19:36:10,551  The loss during training is  :: 0.004656534176319838 
2019-04-26 19:36:10,724  The global step train is 2961
2019-04-26 19:36:10,867  The loss during training is  :: 0.023569663986563683 
2019-04-26 19:36:11,039  The global step train is 2962
2019-04-26 19:36:11,170  The loss during training is  :: 0.030802493914961815 
2019-04-26 19:36:11,336  The global step train is 2963
2019-04-26 19:36:11,467  The loss during training is  :: 0.02355422079563141 
2019-04-26 19:36:11,628  The global step train is 2964
2019-04-26 19:36:11,756  The loss during training is  :: 0.0059319972060620785 
2019-04-26 19:36:11,919  The global step train is 2965
2019-04-26 19:36:12,055  The loss during training is  :: 0.003295144997537136 
2019-04-26 19:36:12,216  The global step train is 2966
2019-04-26 19:36:12,346  The loss during training is  :: 0.01320620533078909 
2019-04-26 19:36:12,511  The global step train is 2967
2019-04-26 19:36:12,642  The loss during training is  :: 0.010161374695599079 
2019-04-26 19:36:12,803  The global step train is 2968
2019-04-26 19:36:12,934  The loss during training is  :: 0.007095120847225189 
2019-04-26 19:36:13,102  The global step train is 2969
2019-04-26 19:36:13,230  The loss during training is  :: 0.01220551785081625 
2019-04-26 19:36:13,388  The global step train is 2970
2019-04-26 19:36:13,517  The loss during training is  :: 0.019282283261418343 
2019-04-26 19:36:13,677  The global step train is 2971
2019-04-26 19:36:13,810  The loss during training is  :: 0.026754122227430344 
2019-04-26 19:36:13,975  The global step train is 2972
2019-04-26 19:36:14,111  The loss during training is  :: 0.0062837316654622555 
2019-04-26 19:36:14,276  The global step train is 2973
2019-04-26 19:36:14,411  The loss during training is  :: 0.00884345080703497 
2019-04-26 19:36:14,586  The global step train is 2974
2019-04-26 19:36:14,724  The loss during training is  :: 0.026135988533496857 
2019-04-26 19:36:14,893  The global step train is 2975
2019-04-26 19:36:15,031  The loss during training is  :: 0.005259303841739893 
2019-04-26 19:36:15,199  The global step train is 2976
2019-04-26 19:36:15,333  The loss during training is  :: 0.01100744865834713 
2019-04-26 19:36:15,496  The global step train is 2977
2019-04-26 19:36:15,642  The loss during training is  :: 0.027831077575683594 
2019-04-26 19:36:15,841  The global step train is 2978
2019-04-26 19:36:15,978  The loss during training is  :: 0.01709103398025036 
2019-04-26 19:36:16,143  The global step train is 2979
2019-04-26 19:36:16,276  The loss during training is  :: 0.019778616726398468 
2019-04-26 19:36:16,438  The global step train is 2980
2019-04-26 19:36:16,570  The loss during training is  :: 0.03355195373296738 
2019-04-26 19:36:16,737  The global step train is 2981
2019-04-26 19:36:16,878  The loss during training is  :: 0.017518656328320503 
2019-04-26 19:36:17,045  The global step train is 2982
2019-04-26 19:36:17,184  The loss during training is  :: 0.02269653044641018 
2019-04-26 19:36:17,347  The global step train is 2983
2019-04-26 19:36:17,479  The loss during training is  :: 0.03769531473517418 
2019-04-26 19:36:17,644  The global step train is 2984
2019-04-26 19:36:17,780  The loss during training is  :: 0.01710721105337143 
2019-04-26 19:36:17,944  The global step train is 2985
2019-04-26 19:36:18,077  The loss during training is  :: 0.005028727930039167 
2019-04-26 19:36:18,244  The global step train is 2986
2019-04-26 19:36:18,376  The loss during training is  :: 0.00775801669806242 
2019-04-26 19:36:18,537  The global step train is 2987
2019-04-26 19:36:18,674  The loss during training is  :: 0.007391961291432381 
2019-04-26 19:36:18,849  The global step train is 2988
2019-04-26 19:36:18,981  The loss during training is  :: 0.014454355463385582 
2019-04-26 19:36:19,140  The global step train is 2989
2019-04-26 19:36:19,272  The loss during training is  :: 0.048545531928539276 
2019-04-26 19:36:19,437  The global step train is 2990
2019-04-26 19:36:19,568  The loss during training is  :: 0.020633196458220482 
2019-04-26 19:36:19,736  The global step train is 2991
2019-04-26 19:36:19,860  The loss during training is  :: 0.04100403934717178 
2019-04-26 19:36:20,020  The global step train is 2992
2019-04-26 19:36:20,153  The loss during training is  :: 0.010897611267864704 
2019-04-26 19:36:20,316  The global step train is 2993
2019-04-26 19:36:20,437  The loss during training is  :: 0.015408054925501347 
2019-04-26 19:36:20,603  The global step train is 2994
2019-04-26 19:36:20,735  The loss during training is  :: 0.12271298468112946 
2019-04-26 19:36:20,896  The global step train is 2995
2019-04-26 19:36:21,022  The loss during training is  :: 0.014929577708244324 
2019-04-26 19:36:21,185  The global step train is 2996
2019-04-26 19:36:21,320  The loss during training is  :: 0.011261733248829842 
2019-04-26 19:36:21,479  The global step train is 2997
2019-04-26 19:36:21,609  The loss during training is  :: 0.011340023949742317 
2019-04-26 19:36:21,771  The global step train is 2998
2019-04-26 19:36:21,906  The loss during training is  :: 0.010523051954805851 
2019-04-26 19:36:22,071  The global step train is 2999
2019-04-26 19:36:22,203  The loss during training is  :: 0.008729158900678158 
2019-04-26 19:36:22,363  The global step train is 3000
2019-04-26 19:36:22,494  The loss during training is  :: 0.009319175034761429 
2019-04-26 19:36:22,664  The global step train is 3001
2019-04-26 19:36:22,807  The loss during training is  :: 0.005285851191729307 
2019-04-26 19:36:22,981  The global step train is 3002
2019-04-26 19:36:23,123  The loss during training is  :: 0.010635020211338997 
2019-04-26 19:36:23,289  The global step train is 3003
2019-04-26 19:36:23,420  The loss during training is  :: 0.03499085456132889 
2019-04-26 19:36:23,586  The global step train is 3004
2019-04-26 19:36:23,718  The loss during training is  :: 0.009408232755959034 
2019-04-26 19:36:23,890  The global step train is 3005
2019-04-26 19:36:24,023  The loss during training is  :: 0.005891176871955395 
2019-04-26 19:36:24,185  The global step train is 3006
2019-04-26 19:36:24,314  The loss during training is  :: 0.011068328283727169 
2019-04-26 19:36:24,477  The global step train is 3007
2019-04-26 19:36:24,608  The loss during training is  :: 0.00817173346877098 
2019-04-26 19:36:24,773  The global step train is 3008
2019-04-26 19:36:24,903  The loss during training is  :: 0.009115826338529587 
2019-04-26 19:36:25,066  The global step train is 3009
2019-04-26 19:36:25,192  The loss during training is  :: 0.004551134072244167 
2019-04-26 19:36:25,352  The global step train is 3010
2019-04-26 19:36:25,486  The loss during training is  :: 0.031553126871585846 
2019-04-26 19:36:25,659  The global step train is 3011
2019-04-26 19:36:25,789  The loss during training is  :: 0.01947459578514099 
2019-04-26 19:36:25,955  The global step train is 3012
2019-04-26 19:36:26,087  The loss during training is  :: 0.029118534177541733 
2019-04-26 19:36:26,249  The global step train is 3013
2019-04-26 19:36:26,380  The loss during training is  :: 0.005686817225068808 
2019-04-26 19:36:26,546  The global step train is 3014
2019-04-26 19:36:26,681  The loss during training is  :: 0.0037608910351991653 
2019-04-26 19:36:26,848  The global step train is 3015
2019-04-26 19:36:26,985  The loss during training is  :: 0.015153338201344013 
2019-04-26 19:36:27,167  The global step train is 3016
2019-04-26 19:36:27,313  The loss during training is  :: 0.046305812895298004 
2019-04-26 19:36:27,496  The global step train is 3017
2019-04-26 19:36:27,633  The loss during training is  :: 0.007661959156394005 
2019-04-26 19:36:27,798  The global step train is 3018
2019-04-26 19:36:27,938  The loss during training is  :: 0.024655669927597046 
2019-04-26 19:36:28,106  The global step train is 3019
2019-04-26 19:36:28,258  The loss during training is  :: 0.011660442687571049 
2019-04-26 19:36:28,426  The global step train is 3020
2019-04-26 19:36:28,557  The loss during training is  :: 0.006555160041898489 
2019-04-26 19:36:28,719  The global step train is 3021
2019-04-26 19:36:28,852  The loss during training is  :: 0.008594067767262459 
2019-04-26 19:36:29,016  The global step train is 3022
2019-04-26 19:36:29,145  The loss during training is  :: 0.006588354241102934 
2019-04-26 19:36:29,307  The global step train is 3023
2019-04-26 19:36:29,437  The loss during training is  :: 0.01072710007429123 
2019-04-26 19:36:29,609  The global step train is 3024
2019-04-26 19:36:29,742  The loss during training is  :: 0.03297512233257294 
2019-04-26 19:36:29,907  The global step train is 3025
2019-04-26 19:36:30,042  The loss during training is  :: 0.02075578086078167 
2019-04-26 19:36:30,212  The global step train is 3026
2019-04-26 19:36:30,345  The loss during training is  :: 0.03337837755680084 
2019-04-26 19:36:30,508  The global step train is 3027
2019-04-26 19:36:30,644  The loss during training is  :: 0.009224542416632175 
2019-04-26 19:36:30,805  The global step train is 3028
2019-04-26 19:36:30,941  The loss during training is  :: 0.017259560525417328 
2019-04-26 19:36:31,108  The global step train is 3029
2019-04-26 19:36:31,244  The loss during training is  :: 0.025670010596513748 
2019-04-26 19:36:31,413  The global step train is 3030
2019-04-26 19:36:31,541  The loss during training is  :: 0.006079285871237516 
2019-04-26 19:36:31,704  The global step train is 3031
2019-04-26 19:36:31,840  The loss during training is  :: 0.030897293239831924 
2019-04-26 19:36:31,998  The global step train is 3032
2019-04-26 19:36:32,133  The loss during training is  :: 0.007872476242482662 
2019-04-26 19:36:32,294  The global step train is 3033
2019-04-26 19:36:32,430  The loss during training is  :: 0.009796428494155407 
2019-04-26 19:36:32,603  The global step train is 3034
2019-04-26 19:36:32,740  The loss during training is  :: 0.016232769936323166 
2019-04-26 19:36:32,909  The global step train is 3035
2019-04-26 19:36:33,046  The loss during training is  :: 0.019436687231063843 
2019-04-26 19:36:33,215  The global step train is 3036
2019-04-26 19:36:33,356  The loss during training is  :: 0.013663473539054394 
2019-04-26 19:36:33,530  The global step train is 3037
2019-04-26 19:36:33,669  The loss during training is  :: 0.01234258059412241 
2019-04-26 19:36:33,842  The global step train is 3038
2019-04-26 19:36:33,980  The loss during training is  :: 0.008573995903134346 
2019-04-26 19:36:34,178  The global step train is 3039
2019-04-26 19:36:34,337  The loss during training is  :: 0.011588824912905693 
2019-04-26 19:36:34,568  The global step train is 3040
2019-04-26 19:36:34,758  The loss during training is  :: 0.011895046569406986 
2019-04-26 19:36:34,950  The global step train is 3041
2019-04-26 19:36:35,101  The loss during training is  :: 0.04266132414340973 
2019-04-26 19:36:35,272  The global step train is 3042
2019-04-26 19:36:35,416  The loss during training is  :: 0.010663487017154694 
2019-04-26 19:36:35,584  The global step train is 3043
2019-04-26 19:36:35,757  The loss during training is  :: 0.0327010378241539 
2019-04-26 19:36:35,964  The global step train is 3044
2019-04-26 19:36:36,118  The loss during training is  :: 0.035400450229644775 
2019-04-26 19:36:36,361  The global step train is 3045
2019-04-26 19:36:36,552  The loss during training is  :: 0.01903744973242283 
2019-04-26 19:36:36,742  The global step train is 3046
2019-04-26 19:36:36,928  The loss during training is  :: 0.006061525549739599 
2019-04-26 19:36:37,145  The global step train is 3047
2019-04-26 19:36:37,345  The loss during training is  :: 0.01930428482592106 
2019-04-26 19:36:37,567  The global step train is 3048
2019-04-26 19:36:37,723  The loss during training is  :: 0.006799306720495224 
2019-04-26 19:36:37,897  The global step train is 3049
2019-04-26 19:36:38,038  The loss during training is  :: 0.012525049969553947 
2019-04-26 19:36:38,219  The global step train is 3050
2019-04-26 19:36:38,360  The loss during training is  :: 0.011149708181619644 
2019-04-26 19:36:38,556  The global step train is 3051
2019-04-26 19:36:38,739  The loss during training is  :: 0.026124365627765656 
2019-04-26 19:36:38,925  The global step train is 3052
2019-04-26 19:36:39,070  The loss during training is  :: 0.06110246106982231 
2019-04-26 19:36:39,241  The global step train is 3053
2019-04-26 19:36:39,426  The loss during training is  :: 0.02643156610429287 
2019-04-26 19:36:39,639  The global step train is 3054
2019-04-26 19:36:39,800  The loss during training is  :: 0.04434974491596222 
2019-04-26 19:36:39,983  The global step train is 3055
2019-04-26 19:36:40,160  The loss during training is  :: 0.010174976661801338 
2019-04-26 19:36:40,367  The global step train is 3056
2019-04-26 19:36:40,535  The loss during training is  :: 0.024946721270680428 
2019-04-26 19:36:40,731  The global step train is 3057
2019-04-26 19:36:40,891  The loss during training is  :: 0.008538207970559597 
2019-04-26 19:36:41,073  The global step train is 3058
2019-04-26 19:36:41,230  The loss during training is  :: 0.008392645977437496 
2019-04-26 19:36:41,452  The global step train is 3059
2019-04-26 19:36:41,621  The loss during training is  :: 0.005779193248599768 
2019-04-26 19:36:41,828  The global step train is 3060
2019-04-26 19:36:41,985  The loss during training is  :: 0.006879888940602541 
2019-04-26 19:36:42,174  The global step train is 3061
2019-04-26 19:36:42,328  The loss during training is  :: 0.0035371684934943914 
2019-04-26 19:36:42,514  The global step train is 3062
2019-04-26 19:36:42,666  The loss during training is  :: 0.053111955523490906 
2019-04-26 19:36:42,845  The global step train is 3063
2019-04-26 19:36:42,997  The loss during training is  :: 0.024057243019342422 
2019-04-26 19:36:43,185  The global step train is 3064
2019-04-26 19:36:43,338  The loss during training is  :: 0.012738046236336231 
2019-04-26 19:36:43,529  The global step train is 3065
2019-04-26 19:36:43,680  The loss during training is  :: 0.01589159294962883 
2019-04-26 19:36:43,873  The global step train is 3066
2019-04-26 19:36:44,022  The loss during training is  :: 0.032421279698610306 
2019-04-26 19:36:44,207  The global step train is 3067
2019-04-26 19:36:44,357  The loss during training is  :: 0.03223377466201782 
2019-04-26 19:36:44,548  The global step train is 3068
2019-04-26 19:36:44,704  The loss during training is  :: 0.0198582261800766 
2019-04-26 19:36:44,890  The global step train is 3069
2019-04-26 19:36:45,043  The loss during training is  :: 0.0015462716110050678 
2019-04-26 19:36:45,227  The global step train is 3070
2019-04-26 19:36:45,389  The loss during training is  :: 0.03345593065023422 
2019-04-26 19:36:45,589  The global step train is 3071
2019-04-26 19:36:45,740  The loss during training is  :: 0.009542608633637428 
2019-04-26 19:36:45,919  The global step train is 3072
2019-04-26 19:36:46,109  The loss during training is  :: 0.0037944188807159662 
2019-04-26 19:36:46,285  The global step train is 3073
2019-04-26 19:36:46,431  The loss during training is  :: 0.009914573282003403 
2019-04-26 19:36:46,604  The global step train is 3074
2019-04-26 19:36:46,750  The loss during training is  :: 0.05188605934381485 
2019-04-26 19:36:46,931  The global step train is 3075
2019-04-26 19:36:47,077  The loss during training is  :: 0.0459163635969162 
2019-04-26 19:36:47,260  The global step train is 3076
2019-04-26 19:36:47,405  The loss during training is  :: 0.023221565410494804 
2019-04-26 19:36:47,581  The global step train is 3077
2019-04-26 19:36:47,749  The loss during training is  :: 0.014143622480332851 
2019-04-26 19:36:47,932  The global step train is 3078
2019-04-26 19:36:48,084  The loss during training is  :: 0.006366475485265255 
2019-04-26 19:36:48,263  The global step train is 3079
2019-04-26 19:36:48,407  The loss during training is  :: 0.03603889048099518 
2019-04-26 19:36:48,584  The global step train is 3080
2019-04-26 19:36:48,756  The loss during training is  :: 0.013505798764526844 
2019-04-26 19:36:48,932  The global step train is 3081
2019-04-26 19:36:49,080  The loss during training is  :: 0.023134540766477585 
2019-04-26 19:36:49,261  The global step train is 3082
2019-04-26 19:36:49,411  The loss during training is  :: 0.025324111804366112 
2019-04-26 19:36:49,582  The global step train is 3083
2019-04-26 19:36:49,738  The loss during training is  :: 0.019906679168343544 
2019-04-26 19:36:49,910  The global step train is 3084
2019-04-26 19:36:50,051  The loss during training is  :: 0.011039450764656067 
2019-04-26 19:36:50,232  The global step train is 3085
2019-04-26 19:36:50,403  The loss during training is  :: 0.0112567488104105 
2019-04-26 19:36:50,575  The global step train is 3086
2019-04-26 19:36:50,726  The loss during training is  :: 0.01616715081036091 
2019-04-26 19:36:50,917  The global step train is 3087
2019-04-26 19:36:51,099  The loss during training is  :: 0.02888825349509716 
2019-04-26 19:36:51,280  The global step train is 3088
2019-04-26 19:36:51,431  The loss during training is  :: 0.016061455011367798 
2019-04-26 19:36:51,611  The global step train is 3089
2019-04-26 19:36:51,764  The loss during training is  :: 0.00450383173301816 
2019-04-26 19:36:51,945  The global step train is 3090
2019-04-26 19:36:52,094  The loss during training is  :: 0.009953775443136692 
2019-04-26 19:36:52,277  The global step train is 3091
2019-04-26 19:36:52,420  The loss during training is  :: 0.00780537910759449 
2019-04-26 19:36:52,611  The global step train is 3092
2019-04-26 19:36:52,774  The loss during training is  :: 0.008557294495403767 
2019-04-26 19:36:52,955  The global step train is 3093
2019-04-26 19:36:53,101  The loss during training is  :: 0.005666081327944994 
2019-04-26 19:36:53,286  The global step train is 3094
2019-04-26 19:36:53,446  The loss during training is  :: 0.03779326751828194 
2019-04-26 19:36:53,622  The global step train is 3095
2019-04-26 19:36:53,772  The loss during training is  :: 0.013375981710851192 
2019-04-26 19:36:53,950  The global step train is 3096
2019-04-26 19:36:54,097  The loss during training is  :: 0.014141292311251163 
2019-04-26 19:36:54,274  The global step train is 3097
2019-04-26 19:36:54,427  The loss during training is  :: 0.06540896743535995 
2019-04-26 19:36:54,628  The global step train is 3098
2019-04-26 19:36:54,780  The loss during training is  :: 0.029639549553394318 
2019-04-26 19:36:54,960  The global step train is 3099
2019-04-26 19:36:55,110  The loss during training is  :: 0.024583861231803894 
2019-04-26 19:36:55,285  The global step train is 3100
2019-04-26 19:36:55,436  The loss during training is  :: 0.01537350658327341 
2019-04-26 19:36:55,637  The global step train is 3101
2019-04-26 19:36:55,826  The loss during training is  :: 0.014102560468018055 
2019-04-26 19:36:56,032  The global step train is 3102
2019-04-26 19:36:56,183  The loss during training is  :: 0.015584885142743587 
2019-04-26 19:36:56,374  The global step train is 3103
2019-04-26 19:36:56,525  The loss during training is  :: 0.023155653849244118 
2019-04-26 19:36:56,707  The global step train is 3104
2019-04-26 19:36:56,856  The loss during training is  :: 0.03080933913588524 
2019-04-26 19:36:57,037  The global step train is 3105
2019-04-26 19:36:57,180  The loss during training is  :: 0.06878409534692764 
2019-04-26 19:36:57,388  The global step train is 3106
2019-04-26 19:36:57,565  The loss during training is  :: 0.043870437890291214 
2019-04-26 19:36:57,760  The global step train is 3107
2019-04-26 19:36:57,917  The loss during training is  :: 0.01769132912158966 
2019-04-26 19:36:58,110  The global step train is 3108
2019-04-26 19:36:58,269  The loss during training is  :: 0.03851547837257385 
2019-04-26 19:36:58,474  The global step train is 3109
2019-04-26 19:36:58,663  The loss during training is  :: 0.02198067307472229 
2019-04-26 19:36:58,888  The global step train is 3110
2019-04-26 19:36:59,052  The loss during training is  :: 0.004989118780940771 
2019-04-26 19:36:59,239  The global step train is 3111
2019-04-26 19:36:59,399  The loss during training is  :: 0.029808247461915016 
2019-04-26 19:36:59,597  The global step train is 3112
2019-04-26 19:36:59,771  The loss during training is  :: 0.012939424254000187 
2019-04-26 19:36:59,956  The global step train is 3113
2019-04-26 19:37:00,114  The loss during training is  :: 0.024752477183938026 
2019-04-26 19:37:00,299  The global step train is 3114
2019-04-26 19:37:00,461  The loss during training is  :: 0.09940914064645767 
2019-04-26 19:37:00,647  The global step train is 3115
2019-04-26 19:37:00,803  The loss during training is  :: 0.00818223599344492 
2019-04-26 19:37:01,000  The global step train is 3116
2019-04-26 19:37:01,157  The loss during training is  :: 0.034329045563936234 
2019-04-26 19:37:01,362  The global step train is 3117
2019-04-26 19:37:01,522  The loss during training is  :: 0.009893153794109821 
2019-04-26 19:37:01,742  The global step train is 3118
2019-04-26 19:37:01,897  The loss during training is  :: 0.01648971624672413 
2019-04-26 19:37:02,095  The global step train is 3119
2019-04-26 19:37:02,255  The loss during training is  :: 0.012393033131957054 
2019-04-26 19:37:02,444  The global step train is 3120
2019-04-26 19:37:02,593  The loss during training is  :: 0.0012628365075215697 
2019-04-26 19:37:02,782  The global step train is 3121
2019-04-26 19:37:02,931  The loss during training is  :: 0.016763759776949883 
2019-04-26 19:37:03,108  The global step train is 3122
2019-04-26 19:37:03,273  The loss during training is  :: 0.014710715971887112 
2019-04-26 19:37:03,450  The global step train is 3123
2019-04-26 19:37:03,596  The loss during training is  :: 0.022168055176734924 
2019-04-26 19:37:03,777  The global step train is 3124
2019-04-26 19:37:03,924  The loss during training is  :: 0.025052299723029137 
2019-04-26 19:37:04,107  The global step train is 3125
2019-04-26 19:37:04,246  The loss during training is  :: 0.05186827480792999 
2019-04-26 19:37:04,414  The global step train is 3126
2019-04-26 19:37:04,552  The loss during training is  :: 0.004630371928215027 
2019-04-26 19:37:04,723  The global step train is 3127
2019-04-26 19:37:04,860  The loss during training is  :: 0.004048744682222605 
2019-04-26 19:37:05,025  The global step train is 3128
2019-04-26 19:37:05,161  The loss during training is  :: 0.039446230977773666 
2019-04-26 19:37:05,335  The global step train is 3129
2019-04-26 19:37:05,474  The loss during training is  :: 0.01157727837562561 
2019-04-26 19:37:05,640  The global step train is 3130
2019-04-26 19:37:05,785  The loss during training is  :: 0.015140377916395664 
2019-04-26 19:37:05,955  The global step train is 3131
2019-04-26 19:37:06,091  The loss during training is  :: 0.011541337706148624 
2019-04-26 19:37:06,260  The global step train is 3132
2019-04-26 19:37:06,398  The loss during training is  :: 0.007745570968836546 
2019-04-26 19:37:06,563  The global step train is 3133
2019-04-26 19:37:06,699  The loss during training is  :: 0.010332489386200905 
2019-04-26 19:37:06,861  The global step train is 3134
2019-04-26 19:37:06,993  The loss during training is  :: 0.02597547136247158 
2019-04-26 19:37:07,161  The global step train is 3135
2019-04-26 19:37:07,294  The loss during training is  :: 0.005755643825978041 
2019-04-26 19:37:07,456  The global step train is 3136
2019-04-26 19:37:07,458  Starting evaluation 
2019-04-26 19:37:07,599  The loss during eval_loss is  :: 0.04445705935359001
2019-04-26 19:37:07,601  The global step eval is 729
2019-04-26 19:37:07,736  The loss during eval_loss is  :: 0.0584072507917881
2019-04-26 19:37:07,739  The global step eval is 730
2019-04-26 19:37:07,848  The loss during eval_loss is  :: 0.020425476133823395
2019-04-26 19:37:07,850  The global step eval is 731
2019-04-26 19:37:07,956  The loss during eval_loss is  :: 0.038101423531770706
2019-04-26 19:37:07,959  The global step eval is 732
2019-04-26 19:37:08,074  The loss during eval_loss is  :: 0.03130291774868965
2019-04-26 19:37:08,076  The global step eval is 733
2019-04-26 19:37:08,191  The loss during eval_loss is  :: 0.08960063755512238
2019-04-26 19:37:08,193  The global step eval is 734
2019-04-26 19:37:08,314  The loss during eval_loss is  :: 0.07815307378768921
2019-04-26 19:37:08,315  The global step eval is 735
2019-04-26 19:37:08,435  The loss during eval_loss is  :: 0.0037469100207090378
2019-04-26 19:37:08,437  The global step eval is 736
2019-04-26 19:37:08,549  The loss during eval_loss is  :: 0.10361555218696594
2019-04-26 19:37:08,551  The global step eval is 737
2019-04-26 19:37:08,667  The loss during eval_loss is  :: 0.03162670135498047
2019-04-26 19:37:08,669  The global step eval is 738
2019-04-26 19:37:08,781  The loss during eval_loss is  :: 0.10479331761598587
2019-04-26 19:37:08,783  The global step eval is 739
2019-04-26 19:37:08,897  The loss during eval_loss is  :: 0.028317419812083244
2019-04-26 19:37:08,899  The global step eval is 740
2019-04-26 19:37:09,008  The loss during eval_loss is  :: 0.029480857774615288
2019-04-26 19:37:09,010  The global step eval is 741
2019-04-26 19:37:09,124  The loss during eval_loss is  :: 0.06839919090270996
2019-04-26 19:37:09,126  The global step eval is 742
2019-04-26 19:37:09,242  The loss during eval_loss is  :: 0.027992893010377884
2019-04-26 19:37:09,244  The global step eval is 743
2019-04-26 19:37:09,359  The loss during eval_loss is  :: 0.07322275638580322
2019-04-26 19:37:09,361  The global step eval is 744
2019-04-26 19:37:09,474  The loss during eval_loss is  :: 0.06979504972696304
2019-04-26 19:37:09,476  The global step eval is 745
2019-04-26 19:37:09,579  The loss during eval_loss is  :: 0.18638020753860474
2019-04-26 19:37:09,580  The global step eval is 746
2019-04-26 19:37:09,689  The loss during eval_loss is  :: 0.05085878074169159
2019-04-26 19:37:09,691  The global step eval is 747
2019-04-26 19:37:09,794  The loss during eval_loss is  :: 0.04186464846134186
2019-04-26 19:37:09,796  The global step eval is 748
2019-04-26 19:37:09,905  The loss during eval_loss is  :: 0.09295891970396042
2019-04-26 19:37:09,907  The global step eval is 749
2019-04-26 19:37:10,021  The loss during eval_loss is  :: 0.04621938243508339
2019-04-26 19:37:10,022  The global step eval is 750
2019-04-26 19:37:10,136  The loss during eval_loss is  :: 0.0440102182328701
2019-04-26 19:37:10,138  The global step eval is 751
2019-04-26 19:37:10,253  The loss during eval_loss is  :: 0.040789585560560226
2019-04-26 19:37:10,255  The global step eval is 752
2019-04-26 19:37:10,370  The loss during eval_loss is  :: 0.058689117431640625
2019-04-26 19:37:10,372  The global step eval is 753
2019-04-26 19:37:10,478  The loss during eval_loss is  :: 0.0035438600461930037
2019-04-26 19:37:10,481  The global step eval is 754
2019-04-26 19:37:10,594  The loss during eval_loss is  :: 0.06462094187736511
2019-04-26 19:37:10,597  The global step eval is 755
2019-04-26 19:37:10,725  The loss during eval_loss is  :: 0.034521546214818954
2019-04-26 19:37:10,727  The global step eval is 756
2019-04-26 19:37:10,840  The loss during eval_loss is  :: 0.06344528496265411
2019-04-26 19:37:10,842  The global step eval is 757
2019-04-26 19:37:10,958  The loss during eval_loss is  :: 0.024085035547614098
2019-04-26 19:37:10,960  The global step eval is 758
2019-04-26 19:37:11,076  The loss during eval_loss is  :: 0.027558984234929085
2019-04-26 19:37:11,078  The global step eval is 759
2019-04-26 19:37:11,187  The loss during eval_loss is  :: 0.052606698125600815
2019-04-26 19:37:11,189  The global step eval is 760
2019-04-26 19:37:11,294  The loss during eval_loss is  :: 0.058103397488594055
2019-04-26 19:37:11,297  The global step eval is 761
2019-04-26 19:37:11,413  The loss during eval_loss is  :: 0.14005129039287567
2019-04-26 19:37:11,415  The global step eval is 762
2019-04-26 19:37:11,534  The loss during eval_loss is  :: 0.060687415301799774
2019-04-26 19:37:11,536  The global step eval is 763
2019-04-26 19:37:11,658  The loss during eval_loss is  :: 0.13501261174678802
2019-04-26 19:37:11,661  The global step eval is 764
2019-04-26 19:37:11,774  The loss during eval_loss is  :: 0.09162592887878418
2019-04-26 19:37:11,775  The global step eval is 765
2019-04-26 19:37:11,894  The loss during eval_loss is  :: 0.07238242775201797
2019-04-26 19:37:11,896  The global step eval is 766
2019-04-26 19:37:11,999  The loss during eval_loss is  :: 0.00964326225221157
2019-04-26 19:37:12,001  The global step eval is 767
2019-04-26 19:37:12,103  The loss during eval_loss is  :: 0.018877241760492325
2019-04-26 19:37:12,106  The global step eval is 768
2019-04-26 19:37:12,215  The loss during eval_loss is  :: 0.054384779185056686
2019-04-26 19:37:12,216  The global step eval is 769
2019-04-26 19:37:12,342  The loss during eval_loss is  :: 0.049379654228687286
2019-04-26 19:37:12,344  The global step eval is 770
2019-04-26 19:37:12,469  The loss during eval_loss is  :: 0.10247599333524704
2019-04-26 19:37:12,471  The global step eval is 771
2019-04-26 19:37:12,580  The loss during eval_loss is  :: 0.04181898012757301
2019-04-26 19:37:12,581  The global step eval is 772
2019-04-26 19:37:12,696  The loss during eval_loss is  :: 0.10448015481233597
2019-04-26 19:37:12,698  The global step eval is 773
2019-04-26 19:37:12,810  The loss during eval_loss is  :: 0.05313379317522049
2019-04-26 19:37:12,812  The global step eval is 774
2019-04-26 19:37:12,920  The loss during eval_loss is  :: 0.10644447058439255
2019-04-26 19:37:12,921  The global step eval is 775
2019-04-26 19:37:13,030  The loss during eval_loss is  :: 0.07592147588729858
2019-04-26 19:37:13,032  The global step eval is 776
2019-04-26 19:37:13,158  The loss during eval_loss is  :: 0.020362036302685738
2019-04-26 19:37:13,160  The global step eval is 777
2019-04-26 19:37:13,268  The loss during eval_loss is  :: 0.08148162811994553
2019-04-26 19:37:13,270  The global step eval is 778
2019-04-26 19:37:13,380  The loss during eval_loss is  :: 0.08523551374673843
2019-04-26 19:37:13,382  The global step eval is 779
2019-04-26 19:37:13,507  The loss during eval_loss is  :: 0.021641375496983528
2019-04-26 19:37:13,509  The global step eval is 780
2019-04-26 19:37:13,624  The loss during eval_loss is  :: 0.03039148636162281
2019-04-26 19:37:13,626  The global step eval is 781
2019-04-26 19:37:13,743  The loss during eval_loss is  :: 0.01054621022194624
2019-04-26 19:37:13,745  The global step eval is 782
2019-04-26 19:37:13,857  The loss during eval_loss is  :: 0.027155090123414993
2019-04-26 19:37:13,858  The global step eval is 783
2019-04-26 19:37:13,971  The loss during eval_loss is  :: 0.08228030800819397
2019-04-26 19:37:13,973  The global step eval is 784
2019-04-26 19:37:13,984  Saved checkpoint: ./trained_model\step_13.pth.tar
2019-04-26 19:37:13,985  Removed checkpoint: ./trained_model\step_13.pth.tar
2019-04-26 19:37:14,094  The loss during training is  :: 0.024959493428468704 
2019-04-26 19:37:14,254  The global step train is 3137
2019-04-26 19:37:14,389  The loss during training is  :: 0.015652211382985115 
2019-04-26 19:37:14,551  The global step train is 3138
2019-04-26 19:37:14,683  The loss during training is  :: 0.020082522183656693 
2019-04-26 19:37:14,850  The global step train is 3139
2019-04-26 19:37:14,979  The loss during training is  :: 0.008482561446726322 
2019-04-26 19:37:15,148  The global step train is 3140
2019-04-26 19:37:15,280  The loss during training is  :: 0.01821923814713955 
2019-04-26 19:37:15,448  The global step train is 3141
2019-04-26 19:37:15,578  The loss during training is  :: 0.0054086558520793915 
2019-04-26 19:37:15,739  The global step train is 3142
2019-04-26 19:37:15,871  The loss during training is  :: 0.005646343342959881 
2019-04-26 19:37:16,033  The global step train is 3143
2019-04-26 19:37:16,166  The loss during training is  :: 0.004312305245548487 
2019-04-26 19:37:16,327  The global step train is 3144
2019-04-26 19:37:16,466  The loss during training is  :: 0.00589887285605073 
2019-04-26 19:37:16,643  The global step train is 3145
2019-04-26 19:37:16,770  The loss during training is  :: 0.03380395844578743 
2019-04-26 19:37:16,937  The global step train is 3146
2019-04-26 19:37:17,066  The loss during training is  :: 0.051596544682979584 
2019-04-26 19:37:17,230  The global step train is 3147
2019-04-26 19:37:17,364  The loss during training is  :: 0.009424504823982716 
2019-04-26 19:37:17,525  The global step train is 3148
2019-04-26 19:37:17,658  The loss during training is  :: 0.007643356453627348 
2019-04-26 19:37:17,830  The global step train is 3149
2019-04-26 19:37:17,963  The loss during training is  :: 0.013735519722104073 
2019-04-26 19:37:18,123  The global step train is 3150
2019-04-26 19:37:18,253  The loss during training is  :: 0.0367322638630867 
2019-04-26 19:37:18,422  The global step train is 3151
2019-04-26 19:37:18,554  The loss during training is  :: 0.01483879704028368 
2019-04-26 19:37:18,709  The global step train is 3152
2019-04-26 19:37:18,837  The loss during training is  :: 0.025513188913464546 
2019-04-26 19:37:19,004  The global step train is 3153
2019-04-26 19:37:19,136  The loss during training is  :: 0.009225279092788696 
2019-04-26 19:37:19,293  The global step train is 3154
2019-04-26 19:37:19,424  The loss during training is  :: 0.02430390752851963 
2019-04-26 19:37:19,586  The global step train is 3155
2019-04-26 19:37:19,719  The loss during training is  :: 0.026143793016672134 
2019-04-26 19:37:19,879  The global step train is 3156
2019-04-26 19:37:20,011  The loss during training is  :: 0.009865119121968746 
2019-04-26 19:37:20,175  The global step train is 3157
2019-04-26 19:37:20,318  The loss during training is  :: 0.009779621846973896 
2019-04-26 19:37:20,495  The global step train is 3158
2019-04-26 19:37:20,637  The loss during training is  :: 0.000907932932022959 
2019-04-26 19:37:20,809  The global step train is 3159
2019-04-26 19:37:20,948  The loss during training is  :: 0.012626574374735355 
2019-04-26 19:37:21,118  The global step train is 3160
2019-04-26 19:37:21,255  The loss during training is  :: 0.007276980206370354 
2019-04-26 19:37:21,426  The global step train is 3161
2019-04-26 19:37:21,561  The loss during training is  :: 0.017594611272215843 
2019-04-26 19:37:21,741  The global step train is 3162
2019-04-26 19:37:21,885  The loss during training is  :: 0.010820506140589714 
2019-04-26 19:37:22,058  The global step train is 3163
2019-04-26 19:37:22,194  The loss during training is  :: 0.025863317772746086 
2019-04-26 19:37:22,367  The global step train is 3164
2019-04-26 19:37:22,503  The loss during training is  :: 0.0053357952274382114 
2019-04-26 19:37:22,672  The global step train is 3165
2019-04-26 19:37:22,800  The loss during training is  :: 0.0027823385316878557 
2019-04-26 19:37:22,973  The global step train is 3166
2019-04-26 19:37:23,117  The loss during training is  :: 0.0200931616127491 
2019-04-26 19:37:23,292  The global step train is 3167
2019-04-26 19:37:23,420  The loss during training is  :: 0.02070014923810959 
2019-04-26 19:37:23,591  The global step train is 3168
2019-04-26 19:37:23,721  The loss during training is  :: 0.010208606719970703 
2019-04-26 19:37:23,882  The global step train is 3169
2019-04-26 19:37:24,019  The loss during training is  :: 0.007653131615370512 
2019-04-26 19:37:24,188  The global step train is 3170
2019-04-26 19:37:24,342  The loss during training is  :: 0.0514485128223896 
2019-04-26 19:37:24,511  The global step train is 3171
2019-04-26 19:37:24,645  The loss during training is  :: 0.0108240507543087 
2019-04-26 19:37:24,821  The global step train is 3172
2019-04-26 19:37:24,965  The loss during training is  :: 0.017125742509961128 
2019-04-26 19:37:25,135  The global step train is 3173
2019-04-26 19:37:25,277  The loss during training is  :: 0.02689460664987564 
2019-04-26 19:37:25,450  The global step train is 3174
2019-04-26 19:37:25,590  The loss during training is  :: 0.01610560342669487 
2019-04-26 19:37:25,771  The global step train is 3175
2019-04-26 19:37:25,917  The loss during training is  :: 0.0021453602239489555 
2019-04-26 19:37:26,093  The global step train is 3176
2019-04-26 19:37:26,236  The loss during training is  :: 0.011654532514512539 
2019-04-26 19:37:26,412  The global step train is 3177
2019-04-26 19:37:26,551  The loss during training is  :: 0.017416276037693024 
2019-04-26 19:37:26,725  The global step train is 3178
2019-04-26 19:37:26,865  The loss during training is  :: 0.01959236152470112 
2019-04-26 19:37:27,038  The global step train is 3179
2019-04-26 19:37:27,174  The loss during training is  :: 0.0038728618528693914 
2019-04-26 19:37:27,339  The global step train is 3180
2019-04-26 19:37:27,470  The loss during training is  :: 0.009400462731719017 
2019-04-26 19:37:27,631  The global step train is 3181
2019-04-26 19:37:27,770  The loss during training is  :: 0.0056299432180821896 
2019-04-26 19:37:27,933  The global step train is 3182
2019-04-26 19:37:28,064  The loss during training is  :: 0.007549654692411423 
2019-04-26 19:37:28,247  The global step train is 3183
2019-04-26 19:37:28,402  The loss during training is  :: 0.024091364815831184 
2019-04-26 19:37:28,591  The global step train is 3184
2019-04-26 19:37:28,724  The loss during training is  :: 0.011747926473617554 
2019-04-26 19:37:28,895  The global step train is 3185
2019-04-26 19:37:29,026  The loss during training is  :: 0.012085320428013802 
2019-04-26 19:37:29,194  The global step train is 3186
2019-04-26 19:37:29,325  The loss during training is  :: 0.016157357022166252 
2019-04-26 19:37:29,494  The global step train is 3187
2019-04-26 19:37:29,627  The loss during training is  :: 0.005172007717192173 
2019-04-26 19:37:29,792  The global step train is 3188
2019-04-26 19:37:29,925  The loss during training is  :: 0.014876855537295341 
2019-04-26 19:37:30,085  The global step train is 3189
2019-04-26 19:37:30,214  The loss during training is  :: 0.042861923575401306 
2019-04-26 19:37:30,367  The global step train is 3190
2019-04-26 19:37:30,498  The loss during training is  :: 0.0030267429538071156 
2019-04-26 19:37:30,696  The global step train is 3191
2019-04-26 19:37:30,839  The loss during training is  :: 0.005134010221809149 
2019-04-26 19:37:31,007  The global step train is 3192
2019-04-26 19:37:31,142  The loss during training is  :: 0.00858061108738184 
2019-04-26 19:37:31,308  The global step train is 3193
2019-04-26 19:37:31,442  The loss during training is  :: 0.010260417126119137 
2019-04-26 19:37:31,607  The global step train is 3194
2019-04-26 19:37:31,735  The loss during training is  :: 0.018961187452077866 
2019-04-26 19:37:31,914  The global step train is 3195
2019-04-26 19:37:32,059  The loss during training is  :: 0.008468513377010822 
2019-04-26 19:37:32,240  The global step train is 3196
2019-04-26 19:37:32,375  The loss during training is  :: 0.008274040184915066 
2019-04-26 19:37:32,542  The global step train is 3197
2019-04-26 19:37:32,678  The loss during training is  :: 0.02319839410483837 
2019-04-26 19:37:32,844  The global step train is 3198
2019-04-26 19:37:32,987  The loss during training is  :: 0.007235793862491846 
2019-04-26 19:37:33,173  The global step train is 3199
2019-04-26 19:37:33,314  The loss during training is  :: 0.010936626233160496 
2019-04-26 19:37:33,485  The global step train is 3200
2019-04-26 19:37:33,614  The loss during training is  :: 0.051152896136045456 
2019-04-26 19:37:33,777  The global step train is 3201
2019-04-26 19:37:33,908  The loss during training is  :: 0.006444705184549093 
2019-04-26 19:37:34,068  The global step train is 3202
2019-04-26 19:37:34,199  The loss during training is  :: 0.012727823108434677 
2019-04-26 19:37:34,360  The global step train is 3203
2019-04-26 19:37:34,490  The loss during training is  :: 0.012956882826983929 
2019-04-26 19:37:34,649  The global step train is 3204
2019-04-26 19:37:34,782  The loss during training is  :: 0.03988691791892052 
2019-04-26 19:37:34,943  The global step train is 3205
2019-04-26 19:37:35,084  The loss during training is  :: 0.022644834592938423 
2019-04-26 19:37:35,245  The global step train is 3206
2019-04-26 19:37:35,375  The loss during training is  :: 0.02612937055528164 
2019-04-26 19:37:35,545  The global step train is 3207
2019-04-26 19:37:35,678  The loss during training is  :: 0.029342714697122574 
2019-04-26 19:37:35,839  The global step train is 3208
2019-04-26 19:37:35,969  The loss during training is  :: 0.004750079941004515 
2019-04-26 19:37:36,138  The global step train is 3209
2019-04-26 19:37:36,271  The loss during training is  :: 0.06332570314407349 
2019-04-26 19:37:36,432  The global step train is 3210
2019-04-26 19:37:36,562  The loss during training is  :: 0.0037536683958023787 
2019-04-26 19:37:36,743  The global step train is 3211
2019-04-26 19:37:36,874  The loss during training is  :: 0.009276977740228176 
2019-04-26 19:37:37,035  The global step train is 3212
2019-04-26 19:37:37,165  The loss during training is  :: 0.032235316932201385 
2019-04-26 19:37:37,326  The global step train is 3213
2019-04-26 19:37:37,447  The loss during training is  :: 0.03168820962309837 
2019-04-26 19:37:37,616  The global step train is 3214
2019-04-26 19:37:37,749  The loss during training is  :: 0.004498109687119722 
2019-04-26 19:37:37,909  The global step train is 3215
2019-04-26 19:37:38,050  The loss during training is  :: 0.012341031804680824 
2019-04-26 19:37:38,209  The global step train is 3216
2019-04-26 19:37:38,342  The loss during training is  :: 0.012215184979140759 
2019-04-26 19:37:38,511  The global step train is 3217
2019-04-26 19:37:38,643  The loss during training is  :: 0.0028599421493709087 
2019-04-26 19:37:38,812  The global step train is 3218
2019-04-26 19:37:38,935  The loss during training is  :: 0.01983761228621006 
2019-04-26 19:37:39,106  The global step train is 3219
2019-04-26 19:37:39,227  The loss during training is  :: 0.01845962181687355 
2019-04-26 19:37:39,397  The global step train is 3220
2019-04-26 19:37:39,528  The loss during training is  :: 0.011694797314703465 
2019-04-26 19:37:39,707  The global step train is 3221
2019-04-26 19:37:39,840  The loss during training is  :: 0.018268683925271034 
2019-04-26 19:37:40,009  The global step train is 3222
2019-04-26 19:37:40,142  The loss during training is  :: 0.0079032676294446 
2019-04-26 19:37:40,303  The global step train is 3223
2019-04-26 19:37:40,434  The loss during training is  :: 0.009090372361242771 
2019-04-26 19:37:40,605  The global step train is 3224
2019-04-26 19:37:40,735  The loss during training is  :: 0.01169152557849884 
2019-04-26 19:37:40,906  The global step train is 3225
2019-04-26 19:37:41,027  The loss during training is  :: 0.0022907638922333717 
2019-04-26 19:37:41,188  The global step train is 3226
2019-04-26 19:37:41,316  The loss during training is  :: 0.02369123138487339 
2019-04-26 19:37:41,489  The global step train is 3227
2019-04-26 19:37:41,620  The loss during training is  :: 0.11835083365440369 
2019-04-26 19:37:41,781  The global step train is 3228
2019-04-26 19:37:41,912  The loss during training is  :: 0.011033878661692142 
2019-04-26 19:37:42,072  The global step train is 3229
2019-04-26 19:37:42,203  The loss during training is  :: 0.007149035111069679 
2019-04-26 19:37:42,374  The global step train is 3230
2019-04-26 19:37:42,505  The loss during training is  :: 0.006253007333725691 
2019-04-26 19:37:42,666  The global step train is 3231
2019-04-26 19:37:42,805  The loss during training is  :: 0.00934027973562479 
2019-04-26 19:37:42,967  The global step train is 3232
2019-04-26 19:37:43,101  The loss during training is  :: 0.01475485134869814 
2019-04-26 19:37:43,261  The global step train is 3233
2019-04-26 19:37:43,394  The loss during training is  :: 0.026586389169096947 
2019-04-26 19:37:43,557  The global step train is 3234
2019-04-26 19:37:43,683  The loss during training is  :: 0.029826993122696877 
2019-04-26 19:37:43,848  The global step train is 3235
2019-04-26 19:37:43,976  The loss during training is  :: 0.010615278966724873 
2019-04-26 19:37:44,137  The global step train is 3236
2019-04-26 19:37:44,268  The loss during training is  :: 0.005070050712674856 
2019-04-26 19:37:44,448  The global step train is 3237
2019-04-26 19:37:44,579  The loss during training is  :: 0.008372179232537746 
2019-04-26 19:37:44,750  The global step train is 3238
2019-04-26 19:37:44,881  The loss during training is  :: 0.031139805912971497 
2019-04-26 19:37:45,052  The global step train is 3239
2019-04-26 19:37:45,182  The loss during training is  :: 0.03246735781431198 
2019-04-26 19:37:45,343  The global step train is 3240
2019-04-26 19:37:45,482  The loss during training is  :: 0.037166304886341095 
2019-04-26 19:37:45,645  The global step train is 3241
2019-04-26 19:37:45,776  The loss during training is  :: 0.0332079753279686 
2019-04-26 19:37:45,955  The global step train is 3242
2019-04-26 19:37:46,077  The loss during training is  :: 0.012699912302196026 
2019-04-26 19:37:46,246  The global step train is 3243
2019-04-26 19:37:46,377  The loss during training is  :: 0.03531361743807793 
2019-04-26 19:37:46,550  The global step train is 3244
2019-04-26 19:37:46,680  The loss during training is  :: 0.02831771783530712 
2019-04-26 19:37:46,852  The global step train is 3245
2019-04-26 19:37:46,982  The loss during training is  :: 0.0037428855430334806 
2019-04-26 19:37:47,153  The global step train is 3246
2019-04-26 19:37:47,287  The loss during training is  :: 0.01459150668233633 
2019-04-26 19:37:47,451  The global step train is 3247
2019-04-26 19:37:47,579  The loss during training is  :: 0.033492304384708405 
2019-04-26 19:37:47,747  The global step train is 3248
2019-04-26 19:37:47,876  The loss during training is  :: 0.0038844363298267126 
2019-04-26 19:37:48,040  The global step train is 3249
2019-04-26 19:37:48,171  The loss during training is  :: 0.024823661893606186 
2019-04-26 19:37:48,332  The global step train is 3250
2019-04-26 19:37:48,462  The loss during training is  :: 0.01312528271228075 
2019-04-26 19:37:48,653  The global step train is 3251
2019-04-26 19:37:48,784  The loss during training is  :: 0.022878719493746758 
2019-04-26 19:37:48,945  The global step train is 3252
2019-04-26 19:37:49,086  The loss during training is  :: 0.03341015800833702 
2019-04-26 19:37:49,249  The global step train is 3253
2019-04-26 19:37:49,383  The loss during training is  :: 0.021269438788294792 
2019-04-26 19:37:49,546  The global step train is 3254
2019-04-26 19:37:49,681  The loss during training is  :: 0.009306064806878567 
2019-04-26 19:37:49,841  The global step train is 3255
2019-04-26 19:37:49,971  The loss during training is  :: 0.02196800895035267 
2019-04-26 19:37:50,123  The global step train is 3256
2019-04-26 19:37:50,264  The loss during training is  :: 0.02797546423971653 
2019-04-26 19:37:50,435  The global step train is 3257
2019-04-26 19:37:50,566  The loss during training is  :: 0.027795391157269478 
2019-04-26 19:37:50,747  The global step train is 3258
2019-04-26 19:37:50,867  The loss during training is  :: 0.029880816116929054 
2019-04-26 19:37:51,038  The global step train is 3259
2019-04-26 19:37:51,177  The loss during training is  :: 0.018374668434262276 
2019-04-26 19:37:51,338  The global step train is 3260
2019-04-26 19:37:51,470  The loss during training is  :: 0.03562016785144806 
2019-04-26 19:37:51,631  The global step train is 3261
2019-04-26 19:37:51,762  The loss during training is  :: 0.020280078053474426 
2019-04-26 19:37:51,933  The global step train is 3262
2019-04-26 19:37:52,064  The loss during training is  :: 0.016309188678860664 
2019-04-26 19:37:52,234  The global step train is 3263
2019-04-26 19:37:52,365  The loss during training is  :: 0.006952721159905195 
2019-04-26 19:37:52,536  The global step train is 3264
2019-04-26 19:37:52,665  The loss during training is  :: 0.012442127801477909 
2019-04-26 19:37:52,828  The global step train is 3265
2019-04-26 19:37:52,966  The loss during training is  :: 0.02269141562283039 
2019-04-26 19:37:53,139  The global step train is 3266
2019-04-26 19:37:53,280  The loss during training is  :: 0.008320894092321396 
2019-04-26 19:37:53,451  The global step train is 3267
2019-04-26 19:37:53,600  The loss during training is  :: 0.008322893641889095 
2019-04-26 19:37:53,773  The global step train is 3268
2019-04-26 19:37:53,914  The loss during training is  :: 0.006269143428653479 
2019-04-26 19:37:54,085  The global step train is 3269
2019-04-26 19:37:54,226  The loss during training is  :: 0.016569511964917183 
2019-04-26 19:37:54,405  The global step train is 3270
2019-04-26 19:37:54,548  The loss during training is  :: 0.019702471792697906 
2019-04-26 19:37:54,717  The global step train is 3271
2019-04-26 19:37:54,859  The loss during training is  :: 0.04395747557282448 
2019-04-26 19:37:55,030  The global step train is 3272
2019-04-26 19:37:55,171  The loss during training is  :: 0.007022991310805082 
2019-04-26 19:37:55,342  The global step train is 3273
2019-04-26 19:37:55,483  The loss during training is  :: 0.0038060443475842476 
2019-04-26 19:37:55,654  The global step train is 3274
2019-04-26 19:37:55,805  The loss during training is  :: 0.016687681898474693 
2019-04-26 19:37:55,976  The global step train is 3275
2019-04-26 19:37:56,117  The loss during training is  :: 0.0385904423892498 
2019-04-26 19:37:56,288  The global step train is 3276
2019-04-26 19:37:56,429  The loss during training is  :: 0.009533378295600414 
2019-04-26 19:37:56,600  The global step train is 3277
2019-04-26 19:37:56,749  The loss during training is  :: 0.007841234095394611 
2019-04-26 19:37:56,922  The global step train is 3278
2019-04-26 19:37:57,063  The loss during training is  :: 0.007215528283268213 
2019-04-26 19:37:57,234  The global step train is 3279
2019-04-26 19:37:57,374  The loss during training is  :: 0.008337815292179585 
2019-04-26 19:37:57,545  The global step train is 3280
2019-04-26 19:37:57,686  The loss during training is  :: 0.014956076629459858 
2019-04-26 19:37:57,857  The global step train is 3281
2019-04-26 19:37:57,998  The loss during training is  :: 0.01270537730306387 
2019-04-26 19:37:58,185  The global step train is 3282
2019-04-26 19:37:58,344  The loss during training is  :: 0.023980762809515 
2019-04-26 19:37:58,527  The global step train is 3283
2019-04-26 19:37:58,670  The loss during training is  :: 0.009028367698192596 
2019-04-26 19:37:58,841  The global step train is 3284
2019-04-26 19:37:58,982  The loss during training is  :: 0.01494908332824707 
2019-04-26 19:37:59,153  The global step train is 3285
2019-04-26 19:37:59,294  The loss during training is  :: 0.0067341201938688755 
2019-04-26 19:37:59,473  The global step train is 3286
2019-04-26 19:37:59,616  The loss during training is  :: 0.012675301171839237 
2019-04-26 19:37:59,787  The global step train is 3287
2019-04-26 19:37:59,928  The loss during training is  :: 0.012037970125675201 
2019-04-26 19:38:00,099  The global step train is 3288
2019-04-26 19:38:00,247  The loss during training is  :: 0.0027159531600773335 
2019-04-26 19:38:00,418  The global step train is 3289
2019-04-26 19:38:00,561  The loss during training is  :: 0.014867102727293968 
2019-04-26 19:38:00,732  The global step train is 3290
2019-04-26 19:38:00,873  The loss during training is  :: 0.005423956084996462 
2019-04-26 19:38:01,044  The global step train is 3291
2019-04-26 19:38:01,185  The loss during training is  :: 0.014384209178388119 
2019-04-26 19:38:01,356  The global step train is 3292
2019-04-26 19:38:01,505  The loss during training is  :: 0.0030731423757970333 
2019-04-26 19:38:01,678  The global step train is 3293
2019-04-26 19:38:01,819  The loss during training is  :: 0.018631821498274803 
2019-04-26 19:38:01,990  The global step train is 3294
2019-04-26 19:38:02,130  The loss during training is  :: 0.011274004355072975 
2019-04-26 19:38:02,310  The global step train is 3295
2019-04-26 19:38:02,450  The loss during training is  :: 0.00959477387368679 
2019-04-26 19:38:02,623  The global step train is 3296
2019-04-26 19:38:02,764  The loss during training is  :: 0.002751312218606472 
2019-04-26 19:38:02,943  The global step train is 3297
2019-04-26 19:38:03,084  The loss during training is  :: 0.04738239571452141 
2019-04-26 19:38:03,247  The global step train is 3298
2019-04-26 19:38:03,398  The loss during training is  :: 0.021409548819065094 
2019-04-26 19:38:03,569  The global step train is 3299
2019-04-26 19:38:03,709  The loss during training is  :: 0.016063479706645012 
2019-04-26 19:38:03,880  The global step train is 3300
2019-04-26 19:38:04,021  The loss during training is  :: 0.004846868570894003 
2019-04-26 19:38:04,192  The global step train is 3301
2019-04-26 19:38:04,333  The loss during training is  :: 0.010904226452112198 
2019-04-26 19:38:04,512  The global step train is 3302
2019-04-26 19:38:04,655  The loss during training is  :: 0.017104631289839745 
2019-04-26 19:38:04,826  The global step train is 3303
2019-04-26 19:38:04,965  The loss during training is  :: 0.00856143981218338 
2019-04-26 19:38:05,136  The global step train is 3304
2019-04-26 19:38:05,279  The loss during training is  :: 0.014669529162347317 
2019-04-26 19:38:05,450  The global step train is 3305
2019-04-26 19:38:05,589  The loss during training is  :: 0.005969002842903137 
2019-04-26 19:38:05,762  The global step train is 3306
2019-04-26 19:38:05,903  The loss during training is  :: 0.01007217075675726 
2019-04-26 19:38:06,074  The global step train is 3307
2019-04-26 19:38:06,223  The loss during training is  :: 0.024922918528318405 
2019-04-26 19:38:06,396  The global step train is 3308
2019-04-26 19:38:06,537  The loss during training is  :: 0.009346977807581425 
2019-04-26 19:38:06,708  The global step train is 3309
2019-04-26 19:38:06,857  The loss during training is  :: 0.017138183116912842 
2019-04-26 19:38:07,028  The global step train is 3310
2019-04-26 19:38:07,171  The loss during training is  :: 0.014443190768361092 
2019-04-26 19:38:07,340  The global step train is 3311
2019-04-26 19:38:07,483  The loss during training is  :: 0.019023211672902107 
2019-04-26 19:38:07,654  The global step train is 3312
2019-04-26 19:38:07,795  The loss during training is  :: 0.008032620884478092 
2019-04-26 19:38:07,966  The global step train is 3313
2019-04-26 19:38:08,107  The loss during training is  :: 0.0033307329285889864 
2019-04-26 19:38:08,298  The global step train is 3314
2019-04-26 19:38:08,438  The loss during training is  :: 0.015971940010786057 
2019-04-26 19:38:08,619  The global step train is 3315
2019-04-26 19:38:08,758  The loss during training is  :: 0.02306605689227581 
2019-04-26 19:38:08,931  The global step train is 3316
2019-04-26 19:38:09,072  The loss during training is  :: 0.005350176710635424 
2019-04-26 19:38:09,253  The global step train is 3317
2019-04-26 19:38:09,394  The loss during training is  :: 0.02141624689102173 
2019-04-26 19:38:09,565  The global step train is 3318
2019-04-26 19:38:09,705  The loss during training is  :: 0.006755012087523937 
2019-04-26 19:38:09,876  The global step train is 3319
2019-04-26 19:38:10,017  The loss during training is  :: 0.006676931399852037 
2019-04-26 19:38:10,196  The global step train is 3320
2019-04-26 19:38:10,339  The loss during training is  :: 0.010623333975672722 
2019-04-26 19:38:10,510  The global step train is 3321
2019-04-26 19:38:10,651  The loss during training is  :: 0.004662812687456608 
2019-04-26 19:38:10,841  The global step train is 3322
2019-04-26 19:38:10,980  The loss during training is  :: 0.0068964483216404915 
2019-04-26 19:38:11,153  The global step train is 3323
2019-04-26 19:38:11,292  The loss during training is  :: 0.014988228678703308 
2019-04-26 19:38:11,465  The global step train is 3324
2019-04-26 19:38:11,614  The loss during training is  :: 0.012494211085140705 
2019-04-26 19:38:11,787  The global step train is 3325
2019-04-26 19:38:11,928  The loss during training is  :: 0.0281168594956398 
2019-04-26 19:38:12,099  The global step train is 3326
2019-04-26 19:38:12,240  The loss during training is  :: 0.013453531078994274 
2019-04-26 19:38:12,411  The global step train is 3327
2019-04-26 19:38:12,552  The loss during training is  :: 0.02000734955072403 
2019-04-26 19:38:12,733  The global step train is 3328
2019-04-26 19:38:12,874  The loss during training is  :: 0.009084615856409073 
2019-04-26 19:38:13,045  The global step train is 3329
2019-04-26 19:38:13,186  The loss during training is  :: 0.0029158559627830982 
2019-04-26 19:38:13,357  The global step train is 3330
2019-04-26 19:38:13,498  The loss during training is  :: 0.009143409319221973 
2019-04-26 19:38:13,677  The global step train is 3331
2019-04-26 19:38:13,818  The loss during training is  :: 0.014644816517829895 
2019-04-26 19:38:13,981  The global step train is 3332
2019-04-26 19:38:14,130  The loss during training is  :: 0.009797289967536926 
2019-04-26 19:38:14,302  The global step train is 3333
2019-04-26 19:38:14,445  The loss during training is  :: 0.01446225494146347 
2019-04-26 19:38:14,616  The global step train is 3334
2019-04-26 19:38:14,756  The loss during training is  :: 0.012915327213704586 
2019-04-26 19:38:14,927  The global step train is 3335
2019-04-26 19:38:15,068  The loss during training is  :: 0.004460983444005251 
2019-04-26 19:38:15,239  The global step train is 3336
2019-04-26 19:38:15,380  The loss during training is  :: 0.009977868758141994 
2019-04-26 19:38:15,551  The global step train is 3337
2019-04-26 19:38:15,700  The loss during training is  :: 0.018203826621174812 
2019-04-26 19:38:15,863  The global step train is 3338
2019-04-26 19:38:16,014  The loss during training is  :: 0.026388878002762794 
2019-04-26 19:38:16,186  The global step train is 3339
2019-04-26 19:38:16,326  The loss during training is  :: 0.03411215916275978 
2019-04-26 19:38:16,508  The global step train is 3340
2019-04-26 19:38:16,649  The loss during training is  :: 0.009342603385448456 
2019-04-26 19:38:16,820  The global step train is 3341
2019-04-26 19:38:16,960  The loss during training is  :: 0.013685356825590134 
2019-04-26 19:38:17,132  The global step train is 3342
2019-04-26 19:38:17,273  The loss during training is  :: 0.011418594047427177 
2019-04-26 19:38:17,454  The global step train is 3343
2019-04-26 19:38:17,595  The loss during training is  :: 0.008205827325582504 
2019-04-26 19:38:17,766  The global step train is 3344
2019-04-26 19:38:17,896  The loss during training is  :: 0.018891748040914536 
2019-04-26 19:38:18,067  The global step train is 3345
2019-04-26 19:38:18,198  The loss during training is  :: 0.014163360930979252 
2019-04-26 19:38:18,349  The global step train is 3346
2019-04-26 19:38:18,480  The loss during training is  :: 0.0305214524269104 
2019-04-26 19:38:18,651  The global step train is 3347
2019-04-26 19:38:18,781  The loss during training is  :: 0.021434655413031578 
2019-04-26 19:38:18,942  The global step train is 3348
2019-04-26 19:38:19,082  The loss during training is  :: 0.018490444868803024 
2019-04-26 19:38:19,244  The global step train is 3349
2019-04-26 19:38:19,375  The loss during training is  :: 0.025179071351885796 
2019-04-26 19:38:19,536  The global step train is 3350
2019-04-26 19:38:19,667  The loss during training is  :: 0.022653458639979362 
2019-04-26 19:38:19,848  The global step train is 3351
2019-04-26 19:38:19,968  The loss during training is  :: 0.02021331526339054 
2019-04-26 19:38:20,129  The global step train is 3352
2019-04-26 19:38:20,260  The loss during training is  :: 0.023626115173101425 
2019-04-26 19:38:20,429  The global step train is 3353
2019-04-26 19:38:20,552  The loss during training is  :: 0.005370753817260265 
2019-04-26 19:38:20,723  The global step train is 3354
2019-04-26 19:38:20,863  The loss during training is  :: 0.0016418012091889977 
2019-04-26 19:38:21,024  The global step train is 3355
2019-04-26 19:38:21,155  The loss during training is  :: 0.01793205924332142 
2019-04-26 19:38:21,336  The global step train is 3356
2019-04-26 19:38:21,466  The loss during training is  :: 0.017084697261452675 
2019-04-26 19:38:21,627  The global step train is 3357
2019-04-26 19:38:21,756  The loss during training is  :: 0.0012834930093958974 
2019-04-26 19:38:21,919  The global step train is 3358
2019-04-26 19:38:22,049  The loss during training is  :: 0.007465578615665436 
2019-04-26 19:38:22,230  The global step train is 3359
2019-04-26 19:38:22,351  The loss during training is  :: 0.05095909535884857 
2019-04-26 19:38:22,512  The global step train is 3360
2019-04-26 19:38:22,520  Starting evaluation 
2019-04-26 19:38:22,663  The loss during eval_loss is  :: 0.05591762438416481
2019-04-26 19:38:22,663  The global step eval is 785
2019-04-26 19:38:22,793  The loss during eval_loss is  :: 0.04566746577620506
2019-04-26 19:38:22,793  The global step eval is 786
2019-04-26 19:38:22,914  The loss during eval_loss is  :: 0.009702918119728565
2019-04-26 19:38:22,922  The global step eval is 787
2019-04-26 19:38:23,025  The loss during eval_loss is  :: 0.013578471727669239
2019-04-26 19:38:23,025  The global step eval is 788
2019-04-26 19:38:23,136  The loss during eval_loss is  :: 0.030725227668881416
2019-04-26 19:38:23,136  The global step eval is 789
2019-04-26 19:38:23,257  The loss during eval_loss is  :: 0.08481063693761826
2019-04-26 19:38:23,257  The global step eval is 790
2019-04-26 19:38:23,366  The loss during eval_loss is  :: 0.0822308138012886
2019-04-26 19:38:23,368  The global step eval is 791
2019-04-26 19:38:23,469  The loss during eval_loss is  :: 0.004543088376522064
2019-04-26 19:38:23,469  The global step eval is 792
2019-04-26 19:38:23,598  The loss during eval_loss is  :: 0.07558077573776245
2019-04-26 19:38:23,600  The global step eval is 793
2019-04-26 19:38:23,701  The loss during eval_loss is  :: 0.00908720027655363
2019-04-26 19:38:23,701  The global step eval is 794
2019-04-26 19:38:23,810  The loss during eval_loss is  :: 0.09546609967947006
2019-04-26 19:38:23,812  The global step eval is 795
2019-04-26 19:38:23,913  The loss during eval_loss is  :: 0.04682406038045883
2019-04-26 19:38:23,921  The global step eval is 796
2019-04-26 19:38:24,024  The loss during eval_loss is  :: 0.025208644568920135
2019-04-26 19:38:24,024  The global step eval is 797
2019-04-26 19:38:24,155  The loss during eval_loss is  :: 0.05338328704237938
2019-04-26 19:38:24,155  The global step eval is 798
2019-04-26 19:38:24,266  The loss during eval_loss is  :: 0.03241869807243347
2019-04-26 19:38:24,274  The global step eval is 799
2019-04-26 19:38:24,387  The loss during eval_loss is  :: 0.0785943791270256
2019-04-26 19:38:24,387  The global step eval is 800
2019-04-26 19:38:24,497  The loss during eval_loss is  :: 0.10658052563667297
2019-04-26 19:38:24,507  The global step eval is 801
2019-04-26 19:38:24,608  The loss during eval_loss is  :: 0.1702113300561905
2019-04-26 19:38:24,616  The global step eval is 802
2019-04-26 19:38:24,729  The loss during eval_loss is  :: 0.03174563869833946
2019-04-26 19:38:24,729  The global step eval is 803
2019-04-26 19:38:24,840  The loss during eval_loss is  :: 0.054125379770994186
2019-04-26 19:38:24,848  The global step eval is 804
2019-04-26 19:38:24,961  The loss during eval_loss is  :: 0.062354203313589096
2019-04-26 19:38:24,961  The global step eval is 805
2019-04-26 19:38:25,082  The loss during eval_loss is  :: 0.04597374424338341
2019-04-26 19:38:25,082  The global step eval is 806
2019-04-26 19:38:25,203  The loss during eval_loss is  :: 0.04111430421471596
2019-04-26 19:38:25,205  The global step eval is 807
2019-04-26 19:38:25,313  The loss during eval_loss is  :: 0.03486825153231621
2019-04-26 19:38:25,314  The global step eval is 808
2019-04-26 19:38:25,427  The loss during eval_loss is  :: 0.04066003859043121
2019-04-26 19:38:25,428  The global step eval is 809
2019-04-26 19:38:25,538  The loss during eval_loss is  :: 0.008484738878905773
2019-04-26 19:38:25,539  The global step eval is 810
2019-04-26 19:38:25,662  The loss during eval_loss is  :: 0.03073197975754738
2019-04-26 19:38:25,664  The global step eval is 811
2019-04-26 19:38:25,781  The loss during eval_loss is  :: 0.023048099130392075
2019-04-26 19:38:25,783  The global step eval is 812
2019-04-26 19:38:25,893  The loss during eval_loss is  :: 0.07609698921442032
2019-04-26 19:38:25,895  The global step eval is 813
2019-04-26 19:38:26,012  The loss during eval_loss is  :: 0.02556818723678589
2019-04-26 19:38:26,013  The global step eval is 814
2019-04-26 19:38:26,128  The loss during eval_loss is  :: 0.016588661819696426
2019-04-26 19:38:26,130  The global step eval is 815
2019-04-26 19:38:26,239  The loss during eval_loss is  :: 0.0716468021273613
2019-04-26 19:38:26,241  The global step eval is 816
2019-04-26 19:38:26,360  The loss during eval_loss is  :: 0.05293834209442139
2019-04-26 19:38:26,362  The global step eval is 817
2019-04-26 19:38:26,473  The loss during eval_loss is  :: 0.14779624342918396
2019-04-26 19:38:26,473  The global step eval is 818
2019-04-26 19:38:26,584  The loss during eval_loss is  :: 0.02952902391552925
2019-04-26 19:38:26,592  The global step eval is 819
2019-04-26 19:38:26,715  The loss during eval_loss is  :: 0.1271604597568512
2019-04-26 19:38:26,715  The global step eval is 820
2019-04-26 19:38:26,836  The loss during eval_loss is  :: 0.03799837827682495
2019-04-26 19:38:26,836  The global step eval is 821
2019-04-26 19:38:26,937  The loss during eval_loss is  :: 0.06141693890094757
2019-04-26 19:38:26,937  The global step eval is 822
2019-04-26 19:38:27,048  The loss during eval_loss is  :: 0.0045387521386146545
2019-04-26 19:38:27,048  The global step eval is 823
2019-04-26 19:38:27,169  The loss during eval_loss is  :: 0.01925646699965
2019-04-26 19:38:27,169  The global step eval is 824
2019-04-26 19:38:27,291  The loss during eval_loss is  :: 0.036548715084791183
2019-04-26 19:38:27,291  The global step eval is 825
2019-04-26 19:38:27,412  The loss during eval_loss is  :: 0.023308096453547478
2019-04-26 19:38:27,420  The global step eval is 826
2019-04-26 19:38:27,523  The loss during eval_loss is  :: 0.09495148807764053
2019-04-26 19:38:27,523  The global step eval is 827
2019-04-26 19:38:27,634  The loss during eval_loss is  :: 0.04600488021969795
2019-04-26 19:38:27,642  The global step eval is 828
2019-04-26 19:38:27,735  The loss during eval_loss is  :: 0.12344063073396683
2019-04-26 19:38:27,743  The global step eval is 829
2019-04-26 19:38:27,856  The loss during eval_loss is  :: 0.035768672823905945
2019-04-26 19:38:27,856  The global step eval is 830
2019-04-26 19:38:27,975  The loss during eval_loss is  :: 0.14250126481056213
2019-04-26 19:38:27,977  The global step eval is 831
2019-04-26 19:38:28,099  The loss during eval_loss is  :: 0.08496646583080292
2019-04-26 19:38:28,099  The global step eval is 832
2019-04-26 19:38:28,235  The loss during eval_loss is  :: 0.028172718361020088
2019-04-26 19:38:28,237  The global step eval is 833
2019-04-26 19:38:28,363  The loss during eval_loss is  :: 0.09540031850337982
2019-04-26 19:38:28,365  The global step eval is 834
2019-04-26 19:38:28,481  The loss during eval_loss is  :: 0.09020408987998962
2019-04-26 19:38:28,481  The global step eval is 835
2019-04-26 19:38:28,592  The loss during eval_loss is  :: 0.02940092422068119
2019-04-26 19:38:28,592  The global step eval is 836
2019-04-26 19:38:28,703  The loss during eval_loss is  :: 0.028093239292502403
2019-04-26 19:38:28,703  The global step eval is 837
2019-04-26 19:38:28,812  The loss during eval_loss is  :: 0.011514654383063316
2019-04-26 19:38:28,814  The global step eval is 838
2019-04-26 19:38:28,923  The loss during eval_loss is  :: 0.06308942288160324
2019-04-26 19:38:28,925  The global step eval is 839
2019-04-26 19:38:29,036  The loss during eval_loss is  :: 0.06022161617875099
2019-04-26 19:38:29,036  The global step eval is 840
2019-04-26 19:38:29,046  Saved checkpoint: ./trained_model\step_14.pth.tar
2019-04-26 19:38:29,046  Removed checkpoint: ./trained_model\step_14.pth.tar
2019-04-26 19:38:29,157  The loss during training is  :: 0.002264340640977025 
2019-04-26 19:38:29,308  The global step train is 3361
2019-04-26 19:38:29,438  The loss during training is  :: 0.03992992267012596 
2019-04-26 19:38:29,607  The global step train is 3362
2019-04-26 19:38:29,740  The loss during training is  :: 0.030921706929802895 
2019-04-26 19:38:29,901  The global step train is 3363
2019-04-26 19:38:30,031  The loss during training is  :: 0.007869040593504906 
2019-04-26 19:38:30,202  The global step train is 3364
2019-04-26 19:38:30,333  The loss during training is  :: 0.011315898969769478 
2019-04-26 19:38:30,502  The global step train is 3365
2019-04-26 19:38:30,635  The loss during training is  :: 0.005866588093340397 
2019-04-26 19:38:30,805  The global step train is 3366
2019-04-26 19:38:30,936  The loss during training is  :: 0.02002617157995701 
2019-04-26 19:38:31,107  The global step train is 3367
2019-04-26 19:38:31,228  The loss during training is  :: 0.03234463930130005 
2019-04-26 19:38:31,388  The global step train is 3368
2019-04-26 19:38:31,519  The loss during training is  :: 0.053735993802547455 
2019-04-26 19:38:31,690  The global step train is 3369
2019-04-26 19:38:31,829  The loss during training is  :: 0.006077101919800043 
2019-04-26 19:38:31,990  The global step train is 3370
2019-04-26 19:38:32,123  The loss during training is  :: 0.0025628439616411924 
2019-04-26 19:38:32,284  The global step train is 3371
2019-04-26 19:38:32,422  The loss during training is  :: 0.023352747783064842 
2019-04-26 19:38:32,585  The global step train is 3372
2019-04-26 19:38:32,716  The loss during training is  :: 0.027873629704117775 
2019-04-26 19:38:32,877  The global step train is 3373
2019-04-26 19:38:33,007  The loss during training is  :: 0.005699043162167072 
2019-04-26 19:38:33,168  The global step train is 3374
2019-04-26 19:38:33,299  The loss during training is  :: 0.02535282075405121 
2019-04-26 19:38:33,470  The global step train is 3375
2019-04-26 19:38:33,600  The loss during training is  :: 0.004754845518618822 
2019-04-26 19:38:33,761  The global step train is 3376
2019-04-26 19:38:33,900  The loss during training is  :: 0.012608861550688744 
2019-04-26 19:38:34,063  The global step train is 3377
2019-04-26 19:38:34,193  The loss during training is  :: 0.015164989046752453 
2019-04-26 19:38:34,364  The global step train is 3378
2019-04-26 19:38:34,495  The loss during training is  :: 0.01680614799261093 
2019-04-26 19:38:34,656  The global step train is 3379
2019-04-26 19:38:34,796  The loss during training is  :: 0.03216632083058357 
2019-04-26 19:38:34,957  The global step train is 3380
2019-04-26 19:38:35,078  The loss during training is  :: 0.009130137972533703 
2019-04-26 19:38:35,247  The global step train is 3381
2019-04-26 19:38:35,380  The loss during training is  :: 0.005256811622530222 
2019-04-26 19:38:35,550  The global step train is 3382
2019-04-26 19:38:35,681  The loss during training is  :: 0.01630261167883873 
2019-04-26 19:38:35,852  The global step train is 3383
2019-04-26 19:38:35,983  The loss during training is  :: 0.023329926654696465 
2019-04-26 19:38:36,143  The global step train is 3384
2019-04-26 19:38:36,284  The loss during training is  :: 0.009562470018863678 
2019-04-26 19:38:36,445  The global step train is 3385
2019-04-26 19:38:36,576  The loss during training is  :: 0.011625731363892555 
2019-04-26 19:38:36,746  The global step train is 3386
2019-04-26 19:38:36,867  The loss during training is  :: 0.006887769792228937 
2019-04-26 19:38:37,036  The global step train is 3387
2019-04-26 19:38:37,169  The loss during training is  :: 0.00791535060852766 
2019-04-26 19:38:37,330  The global step train is 3388
2019-04-26 19:38:37,470  The loss during training is  :: 0.009905043058097363 
2019-04-26 19:38:37,631  The global step train is 3389
2019-04-26 19:38:37,762  The loss during training is  :: 0.009524993598461151 
2019-04-26 19:38:37,933  The global step train is 3390
2019-04-26 19:38:38,063  The loss during training is  :: 0.005173857789486647 
2019-04-26 19:38:38,234  The global step train is 3391
2019-04-26 19:38:38,376  The loss during training is  :: 0.008321854285895824 
2019-04-26 19:38:38,547  The global step train is 3392
2019-04-26 19:38:38,687  The loss during training is  :: 0.0030210367403924465 
2019-04-26 19:38:38,858  The global step train is 3393
2019-04-26 19:38:38,999  The loss during training is  :: 0.018525270745158195 
2019-04-26 19:38:39,170  The global step train is 3394
2019-04-26 19:38:39,311  The loss during training is  :: 0.026268519461154938 
2019-04-26 19:38:39,492  The global step train is 3395
2019-04-26 19:38:39,633  The loss during training is  :: 0.0010938612977042794 
2019-04-26 19:38:39,804  The global step train is 3396
2019-04-26 19:38:39,944  The loss during training is  :: 0.004463310353457928 
2019-04-26 19:38:40,119  The global step train is 3397
2019-04-26 19:38:40,261  The loss during training is  :: 0.005389852449297905 
2019-04-26 19:38:40,426  The global step train is 3398
2019-04-26 19:38:40,574  The loss during training is  :: 0.13212144374847412 
2019-04-26 19:38:40,747  The global step train is 3399
2019-04-26 19:38:40,888  The loss during training is  :: 0.007642011623829603 
2019-04-26 19:38:41,059  The global step train is 3400
2019-04-26 19:38:41,200  The loss during training is  :: 0.0035513401962816715 
2019-04-26 19:38:41,371  The global step train is 3401
2019-04-26 19:38:41,512  The loss during training is  :: 0.019420970231294632 
2019-04-26 19:38:41,683  The global step train is 3402
2019-04-26 19:38:41,832  The loss during training is  :: 0.006383027881383896 
2019-04-26 19:38:42,015  The global step train is 3403
2019-04-26 19:38:42,155  The loss during training is  :: 0.007739547174423933 
2019-04-26 19:38:42,326  The global step train is 3404
2019-04-26 19:38:42,467  The loss during training is  :: 0.009933233261108398 
2019-04-26 19:38:42,658  The global step train is 3405
2019-04-26 19:38:42,799  The loss during training is  :: 0.0039659724570810795 
2019-04-26 19:38:42,978  The global step train is 3406
2019-04-26 19:38:43,121  The loss during training is  :: 0.0060458374209702015 
2019-04-26 19:38:43,290  The global step train is 3407
2019-04-26 19:38:43,430  The loss during training is  :: 0.006180617026984692 
2019-04-26 19:38:43,601  The global step train is 3408
2019-04-26 19:38:43,744  The loss during training is  :: 0.010510816238820553 
2019-04-26 19:38:43,915  The global step train is 3409
2019-04-26 19:38:44,056  The loss during training is  :: 0.009943501092493534 
2019-04-26 19:38:44,227  The global step train is 3410
2019-04-26 19:38:44,368  The loss during training is  :: 0.004525076597929001 
2019-04-26 19:38:44,537  The global step train is 3411
2019-04-26 19:38:44,680  The loss during training is  :: 0.014202048070728779 
2019-04-26 19:38:44,851  The global step train is 3412
2019-04-26 19:38:44,991  The loss during training is  :: 0.0019466463709250093 
2019-04-26 19:38:45,162  The global step train is 3413
2019-04-26 19:38:45,303  The loss during training is  :: 0.017212286591529846 
2019-04-26 19:38:45,474  The global step train is 3414
2019-04-26 19:38:45,615  The loss during training is  :: 0.03280600532889366 
2019-04-26 19:38:45,794  The global step train is 3415
2019-04-26 19:38:45,927  The loss during training is  :: 0.024114392697811127 
2019-04-26 19:38:46,107  The global step train is 3416
2019-04-26 19:38:46,250  The loss during training is  :: 0.08085201680660248 
2019-04-26 19:38:46,421  The global step train is 3417
2019-04-26 19:38:46,562  The loss during training is  :: 0.0266848336905241 
2019-04-26 19:38:46,736  The global step train is 3418
2019-04-26 19:38:46,878  The loss during training is  :: 0.00457924185320735 
2019-04-26 19:38:47,048  The global step train is 3419
2019-04-26 19:38:47,186  The loss during training is  :: 0.0044622961431741714 
2019-04-26 19:38:47,357  The global step train is 3420
2019-04-26 19:38:47,498  The loss during training is  :: 0.011491851881146431 
2019-04-26 19:38:47,669  The global step train is 3421
2019-04-26 19:38:47,818  The loss during training is  :: 0.010797237046062946 
2019-04-26 19:38:48,041  The global step train is 3422
2019-04-26 19:38:48,187  The loss during training is  :: 0.006072056945413351 
2019-04-26 19:38:48,359  The global step train is 3423
2019-04-26 19:38:48,502  The loss during training is  :: 0.027787214145064354 
2019-04-26 19:38:48,679  The global step train is 3424
2019-04-26 19:38:48,817  The loss during training is  :: 0.0029419390484690666 
2019-04-26 19:38:48,987  The global step train is 3425
2019-04-26 19:38:49,130  The loss during training is  :: 0.01812049373984337 
2019-04-26 19:38:49,301  The global step train is 3426
2019-04-26 19:38:49,442  The loss during training is  :: 0.00794451404362917 
2019-04-26 19:38:49,613  The global step train is 3427
2019-04-26 19:38:49,764  The loss during training is  :: 0.006587533745914698 
2019-04-26 19:38:49,943  The global step train is 3428
2019-04-26 19:38:50,086  The loss during training is  :: 0.010224800556898117 
2019-04-26 19:38:50,265  The global step train is 3429
2019-04-26 19:38:50,408  The loss during training is  :: 0.009796028025448322 
2019-04-26 19:38:50,579  The global step train is 3430
2019-04-26 19:38:50,728  The loss during training is  :: 0.008344847708940506 
2019-04-26 19:38:50,901  The global step train is 3431
2019-04-26 19:38:51,042  The loss during training is  :: 0.04304996877908707 
2019-04-26 19:38:51,213  The global step train is 3432
2019-04-26 19:38:51,354  The loss during training is  :: 0.009595587849617004 
2019-04-26 19:38:51,536  The global step train is 3433
2019-04-26 19:38:51,676  The loss during training is  :: 0.01767895743250847 
2019-04-26 19:38:51,847  The global step train is 3434
2019-04-26 19:38:51,988  The loss during training is  :: 0.0076207066886126995 
2019-04-26 19:38:52,159  The global step train is 3435
2019-04-26 19:38:52,300  The loss during training is  :: 0.0071549322456121445 
2019-04-26 19:38:52,479  The global step train is 3436
2019-04-26 19:38:52,622  The loss during training is  :: 0.0034026592038571835 
2019-04-26 19:38:52,793  The global step train is 3437
2019-04-26 19:38:52,934  The loss during training is  :: 0.006343119777739048 
2019-04-26 19:38:53,115  The global step train is 3438
2019-04-26 19:38:53,264  The loss during training is  :: 0.024601401761174202 
2019-04-26 19:38:53,437  The global step train is 3439
2019-04-26 19:38:53,578  The loss during training is  :: 0.007863887585699558 
2019-04-26 19:38:53,749  The global step train is 3440
2019-04-26 19:38:53,890  The loss during training is  :: 0.0184710081666708 
2019-04-26 19:38:54,079  The global step train is 3441
2019-04-26 19:38:54,220  The loss during training is  :: 0.0075293732807040215 
2019-04-26 19:38:54,393  The global step train is 3442
2019-04-26 19:38:54,534  The loss during training is  :: 0.010455913841724396 
2019-04-26 19:38:54,713  The global step train is 3443
2019-04-26 19:38:54,856  The loss during training is  :: 0.0022699101828038692 
2019-04-26 19:38:55,033  The global step train is 3444
2019-04-26 19:38:55,170  The loss during training is  :: 0.015378198586404324 
2019-04-26 19:38:55,341  The global step train is 3445
2019-04-26 19:38:55,490  The loss during training is  :: 0.01011106837540865 
2019-04-26 19:38:55,673  The global step train is 3446
2019-04-26 19:38:55,813  The loss during training is  :: 0.015725355595350266 
2019-04-26 19:38:55,984  The global step train is 3447
2019-04-26 19:38:56,125  The loss during training is  :: 0.029575275257229805 
2019-04-26 19:38:56,307  The global step train is 3448
2019-04-26 19:38:56,448  The loss during training is  :: 0.04420420899987221 
2019-04-26 19:38:56,619  The global step train is 3449
2019-04-26 19:38:56,760  The loss during training is  :: 0.0020391622092574835 
2019-04-26 19:38:56,931  The global step train is 3450
2019-04-26 19:38:57,072  The loss during training is  :: 0.010747750289738178 
2019-04-26 19:38:57,244  The global step train is 3451
2019-04-26 19:38:57,395  The loss during training is  :: 0.013788747601211071 
2019-04-26 19:38:57,566  The global step train is 3452
2019-04-26 19:38:57,706  The loss during training is  :: 0.006842769216746092 
2019-04-26 19:38:57,878  The global step train is 3453
2019-04-26 19:38:58,018  The loss during training is  :: 0.01896519958972931 
2019-04-26 19:38:58,197  The global step train is 3454
2019-04-26 19:38:58,356  The loss during training is  :: 0.029566548764705658 
2019-04-26 19:38:58,539  The global step train is 3455
2019-04-26 19:38:58,688  The loss during training is  :: 0.014278926886618137 
2019-04-26 19:38:58,861  The global step train is 3456
2019-04-26 19:38:59,002  The loss during training is  :: 0.003689635545015335 
2019-04-26 19:38:59,184  The global step train is 3457
2019-04-26 19:38:59,324  The loss during training is  :: 0.02851410210132599 
2019-04-26 19:38:59,504  The global step train is 3458
2019-04-26 19:38:59,646  The loss during training is  :: 0.005925293080508709 
2019-04-26 19:38:59,818  The global step train is 3459
2019-04-26 19:38:59,958  The loss during training is  :: 0.009029798209667206 
2019-04-26 19:39:00,130  The global step train is 3460
2019-04-26 19:39:00,271  The loss during training is  :: 0.015171795152127743 
2019-04-26 19:39:00,442  The global step train is 3461
2019-04-26 19:39:00,591  The loss during training is  :: 0.010790074244141579 
2019-04-26 19:39:00,764  The global step train is 3462
2019-04-26 19:39:00,905  The loss during training is  :: 0.019870700314641 
2019-04-26 19:39:01,086  The global step train is 3463
2019-04-26 19:39:01,227  The loss during training is  :: 0.021963326260447502 
2019-04-26 19:39:01,399  The global step train is 3464
2019-04-26 19:39:01,550  The loss during training is  :: 0.009885425679385662 
2019-04-26 19:39:01,719  The global step train is 3465
2019-04-26 19:39:01,861  The loss during training is  :: 0.006547451019287109 
2019-04-26 19:39:02,030  The global step train is 3466
2019-04-26 19:39:02,174  The loss during training is  :: 0.02227035164833069 
2019-04-26 19:39:02,344  The global step train is 3467
2019-04-26 19:39:02,486  The loss during training is  :: 0.03499132767319679 
2019-04-26 19:39:02,656  The global step train is 3468
2019-04-26 19:39:02,786  The loss during training is  :: 0.012655089609324932 
2019-04-26 19:39:02,938  The global step train is 3469
2019-04-26 19:39:03,069  The loss during training is  :: 0.018177049234509468 
2019-04-26 19:39:03,230  The global step train is 3470
2019-04-26 19:39:03,361  The loss during training is  :: 0.03157584369182587 
2019-04-26 19:39:03,531  The global step train is 3471
2019-04-26 19:39:03,662  The loss during training is  :: 0.026863841339945793 
2019-04-26 19:39:03,831  The global step train is 3472
2019-04-26 19:39:03,964  The loss during training is  :: 0.012481502257287502 
2019-04-26 19:39:04,125  The global step train is 3473
2019-04-26 19:39:04,255  The loss during training is  :: 0.013229926116764545 
2019-04-26 19:39:04,426  The global step train is 3474
2019-04-26 19:39:04,557  The loss during training is  :: 0.010673856362700462 
2019-04-26 19:39:04,728  The global step train is 3475
2019-04-26 19:39:04,849  The loss during training is  :: 0.009689448401331902 
2019-04-26 19:39:05,019  The global step train is 3476
2019-04-26 19:39:05,153  The loss during training is  :: 0.016565026715397835 
2019-04-26 19:39:05,317  The global step train is 3477
2019-04-26 19:39:05,446  The loss during training is  :: 0.010517043992877007 
2019-04-26 19:39:05,622  The global step train is 3478
2019-04-26 19:39:05,755  The loss during training is  :: 0.010228964500129223 
2019-04-26 19:39:05,918  The global step train is 3479
2019-04-26 19:39:06,043  The loss during training is  :: 0.033328909426927567 
2019-04-26 19:39:06,209  The global step train is 3480
2019-04-26 19:39:06,348  The loss during training is  :: 0.013346942141652107 
2019-04-26 19:39:06,511  The global step train is 3481
2019-04-26 19:39:06,641  The loss during training is  :: 0.028482550755143166 
2019-04-26 19:39:06,812  The global step train is 3482
2019-04-26 19:39:06,943  The loss during training is  :: 0.006981401238590479 
2019-04-26 19:39:07,109  The global step train is 3483
2019-04-26 19:39:07,239  The loss during training is  :: 0.03152024745941162 
2019-04-26 19:39:07,397  The global step train is 3484
2019-04-26 19:39:07,526  The loss during training is  :: 0.009557714685797691 
2019-04-26 19:39:07,692  The global step train is 3485
2019-04-26 19:39:07,819  The loss during training is  :: 0.0030171966645866632 
2019-04-26 19:39:07,980  The global step train is 3486
2019-04-26 19:39:08,101  The loss during training is  :: 0.014514738693833351 
2019-04-26 19:39:08,272  The global step train is 3487
2019-04-26 19:39:08,403  The loss during training is  :: 0.02411125786602497 
2019-04-26 19:39:08,564  The global step train is 3488
2019-04-26 19:39:08,694  The loss during training is  :: 0.017946001142263412 
2019-04-26 19:39:08,865  The global step train is 3489
2019-04-26 19:39:09,004  The loss during training is  :: 0.007814254611730576 
2019-04-26 19:39:09,167  The global step train is 3490
2019-04-26 19:39:09,295  The loss during training is  :: 0.025279683992266655 
2019-04-26 19:39:09,468  The global step train is 3491
2019-04-26 19:39:09,599  The loss during training is  :: 0.010357853956520557 
2019-04-26 19:39:09,760  The global step train is 3492
2019-04-26 19:39:09,890  The loss during training is  :: 0.01307070441544056 
2019-04-26 19:39:10,059  The global step train is 3493
2019-04-26 19:39:10,190  The loss during training is  :: 0.026481088250875473 
2019-04-26 19:39:10,343  The global step train is 3494
2019-04-26 19:39:10,473  The loss during training is  :: 0.009098256006836891 
2019-04-26 19:39:10,644  The global step train is 3495
2019-04-26 19:39:10,775  The loss during training is  :: 0.008448400534689426 
2019-04-26 19:39:10,946  The global step train is 3496
2019-04-26 19:39:11,077  The loss during training is  :: 0.011469800025224686 
2019-04-26 19:39:11,248  The global step train is 3497
2019-04-26 19:39:11,376  The loss during training is  :: 0.00766297010704875 
2019-04-26 19:39:11,539  The global step train is 3498
2019-04-26 19:39:11,670  The loss during training is  :: 0.02836061455309391 
2019-04-26 19:39:11,839  The global step train is 3499
2019-04-26 19:39:11,971  The loss during training is  :: 0.023723367601633072 
2019-04-26 19:39:12,138  The global step train is 3500
2019-04-26 19:39:12,262  The loss during training is  :: 0.021243751049041748 
2019-04-26 19:39:12,424  The global step train is 3501
2019-04-26 19:39:12,555  The loss during training is  :: 0.021871598437428474 
2019-04-26 19:39:12,715  The global step train is 3502
2019-04-26 19:39:12,836  The loss during training is  :: 0.00538121210411191 
2019-04-26 19:39:12,997  The global step train is 3503
2019-04-26 19:39:13,127  The loss during training is  :: 0.044068239629268646 
2019-04-26 19:39:13,298  The global step train is 3504
2019-04-26 19:39:13,429  The loss during training is  :: 0.01150006614625454 
2019-04-26 19:39:13,610  The global step train is 3505
2019-04-26 19:39:13,741  The loss during training is  :: 0.04690210893750191 
2019-04-26 19:39:13,910  The global step train is 3506
2019-04-26 19:39:14,043  The loss during training is  :: 0.03497463837265968 
2019-04-26 19:39:14,204  The global step train is 3507
2019-04-26 19:39:14,343  The loss during training is  :: 0.018127543851733208 
2019-04-26 19:39:14,505  The global step train is 3508
2019-04-26 19:39:14,646  The loss during training is  :: 0.011069062165915966 
2019-04-26 19:39:14,797  The global step train is 3509
2019-04-26 19:39:14,938  The loss during training is  :: 0.00846480019390583 
2019-04-26 19:39:15,099  The global step train is 3510
2019-04-26 19:39:15,237  The loss during training is  :: 0.036301515996456146 
2019-04-26 19:39:15,401  The global step train is 3511
2019-04-26 19:39:15,531  The loss during training is  :: 0.004689423367381096 
2019-04-26 19:39:15,702  The global step train is 3512
2019-04-26 19:39:15,833  The loss during training is  :: 0.0034063721541315317 
2019-04-26 19:39:15,994  The global step train is 3513
2019-04-26 19:39:16,133  The loss during training is  :: 0.02334633469581604 
2019-04-26 19:39:16,295  The global step train is 3514
2019-04-26 19:39:16,426  The loss during training is  :: 0.01986856199800968 
2019-04-26 19:39:16,587  The global step train is 3515
2019-04-26 19:39:16,718  The loss during training is  :: 0.011046476662158966 
2019-04-26 19:39:16,889  The global step train is 3516
2019-04-26 19:39:17,019  The loss during training is  :: 0.017153551802039146 
2019-04-26 19:39:17,190  The global step train is 3517
2019-04-26 19:39:17,311  The loss during training is  :: 0.014902474358677864 
2019-04-26 19:39:17,480  The global step train is 3518
2019-04-26 19:39:17,612  The loss during training is  :: 0.011387920007109642 
2019-04-26 19:39:17,773  The global step train is 3519
2019-04-26 19:39:17,902  The loss during training is  :: 0.007811743300408125 
2019-04-26 19:39:18,065  The global step train is 3520
2019-04-26 19:39:18,204  The loss during training is  :: 0.020301783457398415 
2019-04-26 19:39:18,367  The global step train is 3521
2019-04-26 19:39:18,497  The loss during training is  :: 0.02351580560207367 
2019-04-26 19:39:18,658  The global step train is 3522
2019-04-26 19:39:18,797  The loss during training is  :: 0.01031235046684742 
2019-04-26 19:39:18,950  The global step train is 3523
2019-04-26 19:39:19,091  The loss during training is  :: 0.006551154423505068 
2019-04-26 19:39:19,270  The global step train is 3524
2019-04-26 19:39:19,400  The loss during training is  :: 0.012211491353809834 
2019-04-26 19:39:19,563  The global step train is 3525
2019-04-26 19:39:19,702  The loss during training is  :: 0.015164073556661606 
2019-04-26 19:39:19,865  The global step train is 3526
2019-04-26 19:39:19,995  The loss during training is  :: 0.007886365056037903 
2019-04-26 19:39:20,166  The global step train is 3527
2019-04-26 19:39:20,297  The loss during training is  :: 0.03175514191389084 
2019-04-26 19:39:20,468  The global step train is 3528
2019-04-26 19:39:20,599  The loss during training is  :: 0.015367139130830765 
2019-04-26 19:39:20,760  The global step train is 3529
2019-04-26 19:39:20,900  The loss during training is  :: 0.008050390519201756 
2019-04-26 19:39:21,061  The global step train is 3530
2019-04-26 19:39:21,200  The loss during training is  :: 0.01445048674941063 
2019-04-26 19:39:21,373  The global step train is 3531
2019-04-26 19:39:21,503  The loss during training is  :: 0.018333764746785164 
2019-04-26 19:39:21,664  The global step train is 3532
2019-04-26 19:39:21,803  The loss during training is  :: 0.003516972763463855 
2019-04-26 19:39:21,966  The global step train is 3533
2019-04-26 19:39:22,087  The loss during training is  :: 0.014624685049057007 
2019-04-26 19:39:22,256  The global step train is 3534
2019-04-26 19:39:22,390  The loss during training is  :: 0.046409592032432556 
2019-04-26 19:39:22,566  The global step train is 3535
2019-04-26 19:39:22,710  The loss during training is  :: 0.04756316915154457 
2019-04-26 19:39:22,881  The global step train is 3536
2019-04-26 19:39:23,019  The loss during training is  :: 0.007147207390516996 
2019-04-26 19:39:23,209  The global step train is 3537
2019-04-26 19:39:23,360  The loss during training is  :: 0.001356560387648642 
2019-04-26 19:39:23,540  The global step train is 3538
2019-04-26 19:39:23,687  The loss during training is  :: 0.005149879492819309 
2019-04-26 19:39:23,869  The global step train is 3539
2019-04-26 19:39:24,015  The loss during training is  :: 0.011966275982558727 
2019-04-26 19:39:24,193  The global step train is 3540
2019-04-26 19:39:24,345  The loss during training is  :: 0.00991215743124485 
2019-04-26 19:39:24,530  The global step train is 3541
2019-04-26 19:39:24,673  The loss during training is  :: 0.01555312518030405 
2019-04-26 19:39:24,849  The global step train is 3542
2019-04-26 19:39:24,992  The loss during training is  :: 0.03390812128782272 
2019-04-26 19:39:25,166  The global step train is 3543
2019-04-26 19:39:25,322  The loss during training is  :: 0.01797344535589218 
2019-04-26 19:39:25,512  The global step train is 3544
2019-04-26 19:39:25,663  The loss during training is  :: 0.01778412237763405 
2019-04-26 19:39:25,849  The global step train is 3545
2019-04-26 19:39:26,004  The loss during training is  :: 0.014905261807143688 
2019-04-26 19:39:26,200  The global step train is 3546
2019-04-26 19:39:26,351  The loss during training is  :: 0.010243800468742847 
2019-04-26 19:39:26,536  The global step train is 3547
2019-04-26 19:39:26,677  The loss during training is  :: 0.0022806930355727673 
2019-04-26 19:39:26,860  The global step train is 3548
2019-04-26 19:39:27,001  The loss during training is  :: 0.029622411355376244 
2019-04-26 19:39:27,182  The global step train is 3549
2019-04-26 19:39:27,323  The loss during training is  :: 0.00606789905577898 
2019-04-26 19:39:27,505  The global step train is 3550
2019-04-26 19:39:27,655  The loss during training is  :: 0.010326366871595383 
2019-04-26 19:39:27,836  The global step train is 3551
2019-04-26 19:39:27,967  The loss during training is  :: 0.011031191796064377 
2019-04-26 19:39:28,139  The global step train is 3552
2019-04-26 19:39:28,296  The loss during training is  :: 0.0025307338219136 
2019-04-26 19:39:28,506  The global step train is 3553
2019-04-26 19:39:28,662  The loss during training is  :: 0.025998283177614212 
2019-04-26 19:39:28,837  The global step train is 3554
2019-04-26 19:39:28,969  The loss during training is  :: 0.015150245279073715 
2019-04-26 19:39:29,137  The global step train is 3555
2019-04-26 19:39:29,271  The loss during training is  :: 0.009759976528584957 
2019-04-26 19:39:29,432  The global step train is 3556
2019-04-26 19:39:29,571  The loss during training is  :: 0.0038492234889417887 
2019-04-26 19:39:29,734  The global step train is 3557
2019-04-26 19:39:29,864  The loss during training is  :: 0.017476418986916542 
2019-04-26 19:39:30,033  The global step train is 3558
2019-04-26 19:39:30,168  The loss during training is  :: 0.007351436652243137 
2019-04-26 19:39:30,337  The global step train is 3559
2019-04-26 19:39:30,466  The loss during training is  :: 0.0056677404791116714 
2019-04-26 19:39:30,618  The global step train is 3560
2019-04-26 19:39:30,749  The loss during training is  :: 0.0021217281464487314 
2019-04-26 19:39:30,929  The global step train is 3561
2019-04-26 19:39:31,061  The loss during training is  :: 0.002985455095767975 
2019-04-26 19:39:31,242  The global step train is 3562
2019-04-26 19:39:31,373  The loss during training is  :: 0.0014013195177540183 
2019-04-26 19:39:31,544  The global step train is 3563
2019-04-26 19:39:31,675  The loss during training is  :: 0.002471017884090543 
2019-04-26 19:39:31,836  The global step train is 3564
2019-04-26 19:39:31,966  The loss during training is  :: 0.017233263701200485 
2019-04-26 19:39:32,127  The global step train is 3565
2019-04-26 19:39:32,248  The loss during training is  :: 0.005993671249598265 
2019-04-26 19:39:32,429  The global step train is 3566
2019-04-26 19:39:32,559  The loss during training is  :: 0.004879483953118324 
2019-04-26 19:39:32,720  The global step train is 3567
2019-04-26 19:39:32,851  The loss during training is  :: 0.02257656119763851 
2019-04-26 19:39:33,012  The global step train is 3568
2019-04-26 19:39:33,152  The loss during training is  :: 0.019107993692159653 
2019-04-26 19:39:33,313  The global step train is 3569
2019-04-26 19:39:33,452  The loss during training is  :: 0.006103254854679108 
2019-04-26 19:39:33,615  The global step train is 3570
2019-04-26 19:39:33,746  The loss during training is  :: 0.004808629397302866 
2019-04-26 19:39:33,917  The global step train is 3571
2019-04-26 19:39:34,038  The loss during training is  :: 0.007959352806210518 
2019-04-26 19:39:34,207  The global step train is 3572
2019-04-26 19:39:34,339  The loss during training is  :: 0.017928432673215866 
2019-04-26 19:39:34,511  The global step train is 3573
2019-04-26 19:39:34,641  The loss during training is  :: 0.012653252109885216 
2019-04-26 19:39:34,813  The global step train is 3574
2019-04-26 19:39:34,943  The loss during training is  :: 0.032217204570770264 
2019-04-26 19:39:35,114  The global step train is 3575
2019-04-26 19:39:35,243  The loss during training is  :: 0.015179157257080078 
2019-04-26 19:39:35,396  The global step train is 3576
2019-04-26 19:39:35,525  The loss during training is  :: 0.0016663932474330068 
2019-04-26 19:39:35,688  The global step train is 3577
2019-04-26 19:39:35,817  The loss during training is  :: 0.01504881214350462 
2019-04-26 19:39:35,998  The global step train is 3578
2019-04-26 19:39:36,128  The loss during training is  :: 0.023082930594682693 
2019-04-26 19:39:36,289  The global step train is 3579
2019-04-26 19:39:36,420  The loss during training is  :: 0.0019587771967053413 
2019-04-26 19:39:36,583  The global step train is 3580
2019-04-26 19:39:36,714  The loss during training is  :: 0.006494238972663879 
2019-04-26 19:39:36,875  The global step train is 3581
2019-04-26 19:39:37,014  The loss during training is  :: 0.014284947887063026 
2019-04-26 19:39:37,177  The global step train is 3582
2019-04-26 19:39:37,314  The loss during training is  :: 0.01735854707658291 
2019-04-26 19:39:37,476  The global step train is 3583
2019-04-26 19:39:37,607  The loss during training is  :: 0.010050942189991474 
2019-04-26 19:39:37,768  The global step train is 3584
2019-04-26 19:39:37,776  Starting evaluation 
2019-04-26 19:39:37,917  The loss during eval_loss is  :: 0.08325336128473282
2019-04-26 19:39:37,919  The global step eval is 841
2019-04-26 19:39:38,050  The loss during eval_loss is  :: 0.04714106768369675
2019-04-26 19:39:38,050  The global step eval is 842
2019-04-26 19:39:38,181  The loss during eval_loss is  :: 0.01055090595036745
2019-04-26 19:39:38,181  The global step eval is 843
2019-04-26 19:39:38,302  The loss during eval_loss is  :: 0.015934579074382782
2019-04-26 19:39:38,302  The global step eval is 844
2019-04-26 19:39:38,422  The loss during eval_loss is  :: 0.03748669847846031
2019-04-26 19:39:38,422  The global step eval is 845
2019-04-26 19:39:38,534  The loss during eval_loss is  :: 0.06988349556922913
2019-04-26 19:39:38,534  The global step eval is 846
2019-04-26 19:39:38,654  The loss during eval_loss is  :: 0.07321947067975998
2019-04-26 19:39:38,654  The global step eval is 847
2019-04-26 19:39:38,765  The loss during eval_loss is  :: 0.0070478948764503
2019-04-26 19:39:38,765  The global step eval is 848
2019-04-26 19:39:38,886  The loss during eval_loss is  :: 0.07761970162391663
2019-04-26 19:39:38,886  The global step eval is 849
2019-04-26 19:39:38,997  The loss during eval_loss is  :: 0.023815155029296875
2019-04-26 19:39:38,997  The global step eval is 850
2019-04-26 19:39:39,108  The loss during eval_loss is  :: 0.0974167138338089
2019-04-26 19:39:39,108  The global step eval is 851
2019-04-26 19:39:39,229  The loss during eval_loss is  :: 0.021434100344777107
2019-04-26 19:39:39,237  The global step eval is 852
2019-04-26 19:39:39,350  The loss during eval_loss is  :: 0.012801691889762878
2019-04-26 19:39:39,350  The global step eval is 853
2019-04-26 19:39:39,461  The loss during eval_loss is  :: 0.07614804804325104
2019-04-26 19:39:39,461  The global step eval is 854
2019-04-26 19:39:39,590  The loss during eval_loss is  :: 0.034917254000902176
2019-04-26 19:39:39,592  The global step eval is 855
2019-04-26 19:39:39,703  The loss during eval_loss is  :: 0.07618334144353867
2019-04-26 19:39:39,705  The global step eval is 856
2019-04-26 19:39:39,829  The loss during eval_loss is  :: 0.047417834401130676
2019-04-26 19:39:39,831  The global step eval is 857
2019-04-26 19:39:39,958  The loss during eval_loss is  :: 0.1370345950126648
2019-04-26 19:39:39,961  The global step eval is 858
2019-04-26 19:39:40,072  The loss during eval_loss is  :: 0.023987356573343277
2019-04-26 19:39:40,072  The global step eval is 859
2019-04-26 19:39:40,194  The loss during eval_loss is  :: 0.0227206964045763
2019-04-26 19:39:40,196  The global step eval is 860
2019-04-26 19:39:40,318  The loss during eval_loss is  :: 0.06052788347005844
2019-04-26 19:39:40,320  The global step eval is 861
2019-04-26 19:39:40,446  The loss during eval_loss is  :: 0.053310099989175797
2019-04-26 19:39:40,447  The global step eval is 862
2019-04-26 19:39:40,556  The loss during eval_loss is  :: 0.04808938875794411
2019-04-26 19:39:40,557  The global step eval is 863
2019-04-26 19:39:40,680  The loss during eval_loss is  :: 0.05298767238855362
2019-04-26 19:39:40,682  The global step eval is 864
2019-04-26 19:39:40,793  The loss during eval_loss is  :: 0.030444400385022163
2019-04-26 19:39:40,795  The global step eval is 865
2019-04-26 19:39:40,912  The loss during eval_loss is  :: 0.0017722639022395015
2019-04-26 19:39:40,914  The global step eval is 866
2019-04-26 19:39:41,034  The loss during eval_loss is  :: 0.0785941630601883
2019-04-26 19:39:41,034  The global step eval is 867
2019-04-26 19:39:41,155  The loss during eval_loss is  :: 0.034280046820640564
2019-04-26 19:39:41,155  The global step eval is 868
2019-04-26 19:39:41,276  The loss during eval_loss is  :: 0.05519004166126251
2019-04-26 19:39:41,276  The global step eval is 869
2019-04-26 19:39:41,406  The loss during eval_loss is  :: 0.03332196921110153
2019-04-26 19:39:41,406  The global step eval is 870
2019-04-26 19:39:41,548  The loss during eval_loss is  :: 0.04456295445561409
2019-04-26 19:39:41,548  The global step eval is 871
2019-04-26 19:39:41,669  The loss during eval_loss is  :: 0.040038105100393295
2019-04-26 19:39:41,669  The global step eval is 872
2019-04-26 19:39:41,790  The loss during eval_loss is  :: 0.04873490706086159
2019-04-26 19:39:41,790  The global step eval is 873
2019-04-26 19:39:41,901  The loss during eval_loss is  :: 0.11300084739923477
2019-04-26 19:39:41,901  The global step eval is 874
2019-04-26 19:39:42,012  The loss during eval_loss is  :: 0.04743277654051781
2019-04-26 19:39:42,012  The global step eval is 875
2019-04-26 19:39:42,122  The loss during eval_loss is  :: 0.1335327923297882
2019-04-26 19:39:42,122  The global step eval is 876
2019-04-26 19:39:42,233  The loss during eval_loss is  :: 0.06467727571725845
2019-04-26 19:39:42,233  The global step eval is 877
2019-04-26 19:39:42,355  The loss during eval_loss is  :: 0.058625608682632446
2019-04-26 19:39:42,355  The global step eval is 878
2019-04-26 19:39:42,495  The loss during eval_loss is  :: 0.00809965468943119
2019-04-26 19:39:42,499  The global step eval is 879
2019-04-26 19:39:42,644  The loss during eval_loss is  :: 0.01888231560587883
2019-04-26 19:39:42,646  The global step eval is 880
2019-04-26 19:39:42,781  The loss during eval_loss is  :: 0.02047152817249298
2019-04-26 19:39:42,783  The global step eval is 881
2019-04-26 19:39:42,912  The loss during eval_loss is  :: 0.02209273912012577
2019-04-26 19:39:42,914  The global step eval is 882
2019-04-26 19:39:43,034  The loss during eval_loss is  :: 0.07347707450389862
2019-04-26 19:39:43,036  The global step eval is 883
2019-04-26 19:39:43,153  The loss during eval_loss is  :: 0.03872178494930267
2019-04-26 19:39:43,155  The global step eval is 884
2019-04-26 19:39:43,283  The loss during eval_loss is  :: 0.15242227911949158
2019-04-26 19:39:43,285  The global step eval is 885
2019-04-26 19:39:43,425  The loss during eval_loss is  :: 0.025866607204079628
2019-04-26 19:39:43,427  The global step eval is 886
2019-04-26 19:39:43,608  The loss during eval_loss is  :: 0.10437807440757751
2019-04-26 19:39:43,611  The global step eval is 887
2019-04-26 19:39:43,767  The loss during eval_loss is  :: 0.08801529556512833
2019-04-26 19:39:43,767  The global step eval is 888
2019-04-26 19:39:43,898  The loss during eval_loss is  :: 0.01818612776696682
2019-04-26 19:39:43,898  The global step eval is 889
2019-04-26 19:39:44,049  The loss during eval_loss is  :: 0.05853050947189331
2019-04-26 19:39:44,057  The global step eval is 890
2019-04-26 19:39:44,254  The loss during eval_loss is  :: 0.08636857569217682
2019-04-26 19:39:44,257  The global step eval is 891
2019-04-26 19:39:44,504  The loss during eval_loss is  :: 0.03226302191615105
2019-04-26 19:39:44,507  The global step eval is 892
2019-04-26 19:39:44,727  The loss during eval_loss is  :: 0.04985084384679794
2019-04-26 19:39:44,730  The global step eval is 893
2019-04-26 19:39:44,901  The loss during eval_loss is  :: 0.007895202375948429
2019-04-26 19:39:44,904  The global step eval is 894
2019-04-26 19:39:45,054  The loss during eval_loss is  :: 0.04332537576556206
2019-04-26 19:39:45,056  The global step eval is 895
2019-04-26 19:39:45,192  The loss during eval_loss is  :: 0.06191244721412659
2019-04-26 19:39:45,194  The global step eval is 896
2019-04-26 19:39:45,204  Saved checkpoint: ./trained_model\step_15.pth.tar
2019-04-26 19:39:45,204  Removed checkpoint: ./trained_model\step_15.pth.tar
2019-04-26 19:39:45,323  The loss during training is  :: 0.004933421034365892 
2019-04-26 19:39:45,494  The global step train is 3585
2019-04-26 19:39:45,631  The loss during training is  :: 0.02360278181731701 
2019-04-26 19:39:45,802  The global step train is 3586
2019-04-26 19:39:45,953  The loss during training is  :: 0.006584173999726772 
2019-04-26 19:39:46,148  The global step train is 3587
2019-04-26 19:39:46,299  The loss during training is  :: 0.010937245562672615 
2019-04-26 19:39:46,476  The global step train is 3588
2019-04-26 19:39:46,616  The loss during training is  :: 0.018629513680934906 
2019-04-26 19:39:46,825  The global step train is 3589
2019-04-26 19:39:46,965  The loss during training is  :: 0.013499896042048931 
2019-04-26 19:39:47,141  The global step train is 3590
2019-04-26 19:39:47,290  The loss during training is  :: 0.009495404548943043 
2019-04-26 19:39:47,463  The global step train is 3591
2019-04-26 19:39:47,634  The loss during training is  :: 0.004944209940731525 
2019-04-26 19:39:47,876  The global step train is 3592
2019-04-26 19:39:48,027  The loss during training is  :: 0.002739610616117716 
2019-04-26 19:39:48,239  The global step train is 3593
2019-04-26 19:39:48,391  The loss during training is  :: 0.00838254950940609 
2019-04-26 19:39:48,572  The global step train is 3594
2019-04-26 19:39:48,727  The loss during training is  :: 0.005912787280976772 
2019-04-26 19:39:48,903  The global step train is 3595
2019-04-26 19:39:49,054  The loss during training is  :: 0.007151937577873468 
2019-04-26 19:39:49,298  The global step train is 3596
2019-04-26 19:39:49,530  The loss during training is  :: 0.010268154554069042 
2019-04-26 19:39:49,760  The global step train is 3597
2019-04-26 19:39:49,957  The loss during training is  :: 0.009015611372888088 
2019-04-26 19:39:50,255  The global step train is 3598
2019-04-26 19:39:50,459  The loss during training is  :: 0.006393759977072477 
2019-04-26 19:39:50,910  The global step train is 3599
2019-04-26 19:39:51,200  The loss during training is  :: 0.004276876337826252 
2019-04-26 19:39:51,410  The global step train is 3600
2019-04-26 19:39:51,583  The loss during training is  :: 0.015663862228393555 
2019-04-26 19:39:51,999  The global step train is 3601
2019-04-26 19:39:52,184  The loss during training is  :: 0.03366842865943909 
2019-04-26 19:39:52,385  The global step train is 3602
2019-04-26 19:39:52,546  The loss during training is  :: 0.0034647590946406126 
2019-04-26 19:39:52,748  The global step train is 3603
2019-04-26 19:39:52,919  The loss during training is  :: 0.005542736034840345 
2019-04-26 19:39:53,128  The global step train is 3604
2019-04-26 19:39:53,291  The loss during training is  :: 0.008726873435080051 
2019-04-26 19:39:53,471  The global step train is 3605
2019-04-26 19:39:53,607  The loss during training is  :: 0.019354747608304024 
2019-04-26 19:39:53,777  The global step train is 3606
2019-04-26 19:39:53,912  The loss during training is  :: 0.005997797474265099 
2019-04-26 19:39:54,072  The global step train is 3607
2019-04-26 19:39:54,203  The loss during training is  :: 0.023027194663882256 
2019-04-26 19:39:54,374  The global step train is 3608
2019-04-26 19:39:54,515  The loss during training is  :: 0.005727844312787056 
2019-04-26 19:39:54,685  The global step train is 3609
2019-04-26 19:39:54,821  The loss during training is  :: 0.013381026685237885 
2019-04-26 19:39:54,993  The global step train is 3610
2019-04-26 19:39:55,125  The loss during training is  :: 0.01863977499306202 
2019-04-26 19:39:55,294  The global step train is 3611
2019-04-26 19:39:55,415  The loss during training is  :: 0.003283713711425662 
2019-04-26 19:39:55,577  The global step train is 3612
2019-04-26 19:39:55,708  The loss during training is  :: 0.0055662281811237335 
2019-04-26 19:39:55,882  The global step train is 3613
2019-04-26 19:39:56,019  The loss during training is  :: 0.010033817030489445 
2019-04-26 19:39:56,189  The global step train is 3614
2019-04-26 19:39:56,326  The loss during training is  :: 0.008192319422960281 
2019-04-26 19:39:56,487  The global step train is 3615
2019-04-26 19:39:56,621  The loss during training is  :: 0.0017773373983800411 
2019-04-26 19:39:56,779  The global step train is 3616
2019-04-26 19:39:56,918  The loss during training is  :: 0.006633097305893898 
2019-04-26 19:39:57,089  The global step train is 3617
2019-04-26 19:39:57,222  The loss during training is  :: 0.01595901884138584 
2019-04-26 19:39:57,384  The global step train is 3618
2019-04-26 19:39:57,510  The loss during training is  :: 0.014458008110523224 
2019-04-26 19:39:57,673  The global step train is 3619
2019-04-26 19:39:57,805  The loss during training is  :: 0.017432181164622307 
2019-04-26 19:39:57,964  The global step train is 3620
2019-04-26 19:39:58,092  The loss during training is  :: 0.006358251441270113 
2019-04-26 19:39:58,275  The global step train is 3621
2019-04-26 19:39:58,427  The loss during training is  :: 0.005211305804550648 
2019-04-26 19:39:58,608  The global step train is 3622
2019-04-26 19:39:58,741  The loss during training is  :: 0.003133096732199192 
2019-04-26 19:39:58,909  The global step train is 3623
2019-04-26 19:39:59,042  The loss during training is  :: 0.00811789557337761 
2019-04-26 19:39:59,202  The global step train is 3624
2019-04-26 19:39:59,334  The loss during training is  :: 0.01291165966540575 
2019-04-26 19:39:59,505  The global step train is 3625
2019-04-26 19:39:59,636  The loss during training is  :: 0.003339344635605812 
2019-04-26 19:39:59,807  The global step train is 3626
2019-04-26 19:39:59,938  The loss during training is  :: 0.0036306127440184355 
2019-04-26 19:40:00,107  The global step train is 3627
2019-04-26 19:40:00,240  The loss during training is  :: 0.005420846864581108 
2019-04-26 19:40:00,412  The global step train is 3628
2019-04-26 19:40:00,549  The loss during training is  :: 0.010601774789392948 
2019-04-26 19:40:00,712  The global step train is 3629
2019-04-26 19:40:00,843  The loss during training is  :: 0.003818801138550043 
2019-04-26 19:40:01,014  The global step train is 3630
2019-04-26 19:40:01,145  The loss during training is  :: 0.011778850108385086 
2019-04-26 19:40:01,306  The global step train is 3631
2019-04-26 19:40:01,437  The loss during training is  :: 0.016833864152431488 
2019-04-26 19:40:01,598  The global step train is 3632
2019-04-26 19:40:01,736  The loss during training is  :: 0.027299677953124046 
2019-04-26 19:40:01,918  The global step train is 3633
2019-04-26 19:40:02,067  The loss during training is  :: 0.006381006445735693 
2019-04-26 19:40:02,266  The global step train is 3634
2019-04-26 19:40:02,453  The loss during training is  :: 0.01797095686197281 
2019-04-26 19:40:02,632  The global step train is 3635
2019-04-26 19:40:02,763  The loss during training is  :: 0.002754338551312685 
2019-04-26 19:40:02,932  The global step train is 3636
2019-04-26 19:40:03,072  The loss during training is  :: 0.006536553613841534 
2019-04-26 19:40:03,244  The global step train is 3637
2019-04-26 19:40:03,374  The loss during training is  :: 0.005254020914435387 
2019-04-26 19:40:03,543  The global step train is 3638
2019-04-26 19:40:03,676  The loss during training is  :: 0.0025713888462632895 
2019-04-26 19:40:03,845  The global step train is 3639
2019-04-26 19:40:03,968  The loss during training is  :: 0.0014692243421450257 
2019-04-26 19:40:04,152  The global step train is 3640
2019-04-26 19:40:04,291  The loss during training is  :: 0.003332551335915923 
2019-04-26 19:40:04,462  The global step train is 3641
2019-04-26 19:40:04,597  The loss during training is  :: 0.011001666076481342 
2019-04-26 19:40:04,761  The global step train is 3642
2019-04-26 19:40:04,890  The loss during training is  :: 0.005305662285536528 
2019-04-26 19:40:05,055  The global step train is 3643
2019-04-26 19:40:05,192  The loss during training is  :: 0.007594458293169737 
2019-04-26 19:40:05,349  The global step train is 3644
2019-04-26 19:40:05,479  The loss during training is  :: 0.004170436877757311 
2019-04-26 19:40:05,670  The global step train is 3645
2019-04-26 19:40:05,801  The loss during training is  :: 0.008578491397202015 
2019-04-26 19:40:05,962  The global step train is 3646
2019-04-26 19:40:06,092  The loss during training is  :: 0.024085907265543938 
2019-04-26 19:40:06,262  The global step train is 3647
2019-04-26 19:40:06,394  The loss during training is  :: 0.003405993804335594 
2019-04-26 19:40:06,555  The global step train is 3648
2019-04-26 19:40:06,686  The loss during training is  :: 0.04280991852283478 
2019-04-26 19:40:06,865  The global step train is 3649
2019-04-26 19:40:07,012  The loss during training is  :: 0.0066850152797997 
2019-04-26 19:40:07,196  The global step train is 3650
2019-04-26 19:40:07,358  The loss during training is  :: 0.005867789499461651 
2019-04-26 19:40:07,569  The global step train is 3651
2019-04-26 19:40:07,701  The loss during training is  :: 0.0024218845646828413 
2019-04-26 19:40:07,878  The global step train is 3652
2019-04-26 19:40:08,013  The loss during training is  :: 0.0075959269888699055 
2019-04-26 19:40:08,175  The global step train is 3653
2019-04-26 19:40:08,310  The loss during training is  :: 0.006833829917013645 
2019-04-26 19:40:08,500  The global step train is 3654
2019-04-26 19:40:08,649  The loss during training is  :: 0.024861134588718414 
2019-04-26 19:40:08,851  The global step train is 3655
2019-04-26 19:40:09,003  The loss during training is  :: 0.0036029466427862644 
2019-04-26 19:40:09,183  The global step train is 3656
2019-04-26 19:40:09,324  The loss during training is  :: 0.04392976313829422 
2019-04-26 19:40:09,539  The global step train is 3657
2019-04-26 19:40:09,710  The loss during training is  :: 0.011092606000602245 
2019-04-26 19:40:09,932  The global step train is 3658
2019-04-26 19:40:10,090  The loss during training is  :: 0.021422920748591423 
2019-04-26 19:40:10,288  The global step train is 3659
2019-04-26 19:40:10,444  The loss during training is  :: 0.005926548503339291 
2019-04-26 19:40:10,645  The global step train is 3660
2019-04-26 19:40:10,792  The loss during training is  :: 0.029156265780329704 
2019-04-26 19:40:10,965  The global step train is 3661
2019-04-26 19:40:11,106  The loss during training is  :: 0.003599532414227724 
2019-04-26 19:40:11,276  The global step train is 3662
2019-04-26 19:40:11,407  The loss during training is  :: 0.0023682403843849897 
2019-04-26 19:40:11,575  The global step train is 3663
2019-04-26 19:40:11,709  The loss during training is  :: 0.03839084133505821 
2019-04-26 19:40:11,873  The global step train is 3664
2019-04-26 19:40:12,010  The loss during training is  :: 0.002989921486005187 
2019-04-26 19:40:12,183  The global step train is 3665
2019-04-26 19:40:12,328  The loss during training is  :: 0.004327354487031698 
2019-04-26 19:40:12,502  The global step train is 3666
2019-04-26 19:40:12,642  The loss during training is  :: 0.007835718803107738 
2019-04-26 19:40:12,803  The global step train is 3667
2019-04-26 19:40:12,939  The loss during training is  :: 0.01229589432477951 
2019-04-26 19:40:13,111  The global step train is 3668
2019-04-26 19:40:13,304  The loss during training is  :: 0.006044737529009581 
2019-04-26 19:40:13,489  The global step train is 3669
2019-04-26 19:40:13,634  The loss during training is  :: 0.004993518348783255 
2019-04-26 19:40:13,846  The global step train is 3670
2019-04-26 19:40:14,116  The loss during training is  :: 0.011021560057997704 
2019-04-26 19:40:14,311  The global step train is 3671
2019-04-26 19:40:14,450  The loss during training is  :: 0.010417292825877666 
2019-04-26 19:40:14,623  The global step train is 3672
2019-04-26 19:40:14,752  The loss during training is  :: 0.013909743167459965 
2019-04-26 19:40:14,915  The global step train is 3673
2019-04-26 19:40:15,035  The loss during training is  :: 0.00645897863432765 
2019-04-26 19:40:15,205  The global step train is 3674
2019-04-26 19:40:15,358  The loss during training is  :: 0.004151055123656988 
2019-04-26 19:40:15,589  The global step train is 3675
2019-04-26 19:40:15,742  The loss during training is  :: 0.0064493753015995026 
2019-04-26 19:40:15,930  The global step train is 3676
2019-04-26 19:40:16,065  The loss during training is  :: 0.009898090735077858 
2019-04-26 19:40:16,233  The global step train is 3677
2019-04-26 19:40:16,364  The loss during training is  :: 0.011811953037977219 
2019-04-26 19:40:16,534  The global step train is 3678
2019-04-26 19:40:16,670  The loss during training is  :: 0.009773126803338528 
2019-04-26 19:40:16,843  The global step train is 3679
2019-04-26 19:40:17,006  The loss during training is  :: 0.03372063860297203 
2019-04-26 19:40:17,170  The global step train is 3680
2019-04-26 19:40:17,312  The loss during training is  :: 0.0018447431502863765 
2019-04-26 19:40:17,482  The global step train is 3681
2019-04-26 19:40:17,621  The loss during training is  :: 0.0119838397949934 
2019-04-26 19:40:17,785  The global step train is 3682
2019-04-26 19:40:17,925  The loss during training is  :: 0.001715094200335443 
2019-04-26 19:40:18,097  The global step train is 3683
2019-04-26 19:40:18,227  The loss during training is  :: 0.006108039058744907 
2019-04-26 19:40:18,398  The global step train is 3684
2019-04-26 19:40:18,529  The loss during training is  :: 0.009116440080106258 
2019-04-26 19:40:18,698  The global step train is 3685
2019-04-26 19:40:18,831  The loss during training is  :: 0.006626924034208059 
2019-04-26 19:40:18,992  The global step train is 3686
2019-04-26 19:40:19,133  The loss during training is  :: 0.009872007183730602 
2019-04-26 19:40:19,302  The global step train is 3687
2019-04-26 19:40:19,435  The loss during training is  :: 0.014927285723388195 
2019-04-26 19:40:19,605  The global step train is 3688
2019-04-26 19:40:19,736  The loss during training is  :: 0.016796179115772247 
2019-04-26 19:40:19,907  The global step train is 3689
2019-04-26 19:40:20,038  The loss during training is  :: 0.004637072794139385 
2019-04-26 19:40:20,209  The global step train is 3690
2019-04-26 19:40:20,350  The loss during training is  :: 0.02449914626777172 
2019-04-26 19:40:20,519  The global step train is 3691
2019-04-26 19:40:20,652  The loss during training is  :: 0.010905259288847446 
2019-04-26 19:40:20,812  The global step train is 3692
2019-04-26 19:40:20,952  The loss during training is  :: 0.00896220188587904 
2019-04-26 19:40:21,121  The global step train is 3693
2019-04-26 19:40:21,256  The loss during training is  :: 0.006661911029368639 
2019-04-26 19:40:21,436  The global step train is 3694
2019-04-26 19:40:21,568  The loss during training is  :: 0.006167233921587467 
2019-04-26 19:40:21,727  The global step train is 3695
2019-04-26 19:40:21,859  The loss during training is  :: 0.012328770942986012 
2019-04-26 19:40:22,019  The global step train is 3696
2019-04-26 19:40:22,155  The loss during training is  :: 0.005088898353278637 
2019-04-26 19:40:22,322  The global step train is 3697
2019-04-26 19:40:22,454  The loss during training is  :: 0.024899562820792198 
2019-04-26 19:40:22,620  The global step train is 3698
2019-04-26 19:40:22,748  The loss during training is  :: 0.0032640998251736164 
2019-04-26 19:40:22,915  The global step train is 3699
2019-04-26 19:40:23,045  The loss during training is  :: 0.01226024329662323 
2019-04-26 19:40:23,210  The global step train is 3700
2019-04-26 19:40:23,341  The loss during training is  :: 0.005762246437370777 
2019-04-26 19:40:23,510  The global step train is 3701
2019-04-26 19:40:23,643  The loss during training is  :: 0.016873124986886978 
2019-04-26 19:40:23,814  The global step train is 3702
2019-04-26 19:40:23,945  The loss during training is  :: 0.010030759498476982 
2019-04-26 19:40:24,111  The global step train is 3703
2019-04-26 19:40:24,245  The loss during training is  :: 0.026264820247888565 
2019-04-26 19:40:24,410  The global step train is 3704
2019-04-26 19:40:24,542  The loss during training is  :: 0.008356822654604912 
2019-04-26 19:40:24,709  The global step train is 3705
2019-04-26 19:40:24,838  The loss during training is  :: 0.010702133178710938 
2019-04-26 19:40:25,001  The global step train is 3706
2019-04-26 19:40:25,137  The loss during training is  :: 0.006440076977014542 
2019-04-26 19:40:25,300  The global step train is 3707
2019-04-26 19:40:25,433  The loss during training is  :: 0.0034325725864619017 
2019-04-26 19:40:25,594  The global step train is 3708
2019-04-26 19:40:25,733  The loss during training is  :: 0.009481830522418022 
2019-04-26 19:40:25,896  The global step train is 3709
2019-04-26 19:40:26,097  The loss during training is  :: 0.02725737914443016 
2019-04-26 19:40:26,261  The global step train is 3710
2019-04-26 19:40:26,394  The loss during training is  :: 0.008630869910120964 
2019-04-26 19:40:26,562  The global step train is 3711
2019-04-26 19:40:26,697  The loss during training is  :: 0.020060403272509575 
2019-04-26 19:40:26,863  The global step train is 3712
2019-04-26 19:40:26,990  The loss during training is  :: 0.0068450612016022205 
2019-04-26 19:40:27,158  The global step train is 3713
2019-04-26 19:40:27,290  The loss during training is  :: 0.006636269856244326 
2019-04-26 19:40:27,460  The global step train is 3714
2019-04-26 19:40:27,585  The loss during training is  :: 0.009857998229563236 
2019-04-26 19:40:27,756  The global step train is 3715
2019-04-26 19:40:27,890  The loss during training is  :: 0.006596279330551624 
2019-04-26 19:40:28,053  The global step train is 3716
2019-04-26 19:40:28,204  The loss during training is  :: 0.008174441754817963 
2019-04-26 19:40:28,404  The global step train is 3717
2019-04-26 19:40:28,551  The loss during training is  :: 0.03899195045232773 
2019-04-26 19:40:28,722  The global step train is 3718
2019-04-26 19:40:28,853  The loss during training is  :: 0.005026540718972683 
2019-04-26 19:40:29,020  The global step train is 3719
2019-04-26 19:40:29,162  The loss during training is  :: 0.015032323077321053 
2019-04-26 19:40:29,333  The global step train is 3720
2019-04-26 19:40:29,473  The loss during training is  :: 0.0037025706842541695 
2019-04-26 19:40:29,640  The global step train is 3721
2019-04-26 19:40:29,777  The loss during training is  :: 0.008849652484059334 
2019-04-26 19:40:29,944  The global step train is 3722
2019-04-26 19:40:30,078  The loss during training is  :: 0.0038878123741596937 
2019-04-26 19:40:30,242  The global step train is 3723
2019-04-26 19:40:30,383  The loss during training is  :: 0.007509005721658468 
2019-04-26 19:40:30,554  The global step train is 3724
2019-04-26 19:40:30,685  The loss during training is  :: 0.035595644265413284 
2019-04-26 19:40:30,846  The global step train is 3725
2019-04-26 19:40:30,977  The loss during training is  :: 0.005288839340209961 
2019-04-26 19:40:31,138  The global step train is 3726
2019-04-26 19:40:31,269  The loss during training is  :: 0.01518610306084156 
2019-04-26 19:40:31,440  The global step train is 3727
2019-04-26 19:40:31,620  The loss during training is  :: 0.012572525069117546 
2019-04-26 19:40:31,792  The global step train is 3728
2019-04-26 19:40:31,922  The loss during training is  :: 0.10677492618560791 
2019-04-26 19:40:32,103  The global step train is 3729
2019-04-26 19:40:32,234  The loss during training is  :: 0.006280924659222364 
2019-04-26 19:40:32,406  The global step train is 3730
2019-04-26 19:40:32,535  The loss during training is  :: 0.017737649381160736 
2019-04-26 19:40:32,698  The global step train is 3731
2019-04-26 19:40:32,837  The loss during training is  :: 0.036383021622896194 
2019-04-26 19:40:33,008  The global step train is 3732
2019-04-26 19:40:33,180  The loss during training is  :: 0.006806246470659971 
2019-04-26 19:40:33,408  The global step train is 3733
2019-04-26 19:40:33,564  The loss during training is  :: 0.027128692716360092 
2019-04-26 19:40:33,738  The global step train is 3734
2019-04-26 19:40:33,878  The loss during training is  :: 0.00814170204102993 
2019-04-26 19:40:34,053  The global step train is 3735
2019-04-26 19:40:34,192  The loss during training is  :: 0.027854621410369873 
2019-04-26 19:40:34,354  The global step train is 3736
2019-04-26 19:40:34,483  The loss during training is  :: 0.004029051400721073 
2019-04-26 19:40:34,646  The global step train is 3737
2019-04-26 19:40:34,787  The loss during training is  :: 0.019788742065429688 
2019-04-26 19:40:34,948  The global step train is 3738
2019-04-26 19:40:35,089  The loss during training is  :: 0.0031364441383630037 
2019-04-26 19:40:35,270  The global step train is 3739
2019-04-26 19:40:35,409  The loss during training is  :: 0.014141661114990711 
2019-04-26 19:40:35,572  The global step train is 3740
2019-04-26 19:40:35,702  The loss during training is  :: 0.029261639341711998 
2019-04-26 19:40:35,874  The global step train is 3741
2019-04-26 19:40:36,004  The loss during training is  :: 0.02378145605325699 
2019-04-26 19:40:36,175  The global step train is 3742
2019-04-26 19:40:36,306  The loss during training is  :: 0.024796372279524803 
2019-04-26 19:40:36,477  The global step train is 3743
2019-04-26 19:40:36,626  The loss during training is  :: 0.005645316559821367 
2019-04-26 19:40:36,789  The global step train is 3744
2019-04-26 19:40:36,928  The loss during training is  :: 0.013606392778456211 
2019-04-26 19:40:37,091  The global step train is 3745
2019-04-26 19:40:37,232  The loss during training is  :: 0.007330974098294973 
2019-04-26 19:40:37,403  The global step train is 3746
2019-04-26 19:40:37,533  The loss during training is  :: 0.029640203341841698 
2019-04-26 19:40:37,702  The global step train is 3747
2019-04-26 19:40:37,825  The loss during training is  :: 0.0017061011167243123 
2019-04-26 19:40:37,986  The global step train is 3748
2019-04-26 19:40:38,118  The loss during training is  :: 0.006297868210822344 
2019-04-26 19:40:38,283  The global step train is 3749
2019-04-26 19:40:38,415  The loss during training is  :: 0.030560096725821495 
2019-04-26 19:40:38,577  The global step train is 3750
2019-04-26 19:40:38,713  The loss during training is  :: 0.012537539936602116 
2019-04-26 19:40:38,876  The global step train is 3751
2019-04-26 19:40:39,011  The loss during training is  :: 0.002838525688275695 
2019-04-26 19:40:39,175  The global step train is 3752
2019-04-26 19:40:39,306  The loss during training is  :: 0.006299457512795925 
2019-04-26 19:40:39,484  The global step train is 3753
2019-04-26 19:40:39,645  The loss during training is  :: 0.017705122008919716 
2019-04-26 19:40:39,819  The global step train is 3754
2019-04-26 19:40:39,957  The loss during training is  :: 0.005622917786240578 
2019-04-26 19:40:40,128  The global step train is 3755
2019-04-26 19:40:40,272  The loss during training is  :: 0.004521579947322607 
2019-04-26 19:40:40,454  The global step train is 3756
2019-04-26 19:40:40,589  The loss during training is  :: 0.005828981287777424 
2019-04-26 19:40:40,759  The global step train is 3757
2019-04-26 19:40:40,895  The loss during training is  :: 0.00843579601496458 
2019-04-26 19:40:41,071  The global step train is 3758
2019-04-26 19:40:41,209  The loss during training is  :: 0.049085650593042374 
2019-04-26 19:40:41,380  The global step train is 3759
2019-04-26 19:40:41,511  The loss during training is  :: 0.00944222416728735 
2019-04-26 19:40:41,685  The global step train is 3760
2019-04-26 19:40:41,821  The loss during training is  :: 0.010090440511703491 
2019-04-26 19:40:41,992  The global step train is 3761
2019-04-26 19:40:42,133  The loss during training is  :: 0.015116333961486816 
2019-04-26 19:40:42,294  The global step train is 3762
2019-04-26 19:40:42,435  The loss during training is  :: 0.011948556639254093 
2019-04-26 19:40:42,606  The global step train is 3763
2019-04-26 19:40:42,737  The loss during training is  :: 0.006042477209120989 
2019-04-26 19:40:42,908  The global step train is 3764
2019-04-26 19:40:43,069  The loss during training is  :: 0.027248891070485115 
2019-04-26 19:40:43,430  The global step train is 3765
2019-04-26 19:40:43,594  The loss during training is  :: 0.018204545602202415 
2019-04-26 19:40:43,775  The global step train is 3766
2019-04-26 19:40:43,916  The loss during training is  :: 0.011120917275547981 
2019-04-26 19:40:44,077  The global step train is 3767
2019-04-26 19:40:44,218  The loss during training is  :: 0.026159588247537613 
2019-04-26 19:40:44,379  The global step train is 3768
2019-04-26 19:40:44,510  The loss during training is  :: 0.012339567765593529 
2019-04-26 19:40:44,683  The global step train is 3769
2019-04-26 19:40:44,813  The loss during training is  :: 0.01452143955975771 
2019-04-26 19:40:44,973  The global step train is 3770
2019-04-26 19:40:45,112  The loss during training is  :: 0.0034667111467570066 
2019-04-26 19:40:45,279  The global step train is 3771
2019-04-26 19:40:45,414  The loss during training is  :: 0.01740448921918869 
2019-04-26 19:40:45,576  The global step train is 3772
2019-04-26 19:40:45,715  The loss during training is  :: 0.03127213194966316 
2019-04-26 19:40:45,883  The global step train is 3773
2019-04-26 19:40:46,016  The loss during training is  :: 0.003681182861328125 
2019-04-26 19:40:46,172  The global step train is 3774
2019-04-26 19:40:46,313  The loss during training is  :: 0.013565562665462494 
2019-04-26 19:40:46,472  The global step train is 3775
2019-04-26 19:40:46,605  The loss during training is  :: 0.01784750632941723 
2019-04-26 19:40:46,766  The global step train is 3776
2019-04-26 19:40:46,904  The loss during training is  :: 0.008853422477841377 
2019-04-26 19:40:47,075  The global step train is 3777
2019-04-26 19:40:47,206  The loss during training is  :: 0.009898529388010502 
2019-04-26 19:40:47,369  The global step train is 3778
2019-04-26 19:40:47,510  The loss during training is  :: 0.003239939920604229 
2019-04-26 19:40:47,681  The global step train is 3779
2019-04-26 19:40:47,812  The loss during training is  :: 0.0022181509993970394 
2019-04-26 19:40:47,983  The global step train is 3780
2019-04-26 19:40:48,113  The loss during training is  :: 0.030636558309197426 
2019-04-26 19:40:48,284  The global step train is 3781
2019-04-26 19:40:48,423  The loss during training is  :: 0.0012854543747380376 
2019-04-26 19:40:48,586  The global step train is 3782
2019-04-26 19:40:48,717  The loss during training is  :: 0.0103314109146595 
2019-04-26 19:40:48,878  The global step train is 3783
2019-04-26 19:40:49,009  The loss during training is  :: 0.009827188216149807 
2019-04-26 19:40:49,171  The global step train is 3784
2019-04-26 19:40:49,305  The loss during training is  :: 0.025447936728596687 
2019-04-26 19:40:49,475  The global step train is 3785
2019-04-26 19:40:49,605  The loss during training is  :: 0.01613060012459755 
2019-04-26 19:40:49,775  The global step train is 3786
2019-04-26 19:40:49,910  The loss during training is  :: 0.010289497673511505 
2019-04-26 19:40:50,083  The global step train is 3787
2019-04-26 19:40:50,217  The loss during training is  :: 0.01829770766198635 
2019-04-26 19:40:50,380  The global step train is 3788
2019-04-26 19:40:50,511  The loss during training is  :: 0.003955376800149679 
2019-04-26 19:40:50,682  The global step train is 3789
2019-04-26 19:40:50,813  The loss during training is  :: 0.028554227203130722 
2019-04-26 19:40:50,985  The global step train is 3790
2019-04-26 19:40:51,122  The loss during training is  :: 0.006938803941011429 
2019-04-26 19:40:51,297  The global step train is 3791
2019-04-26 19:40:51,437  The loss during training is  :: 0.012359794229269028 
2019-04-26 19:40:51,608  The global step train is 3792
2019-04-26 19:40:51,739  The loss during training is  :: 0.010919383727014065 
2019-04-26 19:40:51,910  The global step train is 3793
2019-04-26 19:40:52,051  The loss during training is  :: 0.011999066919088364 
2019-04-26 19:40:52,273  The global step train is 3794
2019-04-26 19:40:52,422  The loss during training is  :: 0.015238507650792599 
2019-04-26 19:40:52,585  The global step train is 3795
2019-04-26 19:40:52,726  The loss during training is  :: 0.0072037759236991405 
2019-04-26 19:40:52,947  The global step train is 3796
2019-04-26 19:40:53,108  The loss during training is  :: 0.009086021222174168 
2019-04-26 19:40:53,310  The global step train is 3797
2019-04-26 19:40:53,461  The loss during training is  :: 0.014152511022984982 
2019-04-26 19:40:53,702  The global step train is 3798
2019-04-26 19:40:53,866  The loss during training is  :: 0.010961446911096573 
2019-04-26 19:40:54,070  The global step train is 3799
2019-04-26 19:40:54,209  The loss during training is  :: 0.014587990008294582 
2019-04-26 19:40:54,384  The global step train is 3800
2019-04-26 19:40:54,519  The loss during training is  :: 0.003210074035450816 
2019-04-26 19:40:54,684  The global step train is 3801
2019-04-26 19:40:54,820  The loss during training is  :: 0.00289573660120368 
2019-04-26 19:40:54,984  The global step train is 3802
2019-04-26 19:40:55,119  The loss during training is  :: 0.01358728762716055 
2019-04-26 19:40:55,287  The global step train is 3803
2019-04-26 19:40:55,421  The loss during training is  :: 0.0075867366977036 
2019-04-26 19:40:55,586  The global step train is 3804
2019-04-26 19:40:55,717  The loss during training is  :: 0.0019789505749940872 
2019-04-26 19:40:55,885  The global step train is 3805
2019-04-26 19:40:56,011  The loss during training is  :: 0.016783080995082855 
2019-04-26 19:40:56,200  The global step train is 3806
2019-04-26 19:40:56,335  The loss during training is  :: 0.008268124423921108 
2019-04-26 19:40:56,493  The global step train is 3807
2019-04-26 19:40:56,630  The loss during training is  :: 0.018890786916017532 
2019-04-26 19:40:56,795  The global step train is 3808
2019-04-26 19:40:56,795  Starting evaluation 
2019-04-26 19:40:56,944  The loss during eval_loss is  :: 0.04264137148857117
2019-04-26 19:40:56,946  The global step eval is 897
2019-04-26 19:40:57,082  The loss during eval_loss is  :: 0.046965666115283966
2019-04-26 19:40:57,084  The global step eval is 898
2019-04-26 19:40:57,200  The loss during eval_loss is  :: 0.014464848674833775
2019-04-26 19:40:57,202  The global step eval is 899
2019-04-26 19:40:57,327  The loss during eval_loss is  :: 0.022060632705688477
2019-04-26 19:40:57,330  The global step eval is 900
2019-04-26 19:40:57,446  The loss during eval_loss is  :: 0.03725776821374893
2019-04-26 19:40:57,448  The global step eval is 901
2019-04-26 19:40:57,560  The loss during eval_loss is  :: 0.08478701859712601
2019-04-26 19:40:57,560  The global step eval is 902
2019-04-26 19:40:57,691  The loss during eval_loss is  :: 0.08627362549304962
2019-04-26 19:40:57,693  The global step eval is 903
2019-04-26 19:40:57,823  The loss during eval_loss is  :: 0.0040761567652225494
2019-04-26 19:40:57,825  The global step eval is 904
2019-04-26 19:40:57,944  The loss during eval_loss is  :: 0.1288313865661621
2019-04-26 19:40:57,944  The global step eval is 905
2019-04-26 19:40:58,088  The loss during eval_loss is  :: 0.026035867631435394
2019-04-26 19:40:58,090  The global step eval is 906
2019-04-26 19:40:58,222  The loss during eval_loss is  :: 0.0885348990559578
2019-04-26 19:40:58,224  The global step eval is 907
2019-04-26 19:40:58,363  The loss during eval_loss is  :: 0.047925058752298355
2019-04-26 19:40:58,365  The global step eval is 908
2019-04-26 19:40:58,488  The loss during eval_loss is  :: 0.027173776179552078
2019-04-26 19:40:58,490  The global step eval is 909
2019-04-26 19:40:58,601  The loss during eval_loss is  :: 0.0890236645936966
2019-04-26 19:40:58,601  The global step eval is 910
2019-04-26 19:40:58,724  The loss during eval_loss is  :: 0.042258504778146744
2019-04-26 19:40:58,724  The global step eval is 911
2019-04-26 19:40:58,855  The loss during eval_loss is  :: 0.04840394854545593
2019-04-26 19:40:58,855  The global step eval is 912
2019-04-26 19:40:58,974  The loss during eval_loss is  :: 0.0690285712480545
2019-04-26 19:40:58,976  The global step eval is 913
2019-04-26 19:40:59,077  The loss during eval_loss is  :: 0.1874689906835556
2019-04-26 19:40:59,077  The global step eval is 914
2019-04-26 19:40:59,188  The loss during eval_loss is  :: 0.023955093696713448
2019-04-26 19:40:59,188  The global step eval is 915
2019-04-26 19:40:59,297  The loss during eval_loss is  :: 0.04263140633702278
2019-04-26 19:40:59,299  The global step eval is 916
2019-04-26 19:40:59,420  The loss during eval_loss is  :: 0.09184470027685165
2019-04-26 19:40:59,420  The global step eval is 917
2019-04-26 19:40:59,542  The loss during eval_loss is  :: 0.03820810094475746
2019-04-26 19:40:59,542  The global step eval is 918
2019-04-26 19:40:59,662  The loss during eval_loss is  :: 0.031727612018585205
2019-04-26 19:40:59,662  The global step eval is 919
2019-04-26 19:40:59,773  The loss during eval_loss is  :: 0.05850129574537277
2019-04-26 19:40:59,773  The global step eval is 920
2019-04-26 19:40:59,894  The loss during eval_loss is  :: 0.04994703084230423
2019-04-26 19:40:59,894  The global step eval is 921
2019-04-26 19:41:00,025  The loss during eval_loss is  :: 0.004859949927777052
2019-04-26 19:41:00,027  The global step eval is 922
2019-04-26 19:41:00,152  The loss during eval_loss is  :: 0.06413643807172775
2019-04-26 19:41:00,154  The global step eval is 923
2019-04-26 19:41:00,276  The loss during eval_loss is  :: 0.041397690773010254
2019-04-26 19:41:00,276  The global step eval is 924
2019-04-26 19:41:00,385  The loss during eval_loss is  :: 0.06843927502632141
2019-04-26 19:41:00,387  The global step eval is 925
2019-04-26 19:41:00,508  The loss during eval_loss is  :: 0.035641953349113464
2019-04-26 19:41:00,508  The global step eval is 926
2019-04-26 19:41:00,623  The loss during eval_loss is  :: 0.038099147379398346
2019-04-26 19:41:00,624  The global step eval is 927
2019-04-26 19:41:00,740  The loss during eval_loss is  :: 0.03753317892551422
2019-04-26 19:41:00,748  The global step eval is 928
2019-04-26 19:41:00,870  The loss during eval_loss is  :: 0.05442263185977936
2019-04-26 19:41:00,870  The global step eval is 929
2019-04-26 19:41:01,002  The loss during eval_loss is  :: 0.1440463811159134
2019-04-26 19:41:01,002  The global step eval is 930
2019-04-26 19:41:01,113  The loss during eval_loss is  :: 0.08224735409021378
2019-04-26 19:41:01,113  The global step eval is 931
2019-04-26 19:41:01,223  The loss during eval_loss is  :: 0.13354189693927765
2019-04-26 19:41:01,231  The global step eval is 932
2019-04-26 19:41:01,334  The loss during eval_loss is  :: 0.02898348495364189
2019-04-26 19:41:01,334  The global step eval is 933
2019-04-26 19:41:01,455  The loss during eval_loss is  :: 0.056964173913002014
2019-04-26 19:41:01,455  The global step eval is 934
2019-04-26 19:41:01,574  The loss during eval_loss is  :: 0.006595510058104992
2019-04-26 19:41:01,576  The global step eval is 935
2019-04-26 19:41:01,687  The loss during eval_loss is  :: 0.013318615034222603
2019-04-26 19:41:01,687  The global step eval is 936
2019-04-26 19:41:01,808  The loss during eval_loss is  :: 0.05569480359554291
2019-04-26 19:41:01,808  The global step eval is 937
2019-04-26 19:41:01,909  The loss during eval_loss is  :: 0.03538839519023895
2019-04-26 19:41:01,917  The global step eval is 938
2019-04-26 19:41:02,032  The loss during eval_loss is  :: 0.10508807003498077
2019-04-26 19:41:02,034  The global step eval is 939
2019-04-26 19:41:02,154  The loss during eval_loss is  :: 0.06250643730163574
2019-04-26 19:41:02,155  The global step eval is 940
2019-04-26 19:41:02,268  The loss during eval_loss is  :: 0.09075996279716492
2019-04-26 19:41:02,270  The global step eval is 941
2019-04-26 19:41:02,395  The loss during eval_loss is  :: 0.03415991738438606
2019-04-26 19:41:02,396  The global step eval is 942
2019-04-26 19:41:02,521  The loss during eval_loss is  :: 0.12799742817878723
2019-04-26 19:41:02,522  The global step eval is 943
2019-04-26 19:41:02,635  The loss during eval_loss is  :: 0.059896137565374374
2019-04-26 19:41:02,637  The global step eval is 944
2019-04-26 19:41:02,747  The loss during eval_loss is  :: 0.021827027201652527
2019-04-26 19:41:02,749  The global step eval is 945
2019-04-26 19:41:02,853  The loss during eval_loss is  :: 0.07126021385192871
2019-04-26 19:41:02,861  The global step eval is 946
2019-04-26 19:41:02,973  The loss during eval_loss is  :: 0.11140953004360199
2019-04-26 19:41:02,973  The global step eval is 947
2019-04-26 19:41:03,095  The loss during eval_loss is  :: 0.022005876526236534
2019-04-26 19:41:03,095  The global step eval is 948
2019-04-26 19:41:03,226  The loss during eval_loss is  :: 0.028009729459881783
2019-04-26 19:41:03,226  The global step eval is 949
2019-04-26 19:41:03,337  The loss during eval_loss is  :: 0.004915952682495117
2019-04-26 19:41:03,337  The global step eval is 950
2019-04-26 19:41:03,460  The loss during eval_loss is  :: 0.019172588363289833
2019-04-26 19:41:03,462  The global step eval is 951
2019-04-26 19:41:03,580  The loss during eval_loss is  :: 0.07191533595323563
2019-04-26 19:41:03,581  The global step eval is 952
2019-04-26 19:41:03,591  Saved checkpoint: ./trained_model\step_16.pth.tar
2019-04-26 19:41:03,592  Removed checkpoint: ./trained_model\step_16.pth.tar
2019-04-26 19:41:03,695  The loss during training is  :: 0.013617578893899918 
2019-04-26 19:41:03,857  The global step train is 3809
2019-04-26 19:41:03,999  The loss during training is  :: 0.0017156887333840132 
2019-04-26 19:41:04,167  The global step train is 3810
2019-04-26 19:41:04,300  The loss during training is  :: 0.008570709265768528 
2019-04-26 19:41:04,469  The global step train is 3811
2019-04-26 19:41:04,602  The loss during training is  :: 0.013541012071073055 
2019-04-26 19:41:04,773  The global step train is 3812
2019-04-26 19:41:04,911  The loss during training is  :: 0.00230751046910882 
2019-04-26 19:41:05,072  The global step train is 3813
2019-04-26 19:41:05,205  The loss during training is  :: 0.005554237402975559 
2019-04-26 19:41:05,372  The global step train is 3814
2019-04-26 19:41:05,513  The loss during training is  :: 0.03154918923974037 
2019-04-26 19:41:05,676  The global step train is 3815
2019-04-26 19:41:05,814  The loss during training is  :: 0.0038680490106344223 
2019-04-26 19:41:05,977  The global step train is 3816
2019-04-26 19:41:06,123  The loss during training is  :: 0.004883750341832638 
2019-04-26 19:41:06,292  The global step train is 3817
2019-04-26 19:41:06,425  The loss during training is  :: 0.00388844171538949 
2019-04-26 19:41:06,586  The global step train is 3818
2019-04-26 19:41:06,724  The loss during training is  :: 0.010761220008134842 
2019-04-26 19:41:06,889  The global step train is 3819
2019-04-26 19:41:07,019  The loss during training is  :: 0.007515850011259317 
2019-04-26 19:41:07,180  The global step train is 3820
2019-04-26 19:41:07,319  The loss during training is  :: 0.004532305523753166 
2019-04-26 19:41:07,490  The global step train is 3821
2019-04-26 19:41:07,623  The loss during training is  :: 0.003133039455860853 
2019-04-26 19:41:07,784  The global step train is 3822
2019-04-26 19:41:07,923  The loss during training is  :: 0.0060850935988128185 
2019-04-26 19:41:08,084  The global step train is 3823
2019-04-26 19:41:08,216  The loss during training is  :: 0.009971106424927711 
2019-04-26 19:41:08,386  The global step train is 3824
2019-04-26 19:41:08,515  The loss during training is  :: 0.0031005828641355038 
2019-04-26 19:41:08,676  The global step train is 3825
2019-04-26 19:41:08,797  The loss during training is  :: 0.003916517831385136 
2019-04-26 19:41:08,968  The global step train is 3826
2019-04-26 19:41:09,109  The loss during training is  :: 0.0027162234764546156 
2019-04-26 19:41:09,270  The global step train is 3827
2019-04-26 19:41:09,408  The loss during training is  :: 0.003077243221923709 
2019-04-26 19:41:09,571  The global step train is 3828
2019-04-26 19:41:09,712  The loss during training is  :: 0.003508510533720255 
2019-04-26 19:41:09,873  The global step train is 3829
2019-04-26 19:41:10,014  The loss during training is  :: 0.033616844564676285 
2019-04-26 19:41:10,175  The global step train is 3830
2019-04-26 19:41:10,313  The loss during training is  :: 0.0049739680252969265 
2019-04-26 19:41:10,476  The global step train is 3831
2019-04-26 19:41:10,615  The loss during training is  :: 0.00326645839959383 
2019-04-26 19:41:10,778  The global step train is 3832
2019-04-26 19:41:10,917  The loss during training is  :: 0.002801787108182907 
2019-04-26 19:41:11,083  The global step train is 3833
2019-04-26 19:41:11,224  The loss during training is  :: 0.0027010408230125904 
2019-04-26 19:41:11,393  The global step train is 3834
2019-04-26 19:41:11,531  The loss during training is  :: 0.0035415489692240953 
2019-04-26 19:41:11,698  The global step train is 3835
2019-04-26 19:41:11,829  The loss during training is  :: 0.0026886051055043936 
2019-04-26 19:41:11,997  The global step train is 3836
2019-04-26 19:41:12,134  The loss during training is  :: 0.006213280372321606 
2019-04-26 19:41:12,307  The global step train is 3837
2019-04-26 19:41:12,441  The loss during training is  :: 0.00368810654617846 
2019-04-26 19:41:12,616  The global step train is 3838
2019-04-26 19:41:12,754  The loss during training is  :: 0.026124363765120506 
2019-04-26 19:41:12,917  The global step train is 3839
2019-04-26 19:41:13,049  The loss during training is  :: 0.0037511633709073067 
2019-04-26 19:41:13,218  The global step train is 3840
2019-04-26 19:41:13,353  The loss during training is  :: 0.011532996781170368 
2019-04-26 19:41:13,508  The global step train is 3841
2019-04-26 19:41:13,647  The loss during training is  :: 0.006213477347046137 
2019-04-26 19:41:13,817  The global step train is 3842
2019-04-26 19:41:13,948  The loss during training is  :: 0.004985929932445288 
2019-04-26 19:41:14,110  The global step train is 3843
2019-04-26 19:41:14,250  The loss during training is  :: 0.0023603979498147964 
2019-04-26 19:41:14,420  The global step train is 3844
2019-04-26 19:41:14,551  The loss during training is  :: 0.0038197452668100595 
2019-04-26 19:41:14,721  The global step train is 3845
2019-04-26 19:41:14,851  The loss during training is  :: 0.0019100316567346454 
2019-04-26 19:41:15,011  The global step train is 3846
2019-04-26 19:41:15,152  The loss during training is  :: 0.0021526336204260588 
2019-04-26 19:41:15,316  The global step train is 3847
2019-04-26 19:41:15,450  The loss during training is  :: 0.016378695145249367 
2019-04-26 19:41:15,619  The global step train is 3848
2019-04-26 19:41:15,754  The loss during training is  :: 0.00472363131120801 
2019-04-26 19:41:15,924  The global step train is 3849
2019-04-26 19:41:16,057  The loss during training is  :: 0.009777477942407131 
2019-04-26 19:41:16,234  The global step train is 3850
2019-04-26 19:41:16,379  The loss during training is  :: 0.019370628520846367 
2019-04-26 19:41:16,549  The global step train is 3851
2019-04-26 19:41:16,690  The loss during training is  :: 0.014948301017284393 
2019-04-26 19:41:16,862  The global step train is 3852
2019-04-26 19:41:16,999  The loss during training is  :: 0.006280450616031885 
2019-04-26 19:41:17,183  The global step train is 3853
2019-04-26 19:41:17,321  The loss during training is  :: 0.0029365508817136288 
2019-04-26 19:41:17,491  The global step train is 3854
2019-04-26 19:41:17,632  The loss during training is  :: 0.0015978686278685927 
2019-04-26 19:41:17,822  The global step train is 3855
2019-04-26 19:41:17,963  The loss during training is  :: 0.006722529884427786 
2019-04-26 19:41:18,133  The global step train is 3856
2019-04-26 19:41:18,266  The loss during training is  :: 0.005060078110545874 
2019-04-26 19:41:18,436  The global step train is 3857
2019-04-26 19:41:18,572  The loss during training is  :: 0.009569021873176098 
2019-04-26 19:41:18,736  The global step train is 3858
2019-04-26 19:41:18,874  The loss during training is  :: 0.00907566025853157 
2019-04-26 19:41:19,041  The global step train is 3859
2019-04-26 19:41:19,175  The loss during training is  :: 0.011191320605576038 
2019-04-26 19:41:19,343  The global step train is 3860
2019-04-26 19:41:19,479  The loss during training is  :: 0.008335396647453308 
2019-04-26 19:41:19,641  The global step train is 3861
2019-04-26 19:41:19,777  The loss during training is  :: 0.006527099758386612 
2019-04-26 19:41:19,935  The global step train is 3862
2019-04-26 19:41:20,073  The loss during training is  :: 0.00236681941896677 
2019-04-26 19:41:20,240  The global step train is 3863
2019-04-26 19:41:20,374  The loss during training is  :: 0.03141692653298378 
2019-04-26 19:41:20,538  The global step train is 3864
2019-04-26 19:41:20,673  The loss during training is  :: 0.006114063318818808 
2019-04-26 19:41:20,836  The global step train is 3865
2019-04-26 19:41:20,966  The loss during training is  :: 0.0011793518206104636 
2019-04-26 19:41:21,137  The global step train is 3866
2019-04-26 19:41:21,258  The loss during training is  :: 0.001593036693520844 
2019-04-26 19:41:21,429  The global step train is 3867
2019-04-26 19:41:21,558  The loss during training is  :: 0.0032165558077394962 
2019-04-26 19:41:21,729  The global step train is 3868
2019-04-26 19:41:21,867  The loss during training is  :: 0.006295941770076752 
2019-04-26 19:41:22,029  The global step train is 3869
2019-04-26 19:41:22,166  The loss during training is  :: 0.011381826363503933 
2019-04-26 19:41:22,335  The global step train is 3870
2019-04-26 19:41:22,473  The loss during training is  :: 0.007358986418694258 
2019-04-26 19:41:22,634  The global step train is 3871
2019-04-26 19:41:22,767  The loss during training is  :: 0.007464250084012747 
2019-04-26 19:41:22,920  The global step train is 3872
2019-04-26 19:41:23,060  The loss during training is  :: 0.010288168676197529 
2019-04-26 19:41:23,229  The global step train is 3873
2019-04-26 19:41:23,362  The loss during training is  :: 0.003971354104578495 
2019-04-26 19:41:23,533  The global step train is 3874
2019-04-26 19:41:23,664  The loss during training is  :: 0.004138132557272911 
2019-04-26 19:41:23,836  The global step train is 3875
2019-04-26 19:41:23,972  The loss during training is  :: 0.005657885689288378 
2019-04-26 19:41:24,136  The global step train is 3876
2019-04-26 19:41:24,274  The loss during training is  :: 0.0025382773019373417 
2019-04-26 19:41:24,437  The global step train is 3877
2019-04-26 19:41:24,568  The loss during training is  :: 0.005180679727345705 
2019-04-26 19:41:24,739  The global step train is 3878
2019-04-26 19:41:24,870  The loss during training is  :: 0.015347289852797985 
2019-04-26 19:41:25,041  The global step train is 3879
2019-04-26 19:41:25,175  The loss during training is  :: 0.020788727328181267 
2019-04-26 19:41:25,342  The global step train is 3880
2019-04-26 19:41:25,478  The loss during training is  :: 0.0010063457302749157 
2019-04-26 19:41:25,647  The global step train is 3881
2019-04-26 19:41:25,783  The loss during training is  :: 0.003338832873851061 
2019-04-26 19:41:25,945  The global step train is 3882
2019-04-26 19:41:26,078  The loss during training is  :: 0.004478886723518372 
2019-04-26 19:41:26,231  The global step train is 3883
2019-04-26 19:41:26,371  The loss during training is  :: 0.004996662028133869 
2019-04-26 19:41:26,542  The global step train is 3884
2019-04-26 19:41:26,681  The loss during training is  :: 0.003688348224386573 
2019-04-26 19:41:26,844  The global step train is 3885
2019-04-26 19:41:26,980  The loss during training is  :: 0.0028025563806295395 
2019-04-26 19:41:27,149  The global step train is 3886
2019-04-26 19:41:27,284  The loss during training is  :: 0.007455011829733849 
2019-04-26 19:41:27,446  The global step train is 3887
2019-04-26 19:41:27,573  The loss during training is  :: 0.0078208576887846 
2019-04-26 19:41:27,736  The global step train is 3888
2019-04-26 19:41:27,866  The loss during training is  :: 0.00984572060406208 
2019-04-26 19:41:28,053  The global step train is 3889
2019-04-26 19:41:28,207  The loss during training is  :: 0.003150545759126544 
2019-04-26 19:41:28,407  The global step train is 3890
2019-04-26 19:41:28,550  The loss during training is  :: 0.011660944670438766 
2019-04-26 19:41:28,715  The global step train is 3891
2019-04-26 19:41:28,846  The loss during training is  :: 0.007825552485883236 
2019-04-26 19:41:29,017  The global step train is 3892
2019-04-26 19:41:29,148  The loss during training is  :: 0.009603732265532017 
2019-04-26 19:41:29,309  The global step train is 3893
2019-04-26 19:41:29,448  The loss during training is  :: 0.00786678958684206 
2019-04-26 19:41:29,611  The global step train is 3894
2019-04-26 19:41:29,750  The loss during training is  :: 0.002575143240392208 
2019-04-26 19:41:29,913  The global step train is 3895
2019-04-26 19:41:30,044  The loss during training is  :: 0.004912500269711018 
2019-04-26 19:41:30,225  The global step train is 3896
2019-04-26 19:41:30,364  The loss during training is  :: 0.0018067550845444202 
2019-04-26 19:41:30,527  The global step train is 3897
2019-04-26 19:41:30,658  The loss during training is  :: 0.0016466362867504358 
2019-04-26 19:41:30,827  The global step train is 3898
2019-04-26 19:41:30,958  The loss during training is  :: 0.010624062269926071 
2019-04-26 19:41:31,130  The global step train is 3899
2019-04-26 19:41:31,261  The loss during training is  :: 0.0029716682620346546 
2019-04-26 19:41:31,432  The global step train is 3900
2019-04-26 19:41:31,574  The loss during training is  :: 0.002217032015323639 
2019-04-26 19:41:31,779  The global step train is 3901
2019-04-26 19:41:31,905  The loss during training is  :: 0.007000951562076807 
2019-04-26 19:41:32,075  The global step train is 3902
2019-04-26 19:41:32,214  The loss during training is  :: 0.003619174938648939 
2019-04-26 19:41:32,377  The global step train is 3903
2019-04-26 19:41:32,518  The loss during training is  :: 0.003254194278270006 
2019-04-26 19:41:32,679  The global step train is 3904
2019-04-26 19:41:32,818  The loss during training is  :: 0.00706283887848258 
2019-04-26 19:41:32,987  The global step train is 3905
2019-04-26 19:41:33,121  The loss during training is  :: 0.008349409326910973 
2019-04-26 19:41:33,291  The global step train is 3906
2019-04-26 19:41:33,422  The loss during training is  :: 0.0044874828308820724 
2019-04-26 19:41:33,598  The global step train is 3907
2019-04-26 19:41:33,733  The loss during training is  :: 0.007986878976225853 
2019-04-26 19:41:33,894  The global step train is 3908
2019-04-26 19:41:34,025  The loss during training is  :: 0.003623174037784338 
2019-04-26 19:41:34,196  The global step train is 3909
2019-04-26 19:41:34,327  The loss during training is  :: 0.014847952872514725 
2019-04-26 19:41:34,498  The global step train is 3910
2019-04-26 19:41:34,619  The loss during training is  :: 0.005227899644523859 
2019-04-26 19:41:34,799  The global step train is 3911
2019-04-26 19:41:34,930  The loss during training is  :: 0.005635156761854887 
2019-04-26 19:41:35,101  The global step train is 3912
2019-04-26 19:41:35,232  The loss during training is  :: 0.027006523683667183 
2019-04-26 19:41:35,410  The global step train is 3913
2019-04-26 19:41:35,541  The loss during training is  :: 0.007196556776762009 
2019-04-26 19:41:35,710  The global step train is 3914
2019-04-26 19:41:35,846  The loss during training is  :: 0.007912390865385532 
2019-04-26 19:41:36,010  The global step train is 3915
2019-04-26 19:41:36,139  The loss during training is  :: 0.015527509152889252 
2019-04-26 19:41:36,311  The global step train is 3916
2019-04-26 19:41:36,439  The loss during training is  :: 0.006646000314503908 
2019-04-26 19:41:36,605  The global step train is 3917
2019-04-26 19:41:36,744  The loss during training is  :: 0.008791986852884293 
2019-04-26 19:41:36,909  The global step train is 3918
2019-04-26 19:41:37,041  The loss during training is  :: 0.004594364203512669 
2019-04-26 19:41:37,205  The global step train is 3919
2019-04-26 19:41:37,338  The loss during training is  :: 0.006178016774356365 
2019-04-26 19:41:37,499  The global step train is 3920
2019-04-26 19:41:37,630  The loss during training is  :: 0.00899122841656208 
2019-04-26 19:41:37,800  The global step train is 3921
2019-04-26 19:41:37,931  The loss during training is  :: 0.006454149726778269 
2019-04-26 19:41:38,100  The global step train is 3922
2019-04-26 19:41:38,233  The loss during training is  :: 0.010754457674920559 
2019-04-26 19:41:38,394  The global step train is 3923
2019-04-26 19:41:38,525  The loss during training is  :: 0.004729375708848238 
2019-04-26 19:41:38,696  The global step train is 3924
2019-04-26 19:41:38,817  The loss during training is  :: 0.00530801760032773 
2019-04-26 19:41:38,978  The global step train is 3925
2019-04-26 19:41:39,120  The loss during training is  :: 0.00567548768594861 
2019-04-26 19:41:39,292  The global step train is 3926
2019-04-26 19:41:39,423  The loss during training is  :: 0.006041908171027899 
2019-04-26 19:41:39,588  The global step train is 3927
2019-04-26 19:41:39,723  The loss during training is  :: 0.008332639932632446 
2019-04-26 19:41:39,886  The global step train is 3928
2019-04-26 19:41:40,020  The loss during training is  :: 0.003009179374203086 
2019-04-26 19:41:40,186  The global step train is 3929
2019-04-26 19:41:40,316  The loss during training is  :: 0.008086261339485645 
2019-04-26 19:41:40,496  The global step train is 3930
2019-04-26 19:41:40,626  The loss during training is  :: 0.017351798713207245 
2019-04-26 19:41:40,789  The global step train is 3931
2019-04-26 19:41:40,919  The loss during training is  :: 0.009107119403779507 
2019-04-26 19:41:41,088  The global step train is 3932
2019-04-26 19:41:41,221  The loss during training is  :: 0.006250428967177868 
2019-04-26 19:41:41,414  The global step train is 3933
2019-04-26 19:41:41,563  The loss during training is  :: 0.008147811517119408 
2019-04-26 19:41:41,746  The global step train is 3934
2019-04-26 19:41:41,887  The loss during training is  :: 0.007581154350191355 
2019-04-26 19:41:42,058  The global step train is 3935
2019-04-26 19:41:42,199  The loss during training is  :: 0.0157732255756855 
2019-04-26 19:41:42,371  The global step train is 3936
2019-04-26 19:41:42,501  The loss during training is  :: 0.00530695915222168 
2019-04-26 19:41:42,672  The global step train is 3937
2019-04-26 19:41:42,813  The loss during training is  :: 0.005473950877785683 
2019-04-26 19:41:42,974  The global step train is 3938
2019-04-26 19:41:43,113  The loss during training is  :: 0.002493305131793022 
2019-04-26 19:41:43,277  The global step train is 3939
2019-04-26 19:41:43,408  The loss during training is  :: 0.003814430208876729 
2019-04-26 19:41:43,583  The global step train is 3940
2019-04-26 19:41:43,721  The loss during training is  :: 0.0025849342346191406 
2019-04-26 19:41:43,882  The global step train is 3941
2019-04-26 19:41:44,012  The loss during training is  :: 0.01014821045100689 
2019-04-26 19:41:44,183  The global step train is 3942
2019-04-26 19:41:44,320  The loss during training is  :: 0.0026472853496670723 
2019-04-26 19:41:44,489  The global step train is 3943
2019-04-26 19:41:44,625  The loss during training is  :: 0.00627351738512516 
2019-04-26 19:41:44,795  The global step train is 3944
2019-04-26 19:41:44,927  The loss during training is  :: 0.0028306134045124054 
2019-04-26 19:41:45,100  The global step train is 3945
2019-04-26 19:41:45,235  The loss during training is  :: 0.009267291985452175 
2019-04-26 19:41:45,403  The global step train is 3946
2019-04-26 19:41:45,534  The loss during training is  :: 0.02018711157143116 
2019-04-26 19:41:45,713  The global step train is 3947
2019-04-26 19:41:45,844  The loss during training is  :: 0.017582911998033524 
2019-04-26 19:41:46,002  The global step train is 3948
2019-04-26 19:41:46,140  The loss during training is  :: 0.013282652013003826 
2019-04-26 19:41:46,308  The global step train is 3949
2019-04-26 19:41:46,441  The loss during training is  :: 0.004521115683019161 
2019-04-26 19:41:46,603  The global step train is 3950
2019-04-26 19:41:46,743  The loss during training is  :: 0.002462666714563966 
2019-04-26 19:41:46,914  The global step train is 3951
2019-04-26 19:41:47,049  The loss during training is  :: 0.007336985319852829 
2019-04-26 19:41:47,215  The global step train is 3952
2019-04-26 19:41:47,345  The loss during training is  :: 0.00447106035426259 
2019-04-26 19:41:47,526  The global step train is 3953
2019-04-26 19:41:47,657  The loss during training is  :: 0.016360508278012276 
2019-04-26 19:41:47,831  The global step train is 3954
2019-04-26 19:41:47,966  The loss during training is  :: 0.00825934112071991 
2019-04-26 19:41:48,137  The global step train is 3955
2019-04-26 19:41:48,275  The loss during training is  :: 0.0033758068457245827 
2019-04-26 19:41:48,461  The global step train is 3956
